### YamlMime:Yaml
ms.openlocfilehash: 6a14cd88330d4511a16d64d3cada7b30ea4768fe
ms.sourcegitcommit: d03bdc7fe5447adb6530886aab848b75fe8fa8ee
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 03/11/2022
ms.locfileid: "139907795"
Slug: from-a-pc-on-every-desktop-to-deep-learning-in-every-software
Title: "\"모든 데스크톱의 PC\"에서 \"모든 소프트웨어의 심층 Learning\"에 이르기까지"
Summary: 딥 러닝은 음성 인식, 언어 이해 및 컴퓨터 비전을 포함하여 인공 지능의 많은 최근 돌파구 뒤에 있습니다. Microsoft는 Cortana, Bing, Office 365, SwiftKey, Skype Translate, Dynamics 365 및 HoloLens 비롯한 다양한 애플리케이션 및 서비스에서 고객 환경을 변화시키고 있습니다.
Content: >-
  <p>딥 러닝은 음성 인식, 언어 이해 및 컴퓨터 비전을 포함하여 인공 지능의 많은 최근 돌파구 뒤에 있습니다. Microsoft는 Cortana, Bing, Office 365, SwiftKey, Skype Translate, Dynamics 365 및 HoloLens 비롯한 다양한 애플리케이션 및 서비스에서 고객 환경을 변화시키고 있습니다. Skype 딥 러닝 기반 <a href="https://www.popsci.com/how-microsofts-machine-learning-breaking-language-barrier" target="_blank">언어 번역</a>&nbsp;은 최근 대중 과학에서 <a href="https://www.popsci.com/6-greatest-software-innovations-year" target="_blank">올해의 7대 소프트웨어 혁신 중 하나로</a> 선정되었으며, 이 기술은 대화형 음성 인식에서 인간 수준의 패리티를 달성하는 데 도움이 됩니다. 딥 러닝은 이제 Microsoft Cognitive Toolkit, Cortana Intelligence Suite, Microsoft Cognitive Services, Azure Machine Learning, Bot Framework 및 Azure Bot Service와 같은 개발 플랫폼의 핵심 기능입니다. 나는이 기술의 응용 프로그램이 지금까지&nbsp; &ldquo;모든 소프트웨어&rdquo;의 딥 Learning이 10 년 이내에 현실이 될 것이라고 생각합니다.</p>


  <p>Were&rsquo;는 개발자가 더 스마트한 제품을 만들고 가장 어려운 컴퓨팅 작업을 해결할 수 있도록 AI 및 Deep Learning 개발자의 역량을 강화하기 위해 열심히 노력하고 있습니다. 알고리즘, 인프라를 적극적으로 개선하고 NVIDIA, OpenAI 등과 같은 파트너와 긴밀하게 협력하고 GPU 가속 시스템의 기능을 활용하여 가장 빠르고 다재다능한 AI 플랫폼 &ndash; 에 Microsoft Azure 진정한 지능형 클라우드로 만들 수&rsquo; 있습니다.</p>


  <h2>모든 사용자를 위한 심층 Learning Toolkit Production-Ready</h2>


  <p><a href="https://cntk.ai/" target="_blank"><strong>Microsoft Cognitive Toolkit</strong></a>(이전 <strong>CNTK</strong>)은 심층 신경망을 학습하고 평가하기 위한 오픈 소스 플랫폼 간 도구 키트입니다. 이 Cognitive Toolkit 간단한 구성 요소를 복잡한 계산 네트워크로 구성하고 모든 관련 네트워크 유형 및 애플리케이션을 지원하여 임의 신경망을 표현합니다. 최첨단 정확도와 효율성으로 다중 GPU/다중 서버 환경으로 확장됩니다. 내부 및 외부 벤치 마크 모두에 따르면, Cognitive Toolkit 대부분의 테스트에서 다른 깊은 Learning 프레임 워크를 능가 하 고 당연히, 최신 버전은 이전 릴리스 보다 빠른, 특히 대규모 빅 데이터 집합 및 NVIDIA에서 파스칼 GPU에 작업 하는 경우. 단일&rsquo; GPU 성능에는 해당하지만 실제로 중요한 것은 Cognitive Toolkit 이미 많은 수의 GPU를 사용하도록 확장할 수 있다는 것입니다. 최신 릴리스&rsquo;에서는 C++외에도 Python을 기본적으로 지원하도록 확장된 Cognitive Toolkit. 또한 Cognitive Toolkit 개발자가 보충 학습을 사용하여 모델을 학습할 수 있습니다. 마지막으로, Cognitive Toolkit 어떤 방식으로든 클라우드에 바인딩되지 않습니다&rsquo;. 클라우드에서 모델을 학습시킬 수 있지만 온-프레미스 또는 다른 호스터를 사용하여 실행할 수 있습니다. 우리의 목표는 누구나 이 강력한 기술을 활용할 수 있도록 힘을 실어주는 것입니다.</p>


  <p>Toolkit 빠르게 속도를 높이기 위해 수많은&nbsp; 자습서를 통해 게시된 <strong>Azure Notebooks</strong>&rsquo;를 만들고 이미지,&rsquo; 숫자, 음성 및 텍스트와 같은 다양한 데이터 세트를 사용하는 시나리오에서 수십 개의 코드 샘플, 레시피 및 자습서가 포함된 <a href="https://www.microsoft.com/en-us/research/product/cognitive-toolkit/model-gallery/" target="_blank"><strong>DNN 모델 갤러리</strong></a>를 조립했습니다.</p>


  <h2>다른 사람들이 말하는 것</h2>


  <p>2016년 9월에 발표된 <a href="https://www.microsoft.com/en-us/research/product/cognitive-toolkit/model-gallery/" target="_blank"><strong>벤치마킹 최첨단 심층 Learning 소프트웨어 도구&rdquo; 논문에서 학술 연구원들은 Caffe, Cognitive Toolkit(CNTK), TensorFlow 및 Torch를 포함한 최첨단 GPU 가속 딥 러닝 소프트웨어 도구에 대한 비교 연구를 실행했습니다.&ldquo;</strong></a> 두&rsquo; 개의 CPU 플랫폼과 3개의 GPU 플랫폼에서 인기 있는 세 가지 유형의 신경망을 사용하여 이러한 도구의 실행 성능을 벤치마킹했습니다. 이 Cognitive Toolkit 거의 모든 워크로드에서 다른 딥 러닝 도구 키트를 능가했습니다.</p>


  <p>또한 Nvidia는 최근 인기 있는 모든 Deep Learning 도구 키트를 최신 하드웨어와 비교하는 벤치마크를 실행했습니다. 결과에 따르면 Cognitive Toolkit 사용 가능한 다른 도구 키트보다 빠르게 딥 러닝 알고리즘을 학습하고 평가하여 CPU에서 GPU까지 다양한 환경에서&mdash; 효율적으로 스케일링하여 정확도를 유지하면서 여러 머신&mdash;으로 확장합니다. 특히 이전&rsquo; 릴리스보다 <strong>1.7배 빠르</strong> 며 Pascal GPU의<strong> TensorFlow보다 3배 더 빠릅니다</strong> (SuperComputing16&rsquo; 컨퍼런스에서 발표됨).</p>


  <p>딥 러닝 소프트웨어 도구의 최종 사용자는 적절한 하드웨어 플랫폼 및 소프트웨어 도구를 선택하는 지침으로 이러한 벤치마킹 결과를 사용할 수 있습니다. 둘째, 딥 러닝 소프트웨어 도구 개발자를 위해 심층 분석은 성능을 더욱 최적화하기 위한 향후 방향을 지적합니다.</p>


  <h2>실제 심층 Learning 워크로드</h2>


  <p>Microsoft는 디지털 에이전트에서 Azure의 핵심 인프라에 이르기까지 다양한 내부 서비스에서 Deep Learning 및 Cognitive Toolkit 사용합니다.</p>


  <p><strong>1.</strong><strong>에이전트(Cortana):</strong> Cortana 사용자가 누구인지 알고 모든 장치에서 업무와 삶의 기본 설정을 알고 있는 디지털 에이전트입니다. Cortana 1억 3,300만 명 이상의 사용자를 보유하고 있으며 120억 개 이상의 질문에 지능적으로 답변했습니다. 음성 인식에서 Cortana &ndash; 컴퓨터 비전에 이르기까지 이러한 모든 기능은 Deep Learning 및 Cognitive Toolkit 통해 제공됩니다. 우리는 최근에 <a href="https://blogs.microsoft.com/next/2016/10/18/historic-achievement-microsoft-researchers-reach-human-parity-conversational-speech-recognition/#sm.000006gmppudtudy7yojksy7pwee5" target="_blank">음성 인식에서 중요한 돌파구</a>를 만들어 대화의 단어를 인식하고 전문 전사자보다 동일하거나 적은 오류를 만드는 기술을 만들었습니다. 연구원은 5.9 %의 단어 오류율 (WER)을보고, 6.3 %에서 아래로, 업계 표준 스위치 보드 음성 인식 작업에 대해 기록 된 가장 낮은 오류 비율. 딥 Learning 사용하여 인간의 패리티에 도달하는 것은 진정으로 역사적인 업적입니다.</p>


  <p><img alt="DeepLearning" border="0" height="297" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/2d83e81d-a588-442a-8e80-f92f842745fc.png" style="border-top: 0px; border-right: 0px; background-image: none; border-bottom: 0px; float: none; padding-top: 0px; padding-left: 0px; margin-left: auto; border-left: 0px; display: block; padding-right: 0px; margin-right: auto" title="DeepLearning" width="610"></p>


  <p><a href="https://arxiv.org/abs/1512.03385" target="_blank">이미지 인식에 대한 접근 방식은</a> ImageNet 및 Microsoft Common Objects in Context 챌린지의 몇 가지 주요 범주에서도 1위를 했습니다. 도구를 사용하여 빌드된 DNN은 분류, 지역화 및 검색이라는 세 가지 범주에서 모두 1위를 차지했습니다. 이 시스템은 과거 &ndash; 보다 훨씬 더 많은 152개의 계층 &ndash; 을 정확하게 학습시킬 수 있었기 때문에 강력한 마진으로 이겼으며 새로운 &ldquo;잔류 학습&rdquo; 원칙을 사용했습니다. 잔차 학습은 학습 절차를 다시 정의하고 심층 신경망의 정보 흐름을 리디렉션합니다. 이는 전통적으로 매우 깊은 신경망을 구축하려는 시도를 해온 정확도 문제를 해결하는 데 도움이 되었습니다.</p>


  <p><strong>2.</strong><strong>응용 프로그램:</strong> Office 365, Outlook, PowerPoint, Word 및 Dynamics 365의 애플리케이션은 딥 러닝을 사용하여 새로운 고객 환경을 제공할 수 있습니다. <strong>Microsoft 고객 지원 및 서비스에서</strong> 사용하는 봇의 딥 러닝 애플리케이션의 한 가지 훌륭한 예입니다. 심층 신경망 및 Cognitive Toolkit 사용하여 고객이 요구하는 문제를 지능적으로 이해하고 이러한 문제를 해결하기 위한 최상의 솔루션을 추천할 수 있습니다. 봇은 많은 일반적인 고객 문제에 대한 빠른 셀프 서비스 환경을 제공하고 기술 직원이 더 어렵고 어려운 고객 문제에 집중할 수 있도록 도와줍니다.</p>


  <p>Deep Learning 사용하는 애플리케이션의 또 다른 예는 고객 eSmart(연결된 <a href="https://blogs.technet.microsoft.com/machinelearning/2016/11/02/connected-drones-3-powerful-lessons-we-can-all-take-away/" target="_blank"><strong>드론</strong></a>의 작동을 확인하려면 <a href="https://www.youtube.com/watch?v=nbMt5hHvpnc" target="_blank">이 비디오를 시청</a>하세요)의 전력선 검사를 위해 빌드된 연결된 드론 애플리케이션입니다. <strong>eSmart Systems</strong> 는 <a href="https://azure.microsoft.com/en-us/services/machine-learning/" target="_blank">클라우드 인텔리전스</a> 와 결합된 드론이 전력 산업에 큰 효율성을 가져다 줄 수 있다는 강한 신념으로 연결된 드론을 개발하기 시작했습니다. 연결된 드론의 목적은 지상 승무원과 헬리콥터가 수행하는 현재 비용이 많이 들고 위험하며 시간이 많이 걸리는 검사 대신 전력망 인프라의 검사 및 모니터링을 지원하고 자동화하는 것입니다. 이를 위해 <a href="https://blogs.technet.microsoft.com/machinelearning/2016/09/15/building-deep-neural-networks-in-the-cloud-with-azure-gpu-vms-mxnet-and-microsoft-r-server/" target="_blank">Deep Learning</a> 사용하여 드론에서 스트리밍된 비디오 데이터 피드를 분석합니다. 분석 소프트웨어는 전신주에 있는 절연체와 같은 개별 개체를 인식하고 새 정보를 구성 요소 레지스트리와 직접 연결하여 검사자가 잠재적인 문제를 신속하게 인식할 수 있도록 합니다. eSmart는 매우 깊고 빠른 R-CNN에서 Single Shot 멀티박스 탐지기 등에 이르기까지 연결된 드론의 데이터를 분석하는 다양한 딥 러닝 기술을 적용합니다.</p>


  <p><strong>3. Cloud Services(Cortana Intelligence Suite):</strong> Azure에서는 <a href="https://www.microsoft.com/cognitive-services/en-us/apis" target="_blank"><strong>Cognitive Services</strong></a>(비전, 음성, 언어, 지식, 검색 등), Bot Framework, Azure Machine Learning, Azure Data Lake, Azure SQL 포함한 Machine Learning 및 고급 분석을 위한 제품군을 제공합니다.  Cortana Intelligence Suite 호출된 데이터 웨어하우스 및 PowerBI입니다. 이러한 서비스를 Cognitive Toolkit 또는 선택한 다른 딥 러닝 프레임워크와 함께 사용하여 지능형 애플리케이션을 배포할 수 있습니다. 예를 들어 이제 Azure의 <strong>HDInsight Apache Spark</strong> 클러스터에서 미리 학습된 DNN 기계 학습 모델을 사용하여 점수 매기기를 대규모로 병렬화할 수 있습니다. 냉장고 내부의 개체를 시각적으로 인식하기 위해 DNN을 <a href="https://blogs.technet.microsoft.com/machinelearning/2016/09/02/microsoft-and-liebherr-collaborating-on-new-generation-of-smart-refrigerators/" target="_blank">실행하는 고객 Liebherr</a>와 같이 많은 이미지에서 미리 학습된 DNN의 점수를 매기는 시나리오가 증가하고 있습니다. 개발자는 몇 단계만 수행하여 이러한 처리 아키텍처를 구현할 수 <a href="https://blogs.technet.microsoft.com/machinelearning/2016/10/31/applying-cloud-deep-learning-at-scale-with-microsoft-r-server-azure-data-lake/" target="_blank">있습니다(여기 지침 참조</a>).</p>


  <p>일반적인 대규모 이미지 점수 매기기 시나리오에는 매우 높은 I/O 처리량 및/또는 대용량 파일 스토리지 용량이 필요할 수 있습니다. 이 경우 ADLS( <a href="https://azure.microsoft.com/en-us/services/data-lake-store/" target="_blank"><strong>Azure Data Lake Store</strong></a> )는 고성능 및 확장 가능한 분석 스토리지를 제공합니다. 또한 ADLS는 읽기에 데이터 스키마를 적용하므로 데이터가 필요할 때까지 사용자가 스키마에 대해 걱정하지 않아도 됩니다. 사용자&rsquo; 관점에서 ADLS는 제공된 HDFS 커넥터를 통해 다른 HDFS 스토리지 계정과 마찬가지로 작동합니다. <strong>학습은 Azure N 시리즈 NC24 GPU 지원 Virtual Machine</strong>에서 수행되거나 <strong>Azure Batch Shipyard</strong>의 레시피를 사용하여 수행될 수 있으며, 이를 통해 퍼블릭 클라우드에서 4개의 NVIDIA Tesla K80 GPU를 사용하여 운영 체제 미설치 GPU 하드웨어 가속으로 DNN을 학습할 수 있습니다. 채점을 위해 HDInsight Spark 클러스터 또는 <a href="https://azure.microsoft.com/en-us/services/data-lake-analytics/" target="_blank"><strong>Azure Data Lake Analytics</strong></a> 사용하여 작업자 노드에 워크로드를 분산하여 <strong>Microsoft R Server(MRS</strong>)의 rxExec 함수를 사용하여 대규모 이미지 컬렉션의 채점을 대규모로 병렬화할 수 있습니다. 점수 매기기 워크로드는 MRS의 단일 인스턴스에서 오케스트레이션되며 각 작업자 노드는 데이터를 ADLS에 독립적으로 병렬로 읽고 쓸 수 있습니다.</p>


  <p>최고의 데이터베이스 엔진인 <a href="https://www.microsoft.com/en-us/sql-server/" target="_blank"><strong>SQL Server</strong></a> 깊&rdquo;어지고 있습니다&ldquo;. 이제 <a href="https://www.microsoft.com/en-us/sql-server/sql-server-r-services?wt.mc_id=dx_875446&amp;gclid=CMuZo8rnx9ACFUlNfgodz2gFGA" target="_blank">R 및 ML SQL Server 기본 제공</a>된 상태에서 처음으로 이 작업을 수행할 수 있습니다. SQL Server 내에 딥 러닝 모델을 푸시하면 이제 고객은 처리량, 병렬 처리, 보안, 안정성, 규정 준수 인증 및 관리 효율성을 모두 하나로 얻을 수 있습니다. &rsquo;ML 모델의 운영 배포를 위해 관리 계층을 별도로 빌드할 필요가 없는&rsquo; 데이터 과학자와 개발자 &ndash; 에게 큰 승리입니다. 또한 데이터베이스의 데이터를 여러 애플리케이션에서 공유할 수 있는 것처럼 이제 딥 러닝 모델을 공유할 수 있습니다.&nbsp; 모델과 인텔리전스는 2016년 SQL Server 관리되는 또 다른 유형의 데이터가&rdquo; 됩니다&ldquo;. 이러한 기능을 통해 개발자는 이제 데이터베이스의 최신 트랜잭션 처리 발전과 딥 러닝을 결합하는 새로운 종류의 애플리케이션을 빌드할 수 있습니다.</p>


  <p><strong>4. 인프라(Azure):</strong> <a href="https://channel9.msdn.com/Shows/Azure-Friday/Leveraging-NVIDIA-GPUs-in-Azure" target="_blank">딥 Learning</a> 심층 학습의 계산 집약적 특성을 지원할 수 있는 새로운 종류의 고성능 인프라가 필요합니다. Azure는 현재 퍼블릭 클라우드에서 단일 및 배정밀도 워크로드에 가장 적합한 <a href="https://gpu.azure.com/" target="_blank">NVIDIA&#39;Tesla K80 GPU</a> 로 구동되는 N 시리즈 가상 머신을 통해 이러한 시나리오를 사용할 수 있습니다. 이러한 GPU는 거의 운영 체제 미설치 성능을 제공할 수 있는 신중한 디바이스 할당이라는 하드웨어 통과 메커니즘을 통해 노출됩니다. 또한 이러한 워크로드에 대한 데이터가 증가함에 따라 데이터 과학자는 단일 서버의 여러 GPU뿐만 아니라 노드의 여러 GPU에 학습을 배포해야 합니다. 수십 또는 수백 개의 GPU에서 이러한 분산 학습 요구 사항을 가능하게 하기 위해 Azure는 대기 시간이 2 마이크로초 미만인 VM 간의 높은 대역폭 통신을 허용하는 Mellanox&#39;InfiniBand 패브릭을 사용하여 N 시리즈용 고급 네트워킹 인프라에 투자했습니다. 이 네트워킹 기능을 사용하면 Microsoft&#39;자체 Cognitive Toolkit(CNTK)와 같은 라이브러리가 노드 간 통신에 MPI를 사용하고 더 많은 수의 계층과 뛰어난 성능으로 효율적으로 학습할 수 있습니다.</p>


  <p>또한 현재 N 시리즈가 해당 로드맵의 첫 번째 반복으로 Azure에 대한 동급 최고의 로드맵에서 NVIDIA와 협력하고 있습니다. 이러한 Virtual Machines는 현재 미리 보기로 제공되며 최근 12월 1일부터 이 제품의 일반 공급이 발표되었습니다.</p>


  <p>Azure에서 딥 러닝을 시작하는 것은 쉽습니다. <a href="https://azure.microsoft.com/en-us/marketplace/partners/microsoft-ads/standard-data-science-vm/" target="_blank"><strong>DSVM(Data Science Virtual Machine)</strong></a>은 Azure Marketplace에서 사용할 수 있으며 Linux 및 Windows 위한 다양한 딥 러닝 프레임워크 및 도구와 함께 미리 로드됩니다. 여러 학습 작업을 병렬로 쉽게 실행하거나 둘 이상의 서버에서 분산 작업을 시작하려면 <a href="https://azure.microsoft.com/en-us/blog/deep-learning-simulation-and-hpc-applications-with-docker-and-azure-batch/" target="_blank"><strong>Azure Batch &ldquo;Shipyard&rdquo;</strong></a> 템플릿을 최상위 프레임워크에 사용할 수 있습니다. Shipyard는 GPU 및 InfiniBand 드라이버 구성을 처리하고 Docker 컨테이너를 사용하여 소프트웨어 환경을 설정합니다.</p>


  <p>마지막으로 엔지니어 및 연구원 팀은 <a href="https://www.wired.com/2016/09/microsoft-bets-future-chip-reprogram-fly/" target="_blank"><strong>필드 프로그래밍 가능 게이트 배열(FPGA</strong></a>)이라는 다시 프로그래밍 가능한 컴퓨터 칩을 사용하여 Bing 및 Azure를 가속화하는 시스템을 만들었습니다. FPGA 칩을 활용하여 이제 잠재적으로 효율성이 낮은 소프트웨어를 중간자로 사용하는 대신 딥 Learning 알고리즘을 하드웨어에 직접 작성할 수 있습니다. 더욱&rsquo;이, FPGA는 AI/Deep Learning 새로운 발전에 대응하거나 데이터 센터에서 다른 유형의 예기치 않은 요구를 충족하기 위해 잠시&rsquo; 후에 다시 프로그래밍할 수 있습니다. 일반적으로 엔지니어는 서로 다른 사양의 하드웨어가 설계 및 배포될 때까지 2년 이상 기다릴 수 있습니다. 이것은 성공 한 달탄 프로젝트&rsquo;이며 우리는 고객에게 지금 이것을 가져오고 있습니다.</p>


  <h2>AI의 미래 형성에 참여</h2>


  <p>Deep Learning 혁신에 중점을 두는 것은 인프라, 개발 도구, PaaS 서비스 및 최종 사용자 애플리케이션의 전체 스택에 걸쳐 있습니다. 다음은 제품이 제공하는 몇 가지 이점입니다.</p>


  <ul>
   <li><strong>보다 다양한 기능:</strong> 이 Cognitive Toolkit 통해 고객은 하나의 프레임워크를 사용하여 NVIDIA DGX-1 또는 NVIDIA GPU 기반 시스템을 사용하여 온-프레미스에서 모델을 학습한 다음 Azure의 클라우드에서 해당 모델을 실행할 수 있습니다. 이 확장성 있는 하이브리드 접근 방식을 통해 기업은 지능형 기능을 신속하게 프로토타입하고 배포할 수 있습니다.</li>
   <li><strong>더 빠른 성능:</strong> CPU에서 실행되는 것과 비교할 때 GPU 가속 Cognitive Toolkit Azure N 시리즈 서버 및 온-프레미스에서 사용할 수 있는 NVIDIA GPU에서 딥 러닝 학습 및 유추를 훨씬 더 빠르게 수행합니다. 예를 들어 파스칼 및 NVLink 상호 연결 기술을 사용하는 NVIDIA DGX-1은 Cognitive Toolkit CPU 서버보다 170배 빠릅니다.</li>
   <li><strong>더 넓은 가용성:</strong> NVIDIA GPU로 구동되는 Azure N 시리즈 가상 머신은 현재 Azure 고객에게 미리 보기로 제공되며 12월에 일반 공급될 예정입니다. Azure GPU를 사용하여 학습 및 모델 평가를 가속화할 수 있습니다. 이미 수천 명의 고객이 미리 보기에 참여하고 있는 상황에서 모든 규모의 기업은 이미 Azure N 시리즈 VM의 Tesla GPU에서 워크로드를 실행하고 있습니다.</li>
   <li><strong>전체 데이터 스택과 네이티브 통합:</strong> 우리는 데이터가 있는 곳 가까이에 인텔리전스를 푸시하는 것을 강력하게 믿습니다. 몇 년 전 데이터베이스 엔진이나 빅 데이터 엔진 내부에서 Deep Learning 실행하는 것은 공상 과학 소설처럼 보였지만 이제는 현실이 되었습니다. 이미지, 비디오, 음성 및 텍스트와 같은 방대한 양의 데이터에 대해 딥 러닝 모델을 실행할 수 있으며 대량으로 수행할 수 있습니다. 이는 Azure Data Lake, HDInsight 및 SQL Server 제공하는 일종의 기능입니다. 이제 딥 러닝의 결과를 다른 유형의 데이터와 조인할 수 있으며, 이를 통해 믿을 수 없을 만큼 강력한 분석 및 인텔리전스를 수행할 수 있습니다(현재 빅 인식&rdquo;이라고 함&ldquo;). &rsquo;한 번에 한 조각의 인지 정보를 추출하는 것뿐만 아니라 추출된 모든 인지 데이터를 다른 유형의 데이터와 조인하고 통합하여 마법처럼 &ldquo;보이는 모든&rdquo; 인식 애플리케이션을 만들 수 있습니다.</li>
  </ul>


  <p>모든 개발자를 초대하여 이 흥미로운 AI 애플리케이션의 여정에 참여하도록 하겠습니다.</p>


  <p><a href="https://www.twitter.com/josephsirosh" target="_blank">@josephsirosh</a></p>
