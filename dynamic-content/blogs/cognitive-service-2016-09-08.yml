### YamlMime:Yaml
ms.openlocfilehash: e4f61bb0d7c019bf1596819103886ed51cb21ced
ms.sourcegitcommit: d03bdc7fe5447adb6530886aab848b75fe8fa8ee
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 03/11/2022
ms.locfileid: "139898072"
Slug: cognitive-service-2016-09-08
Title: Microsoft Cognitive Services API 사용하여 거의 실시간으로 라이브 비디오 분석
Summary: Microsoft Cognitive Services Vision API는 개발자의 손끝에서 최신 컴퓨터 비전 알고리즘을 배치하고, 개별 이미지를 분석하고, 오프라인 비디오 처리를 위한 API를 제공합니다. 이러한 API 조합을 사용하여 라이브 비디오 스트림에서 가져온 프레임을 거의 실시간으로 분석할 수 있는 솔루션을 만드는 방법을 보여주고자 합니다. 당신은 이론적으로, 구축 할 수 ...
Content: >-
  <p><a href="https://www.microsoft.com/cognitive-services/en-us/apis#vision">Microsoft Cognitive Services Vision API</a>&nbsp; 최신 컴퓨터 비전 알고리즘을 개발자의 손끝에 배치하고, 개별 이미지를 분석하고, 오프라인 비디오 처리를 위한 API를 사용합니다. 이러한 API 조합을 사용하여 라이브 비디오 스트림에서 가져온 프레임을 거의 실시간으로 분석할 수 있는 솔루션을 만드는 방법을 보여주고자 합니다. 이론적으로 라이브 TV 이벤트, 군중 비디오 또는 사람들의 반응을 분석하거나 사람이 느끼는 것에 대한 실시간 정보를 제공하는 앱을 빌드할 수 있습니다.</p>

  <p><br>이 솔루션은 비디오 스트림에서 유용한 데이터를 생성하는 앱을 만들려는 개발자에게 특히 유용할 수 있습니다. 예를 들어 개발자는 10인용 포커스 그룹의 반응을 읽을 수 있는 앱을 만들고, 해당 사용자는 새 제품을 표시하거나 웹 사이트를 탐색할 수 있습니다. 이 솔루션은 거의 실시간으로 이 작업을 수행할 수 있습니다.<br>이 게시물에서는 사용자 고유의 솔루션을 더 쉽게 빌드할 수 있도록 API를 사용하여 거의 실시간으로 비디오 분석을 수행할 수 있는 몇 가지 방법과 게시하는 C# 라이브러리에 대해 설명합니다.</p>

  <p>

  <p>이러한 시스템의 기본 구성 요소는 다음과 같습니다.</p>

  <ul>

  <li>비디오 원본에서 프레임을 가져옵니다.</li>

  <li>분석할 프레임을 선택합니다.</li>

  <li>이러한 프레임을 API에 제출합니다.</li>

  <li>API 호출에서 반환되는 각 분석 결과를 사용합니다.</li>

  </ul>

  <p>

  <p>샘플 코드만 원하는 경우 GitHub <a href="https://github.com/Microsoft/Cognitive-Samples-VideoFrameAnalysis/">https://github.com/Microsoft/Cognitive-Samples-VideoFrameAnalysis/</a>찾을 수 있습니다.</p>

  <h3><br>간단한 접근 방식</h3>

  <p><br>거의 실시간 분석 시스템을 위한 가장 간단한 디자인은 무한 루프로, 여기서는 각 반복에서 프레임을 잡아 분석한 후 결과를 사용합니다.</p>

  <p style="padding-left: 30px;"><br>while(true)<br>{</p>

  <p style="padding-left: 60px;">Frame f = GrabFrame();<br> if(ShouldAnalyze(f))<br> {</p>

  <p style="padding-left: 90px;">AnalysisResult r = await Analyze(f);<br> ConsumeResult(r);</p>

  <p style="padding-left: 60px;">}</p>

  <p style="padding-left: 30px;">}</p>

  <p><br>분석이 경량 클라이언트 쪽 알고리즘으로 구성되어 있는 경우 이 접근 방식이 적합합니다. 그러나 클라우드에서 분석이 발생하는 경우 관련된 대기 시간은 API 호출이 몇 초 정도 걸릴 수 있음을 의미하며, 이 기간 동안 이미지를 캡처하지 않고 스레드는 기본적으로 아무 작업도 수행하지 않습니다. 최대 프레임 속도는 API 호출의 대기 시간으로 제한됩니다. 따라서 API가 동시에 작동하게 하는 솔루션이 필요합니다.</p>

  <p>

  <h3>APICall&nbsp; 병렬화</h3>

  <p><br>이 문제의 해결 방법은 프레임을 잡는 프로그램 요소와 함께 장기 실행 API 호출을 병렬로 실행할 수 있도록 하는 것입니다. C#에서는 작업 기반 병렬 처리를 사용하여 이 목표를 달성할 수 있습니다. 예를 들면 다음과 같습니다.</p>

  <p style="padding-left: 30px;"><br>while(true)<br>{</p>

  <p style="padding-left: 60px;">Frame f = GrabFrame();<br>if(ShouldAnalyze(f))<br>{</p>

  <p style="padding-left: 90px;">var t = Task.Run(async () =&gt;</p>

  <p style="padding-left: 90px;">{</p>

  <p style="padding-left: 120px;">AnalysisResult r = await Analyze(f);</p>

  <p style="padding-left: 120px;">ConsumeResult(r);</p>

  <p style="padding-left: 90px;">}</p>

  <p style="padding-left: 60px;">}</p>

  <p style="padding-left: 30px;">}</p>

  <p><br>그러면 새 프레임을 계속 잡는 동안 백그라운드에서 실행할 수 있는 별도의 작업에서 각 분석이 시작됩니다. 이 솔루션은 API 호출이 반환되도록 기다리는 동안 주 스레드를 차단하지 않습니다. 그러나 간단한 버전 제공된 aPI 호출이 병렬로 발생할 수 있고 결과가 잘못된 순서로 반환될 수 있다는 일부 보장이 손실되었습니다&mdash;. 이로 인해 여러 스레드가 동시에 ConsumeResult() 함수에 진입할 수 있으며, 함수가 스레드로부터 안전하지 않은 경우 위험할 수 있습니다. 마지막으로 이 간단한 코드는 생성되는 작업을 추적하지 않으므로 예외가 자동으로 사라집니다. 따라서 추가할 최종 요소는 분석 작업을 추적하고, 예외를 발생시키고, 장기 실행 작업을 중지하고, 결과가 한 번에 하나씩 올바른 순서로 소비되도록 하는 "소비자" 스레드입니다.</p>

  <p>

  <h3>AProducer-Consumer&nbsp; 디자인</h3>

  <p><br>최종 “생산자-소비자” 시스템에서는 이전의 무한 루프와 매우 유사한 생산자 스레드가 있습니다. 그러나 분석 결과를 사용할 수 있는 즉시 사용하는 대신 생산자는 작업을 큐에 배치하여 추적합니다.</p>

  <p style="padding-left: 30px;">API 호출 태스크를 포함할 큐입니다. <br>var taskQueue = new BlockingCollectionTaskResultWrapper&gt;&lt;&lt;&gt;();</p>

  <p style="padding-left: 30px;">생산자 스레드입니다. <br>while(true)<br>{</p>

  <p style="padding-left: 60px;">프레임을 잡습니다. <br>Frame f = GrabFrame();</p>

  <p style="padding-left: 60px;">프레임을 분석할지 여부를 결정합니다. <br>if(ShouldAnalyze(f))<br>{</p>

  <p style="padding-left: 90px;">이 스레드와 병렬로 실행되는 작업을 시작합니다. <br> var analysisTask = Task.Run(async () =&gt; <br> {</p>

  <p style="padding-left: 120px;">프레임과 결과/예외를 래퍼 개체에 넣습니다.<br> var output = new ResultWrapper(f);<br>다음을 시도해 보세요.<br>{</p>

  <p style="padding-left: 150px;">출력. Analysis = await Analyze(f);</p>

  <p style="padding-left: 120px;">}<br> catch(Exception e)<br>{</p>

  <p style="padding-left: 150px;">출력 반환;</p>

  <p style="padding-left: 120px;">}</p>

  <p style="padding-left: 90px;">}</p>

  <p style="padding-left: 90px;">작업을 큐에 푸시합니다.<br>taskQueue.Add(analysisTask);</p>

  <p style="padding-left: 60px;">}</p>

  <p style="padding-left: 30px;">}</p>

  <p><br>또한 큐에서 작업을 수행하고 완료되기를 기다리며 결과를 표시하거나 throw된 예외를 발생시키는 소비자 스레드가 있습니다. 큐를 사용하면 시스템의 최대 프레임 속도를 제한하지 않고 결과가 올바른 순서로 한 번에 하나씩 소비되도록 보장할 수 있습니다.</p>

  <h3></h3>

  <h3>샘플 구현</h3>

  <p><br>이 블로그 게시물과 함께 위에서 설명한 시스템의 구현을 사용할 수 있습니다. 이러한 시나리오를 많이 구현할 수 있을 만큼 유연하면서도 사용하기 쉽습니다. 라이브러리에는 웹캠에서 비디오 프레임을 처리하기 위해 앞에서 설명한 생산자-소비자 시스템을 구현하는 FrameGrabber 클래스가 포함되어 있습니다. 사용자가 정확한 형식의 API 호출을 지정할 수 있으며, 새 프레임이 획득되거나 새 분석 결과를 사용할 수 있는 경우 클래스가 이벤트를 사용하여 호출 코드에 알립니다.</p>

  <p><br>몇 가지 가능성을 설명하기 위해 라이브러리를 사용하는 두 개의 샘플 앱도 게시합니다. 첫 번째는 간단한 콘솔 앱이며 이 앱의 간소화된 버전은 아래에 재현됩니다. 기본 웹캠에서 프레임을 잡고 얼굴 감지를 위해 Face API에 제출합니다.</p>

  <p>using System;<br>VideoFrameAnalyzer 사용<br>Microsoft.ProjectOxford.Face 사용<br>Microsoft.ProjectOxford.Face.Contract 사용</p>

  <p>네임스페이스 VideoFrameConsoleApplication<br>{</p>

  <p style="padding-left: 30px;">클래스 프로그램<br> {</p>

  <p style="padding-left: 60px;">static void Main(string[] args)<br> {</p>

  <p style="padding-left: 90px;">분석 유형 Face[]를 사용하여 그래버를 만듭니다. <br> FrameGrabberFace&lt;[]&gt; 그래버 = new FrameGrabberFace&lt;[]&gt;();<br><br> Face API 클라이언트를 만듭니다. 여기에 Face API 키를 삽입합니다.<br> FaceServiceClient faceClient = new FaceServiceClient("&lt;구독 키&gt;");<br><br> Face API 호출을 설정합니다.<br> 그래버. AnalysisFunction = async frame =&gt; return await faceClient.DetectAsync(frame. Image.ToMemoryStream(".jpg"));<br><br> API 호출에서 새 결과를 받을 때 수신기를 설정합니다. <br> 그래버. NewResultAvailable += (s, e) =&gt;<br> {</p>

  <p style="padding-left: 120px;">if(예: Analysis != null)<br> Console.WriteLine("에서 획득한 {0}프레임에 대해 받은 새 결과입니다. {1} face detected", 예: Frame.Metadata.Timestamp, e.Analysis.Length);</p>

  <p style="padding-left: 90px;">};<br><br> 3초마다 Face API를 호출하도록 그래버에게 지시합니다.<br> 그래버. TriggerAnalysisOnInterval(TimeSpan.FromMilliseconds(3000));<br><br> 실행을 시작합니다.<br> 그래버. StartProcessingCameraAsync(). Wait();<br><br> 키 프레스가 중지되기를 기다립니다.<br> Console.WriteLine("중지하려면 아무 키나 누르세요...");<br> Console.ReadKey();<br><br> 중지하고 완료될 때까지 차단합니다.<br> 그래버. StopProcessingAsync(). Wait();</p>

  <p style="padding-left: 60px;">}</p>

  <p style="padding-left: 30px;">}</p>

  <p>}</p>

  <p><br>두 번째 샘플 앱은 좀 더 흥미롭고 비디오 프레임에서 호출할 API를 선택할 수 있습니다. 왼쪽에 앱은 라이브 비디오의 미리 보기를 표시합니다. 오른쪽에는 해당 프레임에 오버레이된 가장 최근의 API 결과가 표시됩니다.</p>

  <p>대부분의 모드에서는 왼쪽의 라이브 비디오와 오른쪽의 시각화된 분석 간에 눈에 띄는 지연이 발생합니다. 이 지연은 API 호출을 수행하는 데 걸리는 시간입니다. 이 규칙의 예외는 "EmotionsWithClientFaceDetect" 모드로, <a href="https://opencv.org/">OpenCVbefore</a>&nbsp;를 사용하여 클라이언트 컴퓨터에서 로컬로 얼굴 감지를 수행하여 모든 이미지를 Cognitive Services에 제출합니다. 이렇게 하면 감지된 얼굴을 즉시 시각화한 다음, 나중에 API 호출이 반환된 후 감정을 업데이트할 수 있습니다. 이는 클라이언트에서 몇 가지 간단한 처리를 수행할 수 있는 "하이브리드" 접근 방식의 가능성을 보여 줍니다. 그런 다음 Cognitive Services API 사용하여 필요한 경우 고급 분석을 통해 이 접근 방식을 보강할 수 있습니다.</p>

  <p><img width="711" height="543" alt="" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/image.png"></p>

  <p>이 게시물이 라이브 비디오 스트림에서 거의 실시간으로 이미지 분석을 수행할 수 있는 가능성과 샘플 코드를 사용하여 시작하는 방법을 제공했으면 합니다. 아래의 의견, <a href="https://cognitive.uservoice.com/">UserVoicesite</a>&nbsp; 또는 샘플 코드의 <a href="https://github.com/Microsoft/Cognitive-Samples-VideoFrameAnalysis/">GitHub</a>&nbsp; repository에서 피드백과 제안을 자유롭게 제공하세요.</p>
