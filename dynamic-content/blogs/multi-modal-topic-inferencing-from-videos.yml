### YamlMime:Yaml
ms.openlocfilehash: b2e4efea40e0023a45b0026ee58c4cbcf8d3ccf1
ms.sourcegitcommit: d03bdc7fe5447adb6530886aab848b75fe8fa8ee
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 03/11/2022
ms.locfileid: "139901585"
Slug: multi-modal-topic-inferencing-from-videos
Title: 비디오에서 다중 모달 토픽 유추
Summary: 대규모 미디어 아카이브가 있는 조직은 미디어 아카이브를 비즈니스 가치로 변환하려면 어떻게 해야 할까요? 미디어 콘텐츠 관리는 어렵기 때문에 대규모 콘텐츠 검색도 마찬가지입니다. 토픽별 콘텐츠 분류는 사람들이 필요한 콘텐츠를 더 쉽게 검색할 수 있도록 하는 직관적인 접근 방식입니다.
Content: >-
  <p>대규모 미디어 아카이브가 있는 조직은 미디어 아카이브를 비즈니스 가치로 &ndash; 어떻게 변환할 수 있을까요? 미디어 콘텐츠 관리는 어렵기 때문에 대규모 콘텐츠 검색도 마찬가지입니다. 토픽별 콘텐츠 분류는 사람들이 필요한 콘텐츠를 더 쉽게 검색할 수 있도록 하는 직관적인 접근 방식입니다. 그러나 콘텐츠 분류는 일반적으로 공제되며 반드시 비디오에 명시적으로 표시되지는 않습니다&rsquo;. 예를 들어 의료&rsquo; 주제에 &lsquo;초점을 맞춘 콘텐츠에는 실제로 의료&rsquo;라는 단어가 &lsquo;표시되지 않을 수 있으므로 분류를 해결하기가 훨씬 더 어려워집니다. 많은 조직에서는 비용이 많이 들고, 시간이 오래 걸리고, 오류가 발생하기 쉬운, 주기적인 큐레이션이 필요하고 확장할 수 없는 콘텐츠에 수동으로 태그를 지정합니다.</p>


  <p>이 프로세스를 훨씬 더 일관되고 효과적이며 비용 및 시간에 따라 만들기 위해 Video Indexer <strong>에서 다중 모달 토픽 유추</strong> 를 소개합니다. 이 새로운 기능은 채널 간 모델을 사용하여 미디어 콘텐츠를 직관적으로 인덱싱하여 자동으로 토픽을 유추할 수 있습니다. 이 모델은 비디오 개념을 <a href="https://iptc.org/standards/media-topics/" target="_blank">IPTC</a>, <a href="https://www.wikipedia.org/" target="_blank">Wikipedia</a> 및 Video Indexer 계층 구조 토픽 온톨로지(아래 자세한 정보 참조)의 세 가지 온톨로지로 프로젝션하여 수행합니다. 이 모델은 Video Indexer <a href="https://azure.microsoft.com/en-us/blog/video-indexer-general-availability-and-beyond/" target="_blank">얼굴 인식</a> 모델을 사용하여 비디오에서 인식되는 전사(음성 단어), <a href="https://azure.microsoft.com/en-us/blog/text-recognition-for-video-in-microsoft-video-indexer/" target="_blank">OCR 콘텐츠</a>(시각적 텍스트) 및 유명인을 사용합니다. 세 가지 신호는 비디오를 볼 때와 마찬가지로 다양한 각도에서 비디오 개념을 캡처합니다.</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/f86e4061-ab98-49d6-954f-2f096ec2093b.png"><img alt="Figure 1 - Topics on Video Indexer portal" border="0" height="495" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/74a47198-2a20-4400-b6a7-db5db8dbda94.png" style="margin: 0px auto; border: 0px currentcolor; border-image: none; float: none; display: block; background-image: none;" title="그림 1 - Video Indexer 포털의 항목" width="779"></a></p>


  <h2>항목 및 키워드</h2>


  <p>Video Indexers&rsquo; 레거시 <strong>키워드 추출</strong> 모델은 대본 및 OCR 텍스트의 중요한 용어를 강조 표시합니다. 추가 값은 알고리즘의 감독되지 않는 특성과 음성 언어 및 전문 용어에 대한 분산에서 비롯됩니다. 기존 키워드 추출 모델과 토픽 유추 모델 간의 주요 차이점은 키워드가 명시적으로 언급된 용어인 반면 항목은 기술 그래프를 사용하여 유사한 감지된 개념을 함께 클러스터링하여 상위 수준의 암시적 개념을 유추한다는 것입니다.</p>


  <h2>예제</h2>


  <p>&rsquo;Microsoft Build 2018 개발자&rsquo; 컨퍼런스의 오프닝 기조 연설을 통해 가까운 장래에 Microsoft의 비전뿐만 아니라 다양한 제품과 기능을 소개해 보겠습니다. Microsoft 리더십의 주요 주제는 AI와 ML 클라우드와 에지에 주입되는 방식이었습니다. 비디오는 수동으로 레이블을 지정하는 데 시간이 걸리는 3시간 반이 넘습니다. Video Indexer에서 인덱싱하고 기술, 웹 개발, Word Embeddings, 서버리스 컴퓨팅, 시작 조언 및 전략, Machine Learning, 빅 데이터, 클라우드 컴퓨팅, Visual Studio Code, 소프트웨어, 회사, 스마트폰, Windows 10, 발명 및 미디어 기술 항목을 생성했습니다.</p>


  <h2>환경</h2>


  <p>빌드 키노트 예제를 계속 진행&rsquo;합니다. 이 항목은 그림 2와 같이 오른쪽의 Video Indexer 포털에서 사용할 수 있으며, 그림 3과 같이 Insights JSON을 사용하는 API를 통해서도 사용할 수 있습니다. 여기서 소프트웨어와&rdquo; 같은 &ldquo;&ldquo;&rdquo; IPTC 항목과 Wikipedia 범주 항목이 나란히 표시됩니다.</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/aa7edbb8-8176-4b59-a4e3-000fde7f7853.png"><img alt="Figure 2- Video Indexer insights with topics on the right" border="0" height="664" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/e5e54e44-b982-4122-8cec-0cd9bebb715a.png" style="margin: 0px auto; border: 0px currentcolor; border-image: none; float: none; display: block; background-image: none;" title="그림 2 - 오른쪽에 토픽이 있는 Video Indexer 인사이트" width="1432"></a></p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/c20fc39d-95c4-4b13-922a-869f87b466c3.png"><img alt="Figure 3- Insights JSON example of all ontologies" border="0" height="358" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/b95530f0-1722-42d9-a8fd-1ebe4915bf3c.png" style="margin: 0px auto; border: 0px currentcolor; border-image: none; float: none; display: block; background-image: none;" title="그림 3- 모든 온톨로지의 JSON 예제 Insights" width="627"></a></p>


  <h2>기본적인 이해</h2>


  <p>Video Indexer의 내부 아래에 적용된 인공 지능 모델은 그림 4에 나와 있습니다. 이 다이어그램은 왼쪽에 표시된 업로드에서 맨 오른쪽에 있는 인사이트까지 미디어 파일의 분석을 나타냅니다. 아래쪽 채널은 여러 컴퓨터 비전 알고리즘인 OCR, 얼굴 인식을 적용합니다. 위에서는 언어 식별 및&rsquo; 음성 텍스트 변환, 키워드 추출과 같은 상위 수준 모델 및 자연어 처리 알고리즘을 기반으로 하는 토픽 유추와 같은 기본 알고리즘에서 시작하는 오디오 채널을 찾을 수 있습니다. 이는 Video Indexer가 여러 소스의 강력하고 독립적인 입력 신호를 사용하여 더 높은 수준의 개념을 유추하기 위해 빌딩 블록 방식으로 여러 AI 모델을 오케스트레이션하는 방법에 대한 강력한 데모입니다.</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/aa500b17-9d72-44b7-8db1-806cbc3adb5a.png"><img alt="Figure 4 - Video Indexer AI models under the hood" border="0" height="743" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/fb0518f4-2838-4ab3-817b-c0210acb7cff.png" style="margin: 0px auto; border: 0px currentcolor; border-image: none; float: none; display: block; background-image: none;" title="그림 4 - 내부 비디오 인덱서 AI 모델" width="1352"></a></p>


  <p>Video Indexer는 두 가지 모델을 적용하여 토픽을 추출합니다. 첫 번째는 큰 전용 데이터 세트를 기반으로 원시 텍스트에서 직접 토픽의 점수를 매기고 순위를 매기는 심층 신경망입니다. 이 모델은 비디오의 대본을 Video Indexer Ontology 및 IPTC와 매핑합니다. 두 번째 모델은 비디오에 언급된 명명된 엔터티에 스펙트럼 그래프 알고리즘을 적용합니다. 이 알고리즘은 비디오에서 인식되는 유명인의 Wikipedia ID와 같은 입력 신호를 취하며, OCR과 같은 신호와 본질적으로 구조화되지 않은 대본이 있는 구조화된 데이터입니다. 텍스트에 언급된 엔터티를 추출하기 위해 ELIS로도 하는 <a href="https://labs.cognitive.microsoft.com/en-us/project-entity-linking" target="_blank">Entity Linking Intelligent Service</a> 를 사용합니다. ELIS는 자유 형식 텍스트로 명명된 엔터티를 인식하므로 이 시점부터 구조화된 데이터를 사용하여 토픽을 가져올 수 있습니다. 나중에 엔터티&rsquo; Wikipedia 페이지의 유사성에 따라 그래프를 빌드하고 비디오 내에서 다양한 개념을 캡처하도록 클러스터링합니다. 마지막 단계에서는 후방 확률에 따라 Wikipedia 범주의 순위를 지정하여 클러스터당 두 가지 예제를 선택하는 좋은 항목이 됩니다. 흐름은 그림 5에 나와 있습니다.</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/7f18d6cc-96e2-4e90-be68-44320509363a.png"><img alt="Figure 5 – Multi-modal topics inference model flow" border="0" height="276" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/bff8a488-2a27-4b34-9fc0-df3deb4263ba.png" style="margin: 0px auto; border: 0px currentcolor; border-image: none; float: none; display: block; background-image: none;" title="그림 5 – 다중 모달 토픽 유추 모델 흐름" width="1388"></a></p>


  <h2>온톨로지</h2>


  <p><em>Wikipedia 범주</em> &ndash; <a href="https://en.wikipedia.org/wiki/Wikipedia:FAQ/Categorization" target="_blank">범주</a> 는 토픽으로 사용할 수 있는 태그입니다. 잘 편집되었으며 170만 개의 범주를 사용하여 이 고해상도 온톨로지의 가치는 아티클 및 기타 범주에 대한 링크가 있는 특이성 및 그래프와 유사한 연결에 있습니다.</p>


  <p><em>Video Indexer 온톨로지</em> &ndash; Video Indexer Ontology는 20,000개 이상의 항목과 최대 깊이가 3개 계층인 독점 계층 온톨로지입니다.</p>


  <p><em>IPTC</em> &ndash; IPTC 온톨로지는 미디어 회사들 사이에서 인기가 있습니다. 이 계층 구조화된 온톨로지 IPTC&#39;NewsCode에서 탐색할 수 있습니다. IPTC 토픽은 IPTC의 첫 번째 수준 계층에서 Video Indexer 온톨로지 토픽의 대부분에 따라 Video Indexer에서 제공됩니다.</p>


  <h2>요점</h2>


  <p>Video Indexers&rsquo; 토픽 모델은 미디어 사용자가 직관적인 방법론을 사용하여 콘텐츠를 분류하고 콘텐츠 검색을 최적화할 수 있도록 합니다. 다중 형식은 비디오에서 높은 수준의 개념을 인식하기 위한 핵심 요소입니다. 감독된 딥 러닝 기반 모델과 감독되지 않은 Wikipedia 지식 그래프를 사용하여 Video Indexer는 미디어 파일 내의 내부 관계를 이해할 수 있으므로 수동 분류보다 정확하고 효율적이며 비용이 저렴한 솔루션을 제공합니다.</p>


  <p>미디어 콘텐츠를 비즈니스 가치로 변환하려면 <a href="https://vi.microsoft.com" target="_blank">Video Indexer</a>를 확인하세요. 과거에 인덱싱된 비디오를 인덱싱한 경우&rsquo; 파일을 다시 인덱싱하여 이 흥미로운 새로운 기능을 경험하는 것이 좋습니다.</p>


  <p>질문이나 의견이 있으신가요? 다른 미디어 온톨로지 사용 및 Video Indexer에서 사용하시겠습니까? Microsoft는 여러분의 의견을 기다리고 있습니다!</p>


  <p>UserVoice를 방문하여 기능의 우선 순위를 지정하거나 질문이 있는 전자 메일 <a href="mailto:VISupport@Microsoft.com" target="_blank">VISupport@Microsoft.com</a> 을 보내주세요.</p>
