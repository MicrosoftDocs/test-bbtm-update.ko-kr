### YamlMime:Yaml
ms.openlocfilehash: ddb9c29e882e7fb1e34cceef25e950a1ac61757f
ms.sourcegitcommit: d03bdc7fe5447adb6530886aab848b75fe8fa8ee
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 03/11/2022
ms.locfileid: "139906026"
Slug: containers-docker-windows-and-trends
Title: '컨테이너: Docker, Windows 및 추세'
Summary: 컨테이너의 정의와 작동 방식의 기본 사항부터 현재 가장 널리 사용되고 있는 시나리오, "컨테이너화"를 지원하는 새로운 추세에 이르기까지, 이 중요한 클라우드 컴퓨팅 개발을 가장 잘 수용하는 방법을 이해하는 데 도움이 되도록 제 관점을 공유할 것이라고 생각했습니다.
Content: >-
  컨테이너에 대해 이야기하지 않고는 최근에 클라우드 컴퓨팅에 대해 논의할 수 없습니다. 은행 및 주요 금융 서비스 회사에서 전자 상거래 사이트에 이르기까지 모든 비즈니스 부문의 조직은 컨테이너가 무엇인지, 클라우드의 애플리케이션에 대해 무엇을 의미하는지, 특정 개발 및 IT 운영 시나리오에 가장 잘 사용하는 방법을 이해하려고 합니다.


  컨테이너의 정의와 작동 방식의 기본 사항부터 현재 가장 널리 사용되고 있는 시나리오, "컨테이너화"를 지원하는 새로운 추세에 이르기까지, 클라우드 애플리케이션을 보다 원활하게 빌드, 테스트, 배포 및 관리하기 위해 이 중요한 클라우드 컴퓨팅 개발을 가장 잘 수용하는 방법을 이해하는 데 도움이 되도록 제 관점을 공유해 보겠습니다.

  <h2>컨테이너 개요</h2>

  추상적인 측면에서 모든 컴퓨팅은 프로세서, 메모리, 디스크, 네트워크 등과 같은 "물리적" 리소스 집합에서 일부 "함수"를 실행하여 1+1과 같은 간단한 수학 계산 또는 Exchange 같은 여러 컴퓨터에 걸쳐 있는 복잡한 애플리케이션 등 작업을 수행합니다. 시간이 지남에 따라 물리적 리소스가 점점 더 강력해짐에 따라 애플리케이션은 물리적 컴퓨터에서 제공하는 리소스의 일부만 활용하지 못하는 경우가 많습니다. 따라서 기본 물리적 하드웨어를 시뮬레이트하기 위해 "가상" 리소스가 생성되어 여러 애플리케이션이 동시에 실행될 수 있습니다. 각 리소스는 동일한 물리적 컴퓨터의 물리적 리소스의 일부를 활용합니다.


  일반적으로 이러한 시뮬레이션 기술을 가상화라고 합니다.많은 사람들이 가상화를 들을 때 가상 머신을 즉시 생각하지만 가상화의 구현은 하나뿐입니다. 모든 범용 운영 체제(OS)에서 구현되는 메커니즘인 가상 메모리는 애플리케이션에 컴퓨터의 메모리가 전용이라는 환상을 제공하고, 심지어 컴퓨터가 사용할 수 있는 것보다 훨씬 더 많은 RAM에 액세스할 수 있는 환경을 애플리케이션에 제공할 수도 있습니다.


  컨테이너는 OS 가상화라고도 하는 또 다른 유형의 가상화입니다. 오늘날 Linux의 컨테이너는 애플리케이션에 완전히 격리되고 독립적인 OS에 대한 인식을 만듭니다. 실행 중인 컨테이너에 대해 로컬 디스크는 OS 파일의 깨끗한 복사본처럼 보이고, 메모리는 새로 부팅된 OS의 파일 및 데이터를 보관하는 것으로만 표시되며, 유일하게 실행되는 것은 OS입니다. 이를 위해 컨테이너를 만드는 "호스트" 컴퓨터는 몇 가지 영리한 작업을 수행합니다.


  첫 번째 기술은 네임스페이스 격리입니다. 네임스페이스에는 파일, 네트워크 포트 및 실행 중인 프로세스 목록을 포함하여 애플리케이션이 상호 작용할 수 있는 모든 리소스가 포함됩니다. 네임스페이스 격리를 통해 호스트는 각 컨테이너에 표시되어야 하는 리소스만 포함하는 가상화된 네임스페이스를 제공할 수 있습니다. 이 제한된 보기를 사용하면 컨테이너는 단순히 볼 수 없으므로 권한에 관계없이 가상화된 네임스페이스에 포함되지 않은 파일에 액세스할 수 없습니다. 또한 컨테이너의 일부가 아닌 애플리케이션을 나열하거나 상호 작용할 수 없으며, 수십 또는 수백 개의 다른 애플리케이션이 있을 때 시스템에서 실행되는 유일한 애플리케이션이라고 믿게 됩니다.


  효율성을 위해 많은 OS 파일, 디렉터리 및 실행 중인 서비스가 컨테이너 간에 공유되고 각 컨테이너의 네임스페이스에 프로젝토리됩니다. 애플리케이션이 기존 파일을 수정하거나 새 파일을 만드는 경우와 같이 컨테이너를 변경하는 경우에만 컨테이너는 기본 호스트 OS에서 고유한 복사본을 가져올 수 있지만 Docker의 "쓰기 중 복사" 최적화를 사용하여 해당 부분만 변경됩니다.이 공유는 단일 호스트에 여러 컨테이너를 매우 효율적으로 배포하는 과정의 일부입니다.


  둘째, 호스트는 컨테이너에서 사용할 수 있는 호스트 리소스의 양을 제어합니다. CPU, RAM 및 네트워크 대역폭과 같은 리소스를 관리하면 컨테이너가 예상하는 리소스를 가져오고 호스트에서 실행되는 다른 컨테이너의 성능에 영향을 주지 않습니다. 예를 들어 CPU의 10% 이상을 사용할 수 없도록 컨테이너를 제한할 수 있습니다. 즉, 애플리케이션 내의 애플리케이션이 시도하더라도 호스트가 다른 컨테이너 또는 자체 용도로 할당할 수 있는 다른 90%에 액세스할 수 없습니다. Linux는 "cgroups"라는 기술을 사용하여 이러한 거버넌스를 구현합니다. 동일한 호스트에 배치된 컨테이너가 협조적이면 리소스 거버넌스가 필요하지 않으므로 애플리케이션 코드의 변화하는 요구에 맞게 조정되는 표준 OS 동적 리소스 할당을 허용합니다.


  OS 가상화에서 제공되는 즉각적인 시작과 네임스페이스 격리 및 리소스 거버넌스에서 제공되는 안정적인 실행의 조합은 컨테이너를 애플리케이션 개발 및 테스트에 적합하게 만듭니다. 개발 프로세스 중에 개발자는 신속하게 반복할 수 있습니다. 환경 및 리소스 사용량은 시스템 간에 일관되므로 개발자 시스템에서 작동하는 컨테이너화된 애플리케이션은 다른 프로덕션 시스템에서도 동일한 방식으로 작동합니다. 애플리케이션은 빠르게 확장할 수 있고 더 많은 애플리케이션 인스턴스가 VM에 있는 경우보다 더 많은 애플리케이션 인스턴스가 컴퓨터에 적합하여 리소스 사용률을 최대화할 수 있으므로 빠른 시작 및 작은 공간도 클라우드 시나리오에 유용합니다.


  가상 머신을 사용하는 유사한 시나리오와 컨테이너를 사용하는 시나리오를 비교하면 공유에서 얻은 효율성이 강조 표시됩니다. 아래 예제에서 호스트 컴퓨터에는 3개의 VM이 있습니다. VM에서 애플리케이션을 완전히 격리하기 위해 각각 OS 파일, 라이브러리 및 애플리케이션 코드의 자체 복사본과 OS의 전체 메모리 내 인스턴스가 있습니다. 새 VM을 시작하려면 호스트 또는 기존 VM에 동일한 버전의 인스턴스가 이미 실행 중인 경우에도 OS의 다른 인스턴스를 부팅하고 애플리케이션 라이브러리를 메모리에 로드해야 합니다. 각 애플리케이션 VM은 자체 프라이빗 복사본에 대한 OS 부팅 및 메모리 내 공간 비용을 지불하므로 호스트에서 실행할 수 있는 VM(애플리케이션 인스턴스) 수도 제한됩니다.


  <a href="https://acom.azurecomcdn.net/80C57D/blogmedia/blogmedia/2015/08/17/App-Instances-on-Host.png"><img style="background-image: none; float: none; padding-top: 0px; padding-left: 0px; margin-left: auto; display: block; padding-right: 0px; margin-right: auto; border: 0px;" title="호스트의 앱 인스턴스" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/App-Instances-on-Host_thumb.png" alt="App Instances on Host" width="640" height="324" border="0" /></a>


  아래 그림에서는 컨테이너와 동일한 시나리오를 보여 줍니다. 여기서 컨테이너는 커널 및 라이브러리를 포함하여 호스트 운영 체제를 공유하므로 OS를 부팅하거나 라이브러리를 로드하거나 해당 파일에 대한 프라이빗 메모리 비용을 지불할 필요가 없습니다. 애플리케이션이 컨테이너에서 실행되는 데 필요한 메모리 및 디스크 공간만 사용됩니다. 애플리케이션의 환경은 전용 OS처럼 느껴지지만 애플리케이션은 전용 호스트에 배포하는 것처럼 배포됩니다. 컨테이너화된 애플리케이션은 몇 초 안에 시작되며 VM 사례보다 더 많은 애플리케이션 인스턴스가 컴퓨터에 적합할 수 있습니다.


  <a href="https://acom.azurecomcdn.net/80C57D/blogmedia/blogmedia/2015/08/17/Containers-on-Host.png"><img style="background-image: none; float: none; padding-top: 0px; padding-left: 0px; margin-left: auto; display: block; padding-right: 0px; margin-right: auto; border: 0px;" title="호스트의 컨테이너" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/Containers-on-Host_thumb.png" alt="Containers on Host" width="640" height="260" border="0" /></a>

  <h2>Docker의 호소</h2>

  OS와 관련된 네임스페이스 격리 및 리소스 거버넌스의 개념은 BSD 감옥, Solaris 영역 및 기본 UNIX 루트 변경(루트 변경) 메커니즘으로 돌아가는 오랜 시간 동안 사용되어 왔습니다. 그러나 일반적인 도구 집합, 패키징 모델 및 배포 메커니즘을 만들어 Docker는 모든 Linux 호스트에서 실행할 수 있는 애플리케이션의 컨테이너화 및 배포를 크게 간소화했습니다. 이렇게 어디에서나 사용 가능한 기술은 모든 호스트에서 동일한 관리 명령을 제공함으로써 관리를 간소화할 뿐 아니라 원할한 DevOps를 위한 고유한 기회를 창출합니다.


  개발자의 데스크톱에서 테스트 컴퓨터와 여러 프러덕션 컴퓨터에 이르기까지, 몇 초 만에 모든 환경 전체에 동일하게 배포되는 Docker 이미지를 만들 수 있습니다. 이 덕분에 Docker가 관리하는 컨테이너화된 공개 애플리케이션 레지스트리인 DockerHub를 통해, Docker 컨테이너 안에 패키징된 애플리케이션의 거대한 생태계가 탄생했으며 지속적으로 확장되고 있습니다. 현재 공개 커뮤니티 리포지토리에 180,000개 이상의 애플리케이션이 게시되어 있습니다.또한 패키징 형식이 보편적으로 유지되도록 하기 위해 Docker는 최근 OCI(Open Container Initiative)를 조직하여 컨테이너 패키징이 오픈 및 파운데이션 주도 형식으로 유지되도록 하기 위해 Microsoft를 창립 멤버 중 하나로 지정했습니다.

  <h2>Windows 서버 및 컨테이너</h2>

  모든 개발자에게 컨테이너의 기능을 제공하기 위해 지난 10월 Windows Server에서 컨테이너 기술을 구현할 계획을 발표했습니다. Windows Server에서 정확히 동일한 환경의 Linux Docker 컨테이너를 사용하는 개발자를 위해 Docker와의 파트너십을 발표하여 Windows 서버 컨테이너를 지원하기 위해 Docker API 및 도구 집합을 확장했습니다. 이는 Linux와 Windows 모두의 모든 고객에게 혜택을 줄 수 있는 기회였습니다. 최근에 <a href="https://www.youtube.com/watch?v=8vSPpPSd00w#t=1h16m07s">DockerCon</a>에서 설명한 것처럼 개발자와 시스템 관리자가 Windows Server 및 Linux로 구성된 컨테이너화된 애플리케이션을 배포할 수 있는 통합된 개방형 환경을 만들게 되어 기쁩니다. 오픈 <a href="https://github.com/docker/docker">Docker GitHub 리포지토리</a>에서 개발 중입니다.


  Windows Server 2016 Docker API와 Docker 클라이언트를 사용하여 배포할 수 있는 두 가지 버전의 컨테이너인 Windows 서버 컨테이너 및 Hyper-V 컨테이너를 릴리스할 예정입니다. Linux 컨테이너에는 호스트 커널의 Linux API가 필요하고 Windows 서버 컨테이너에는 호스트 Windows 커널의 Windows API가 필요하므로 Windows Server 호스트 또는 Linux 호스트의 Windows 서버 컨테이너에서 Linux 컨테이너를 실행할 수 없습니다. 그러나 동일한 Docker 클라이언트는 이러한 모든 컨테이너를 관리할 수 있으며 Linux에서 패키지된 Windows 컨테이너를 실행할 수는 없지만 Windows 컨테이너 패키지는 Windows 커널을 활용하기 때문에 Windows 서버 컨테이너 및 Hyper-V 컨테이너에서 작동합니다.


  Windows 서버 컨테이너와 Hyper-V 컨테이너를 언제 사용할 것인지에 대한 질문이 있습니다. 커널을 공유하면 빠른 시작 및 효율적인 압축이 가능하지만 Windows 서버 컨테이너는 호스트와 OS를 서로 공유합니다. 공유 데이터 및 API의 양은 애플리케이션이 컨테이너에서 이스케이프하거나 호스트 또는 다른 컨테이너에 대한 서비스를 거부할 수 있도록 설계 또는 네임스페이스 격리 또는 리소스 거버넌스의 구현 결함으로 인해 방법이 있을 수 있음을 의미합니다. 운영 체제 공급업체가 패치하는 권한 취약성의 로컬 권한 상승은 애플리케이션이 활용할 수 있는 결함의 예입니다.


  따라서 Windows 서버 컨테이너는 OS가 호스트될 애플리케이션을 신뢰하고 모든 애플리케이션도 서로 신뢰하는 시나리오에 적합합니다. 즉, 호스트 OS 및 애플리케이션은 동일한 신뢰 경계 내에 있습니다. 이는 많은 다중 컨테이너 애플리케이션, 더 큰 애플리케이션의 공유 서비스를 구성하는 애플리케이션 및 경우에 따라 동일한 조직의 애플리케이션에 적용됩니다.


  그러나 동일한 호스트의 서로 다른 신뢰 경계에서 애플리케이션을 실행하려는 경우가 있습니다. 한 가지 예는 고객이 자신의 코드를 제공하여 서비스의 기능을 확장할 수 있도록 허용하는 다중 테넌트 PaaS 또는 SaaS 제품을 구현하는 경우입니다. 한 고객의 코드가 서비스를 방해하거나 다른 고객의 데이터에 액세스하는 것을 원하지 않지만, VM보다 민첩하고 Docker 에코시스템을 활용하는 컨테이너가 필요합니다. Azure에는 Azure Automation 및 Machine Learning 같은 이러한 서비스의 몇 가지 예가 있습니다. 우리는 의도적으로 고립을 파괴하고자하는 고객이 있다고 가정해야하기 때문에 그들이 "적대적인 다중 테넌트"에서 실행되는 환경을 호출합니다. 이러한 유형의 환경에서는 Windows 서버 컨테이너의 격리가 충분한 보증을 제공하지 못할 수 있으며, 이로 인해 Hyper-V 컨테이너가 개발되었습니다.


  Hyper-V 컨테이너는 컨테이너화에 대해 약간 다른 접근 방식을 사용합니다. 더 많은 격리를 만들기 위해 Hyper-V 컨테이너는 각각 Windows 커널의 자체 복사본을 가지고 있으며 강력한 격리의 핵심 요구 사항인 메모리를 직접 할당합니다. CPU, 메모리 및 IO 격리(예: 네트워크 및 스토리지)에 Hyper-V를 사용하여 VM에 있는 동일한 수준의 격리를 제공합니다. VM과 마찬가지로 호스트는 호스트 리소스의 통신 및 공유를 위해 컨테이너에 제한된 작은 인터페이스만 노출합니다. 이 매우 제한된 공유는 Hyper-V 컨테이너의 시작 시간과 밀도가 Windows 서버 컨테이너보다 효율성이 약간 낮지만 신뢰할 수 없는 "적대적인 다중 테넌트" 애플리케이션이 동일한 호스트에서 실행되도록 허용하는 데 필요한 격리를 의미합니다.


  그렇다면 Hyper-V 컨테이너는 VM과 동일하지 않나요? 물리적 컴퓨터가 아닌 컨테이너에 있다는 사실을 완전히 인식하게 된 OS에 대한 최적화 외에도 Hyper-V 컨테이너는 Docker의 마법을 사용하여 배포되고 Windows Server 컨테이너에서 실행되는 것과 똑같은 패키지를 사용할 수 있습니다. 따라서 격리 수준과 효율성/민첩성의 절충은 개발 시간 결정이 아니라 호스트 소유자가 내린 배포 시간 결정입니다.

  <h2>오케스트레이션</h2>

  컨테이너를 채택하면서 고객은 문제를 발견했습니다. 애플리케이션을 구성하는 수십, 수백 또는 수천 개의 컨테이너를 배포하는 경우 배포를 추적하고 관리하려면 관리와 오케스트레이션 모두에서 발전해야 합니다. 컨테이너 오케스트레이션은 여러 옵션과 솔루션을 갖춘 흥미로운 새로운 혁신 영역이 되었습니다. 컨테이너 오케스트레이터에는 일반적으로 "클러스터"라고 하는 서버 풀(VM 또는 운영 체제 미설치 서버)과 해당 서버에 컨테이너의 "일정" 배포가 할당됩니다. 일부 오케스트레이터는 더 나아가 서로 다른 서버의 컨테이너 간에 네트워킹을 구성하고 일부는 부하 분산, 컨테이너 이름 확인, 롤링 업데이트 등을 포함합니다. 일부는 확장 가능하며 애플리케이션 프레임워크가 이러한 추가 기능을 가져올 수 있도록 합니다.


  오케스트레이션 솔루션에 대한 심층적인 논의를 위해서는 자체적으로 다른 전체 게시물이 필요할 수 있지만, 다음은 Azure에서 지원되는 몇 가지 기술에 대한 간략한 개요입니다.

  <ol>
   <li><a href="https://www.docker.com/docker-compose">Docker Compose</a> 를 사용하면 간단한 다중 컨테이너 애플리케이션을 정의할 수 있습니다. <a href="https://www.docker.com/docker-swarm">Docker Swarm</a> 은 단일 Docker 호스트에서 사용하는 것과 동일한 API를 통해 여러 호스트에서 Docker 컨테이너를 관리하고 구성합니다. <a href="https://azure.microsoft.com/blog/2015/02/26/sunny-and-swarmy-in-azure">Swarm과 Compose가 함께 모여 Docker에서 빌드한 완전한 오케스트레이션 기술을 제공합니다</a>.</li>
   <li><a href="https://mesos.apache.org/">Mesos</a> 는 실제로 Docker보다 이전의 오케스트레이션 및 관리 솔루션이지만, 최근에는 기본 제공 애플리케이션 프레임워크 Marathon에 Docker에 대한 지원을 추가했습니다. <a href="https://mesosphere.com/">Mesosphere</a>에서 구축한 개방형 커뮤니티 기반 솔루션입니다. 최근에 <a href="https://mesosphere.com/blog/2015/04/29/mesosphere-dcos-debuts-on-microsoft-azure/">Azure에서 Mesos 및 DCOS</a>와의 통합을 보여 주었습니다.</li>
   <li><a href="https://kubernetes.io/">Kubernetes</a> 는 여러 호스트에서 관리하기 위해 "Pod"로 그룹화되는 컨테이너를 제공하는 Google에서 빌드한 오픈 소스 솔루션입니다. <a href="https://azure.microsoft.com/blog/2014/07/10/azure-collaboration-with-google-and-docker/">Azure에서도 지원됩니다</a>.</li>
   <li><a href="https://deis.com/">Deis</a> 는 Docker와 통합된 애플리케이션을 배포하고 관리하는 오픈 소스 PaaS 플랫폼입니다. <a href="https://azure.microsoft.com/en-us/documentation/articles/virtual-machines-deis-cluster/">Azure에서 Deis 클러스터를 쉽게 배포할 수 있습니다</a>.</li>
  </ol>

  대부분의 인기 있는 오케스트레이션 솔루션에 대해 Azure에서 지원을 받을 수 있게 되어 기쁘게 생각하고 시간이 지남에 따라 관심과 사용량이 증가함에 따라 이러한 커뮤니티에 더 많은 참여를 기대합니다.

  <h2>마이크로 서비스</h2>

  컨테이너에 대한 즉시 수익성이 높은 사용량은 클라우드 또는 온-프레미스에 배포된 서비스에 대한 프로덕션 흐름을 테스트하기 쉬운 개발자와 함께 DevOps 간소화하는 데 중점을 두고 있습니다. 그러나 컨테이너가 매우 매력적으로 변하는 또 다른 시나리오가 있습니다. 마이크로 서비스는 애플리케이션의 모든 부분이 개별적으로 크기 조정 및 업데이트될 수 있는 마이크로 서비스라고 하는 완전 자체 포함 구성 요소로 배포되는 애플리케이션 개발에 대한 접근 방식입니다. 예를 들어 공용 인터넷에서 요청을 수신하는 애플리케이션의 하위 시스템은 백 엔드 하위 시스템이 요청을 읽고 데이터베이스에 삭제하기 위해 요청을 큐에 배치하는 하위 시스템과 분리될 수 있습니다. 마이크로 서비스를 사용하여 애플리케이션을 생성할 때 각 하위 시스템은 마이크로 서비스입니다. 단일 상자의 개발/테스트 환경에서 마이크로 서비스에는 각각 하나의 인스턴스가 있을 수 있지만 프로덕션 환경에서 실행될 때 고객 요청 수준이 상승하고 감소함에 따라 리소스 수요에 따라 서버 클러스터에서 서로 다른 인스턴스 수로 스케일 아웃할 수 있습니다. 다른 팀에서 인스턴스를 생성하는 경우 또 다른 팀에서 독립적으로 업데이트할 수도 있습니다.


  마이크로 서비스는 프로그래밍에 대한 새로운 접근 방식이 아니며 컨테이너에 명시적으로 연결되지는 않지만 복잡한 마이크로 서비스 기반 애플리케이션에 적용하면 Docker 컨테이너의 이점이 확대됩니다. 민첩성은 증가하는 부하를 충족하기 위해 마이크로 서비스를 신속하게 확장할 수 있고, 컨테이너의 네임스페이스 및 리소스 격리로 인해 한 마이크로 서비스 인스턴스가 다른 마이크로 서비스 인스턴스를 방해하지 않도록 방지하고, Docker 패키징 형식 및 API를 사용하여 마이크로 서비스 개발자 및 애플리케이션 운영자를 위한 Docker 에코시스템의 잠금을 해제할 수 있음을 의미합니다. 좋은 마이크로 서비스 아키텍처를 통해 고객은 높은 민첩성을 유지하면서 가용성 손실 위험을 줄여 컨테이너 기반 서비스의 관리, 배포, 오케스트레이션 및 패치 요구를 해결할 수 있습니다.


  현재 마이크로 서비스를 사용하여 애플리케이션 모델을 빌드하기 위한 몇 가지 솔루션이 있으며, Azure에서 많은 솔루션과 협력하고 있습니다. Docker Compose와 Mesosphere Marathon은 두 가지 예입니다. //build 직전에 Microsoft는 자체 마이크로 서비스 애플리케이션 플랫폼인 Service Fabric 개발자 미리 보기를 <a href="https://azure.microsoft.com/blog/2015/04/20/announcing-azure-service-fabric-reducing-complexity-in-a-hyper-scale-world/">발표</a>했습니다. 여기에는 롤백, 분할, 배치 제약 조건 등을 포함한 다양한 마이크로 서비스 수명 주기 관리 기능이 포함되어 있습니다. 특히 상태 비국적 마이크로 서비스 외에도 마이크로 서비스가 동일한 서버에서 함께 상주하는 데이터를 관리한다는 사실로 구분되는 상태 저장 마이크로 서비스를 지원합니다. 실제로 Service Fabric 상태 관리 및 복제 프레임워크가 클러스터 관리에 직접 구축된 상태 저장 마이크로 서비스를 제공하는 유일한 PaaS 플랫폼입니다. 내부 서비스가 상태 저장 복제를 사용하여 하이퍼스케일로 확장할 수 있도록 이 애플리케이션 모델을 개발했으며, Cortana, Azure SQL Database 및 비즈니스용 Skype 같은 서비스가 빌드됩니다. 올해 하반기에 Service Fabric 공개 미리 보기를 발표할 예정이지만, 그 동안 <a href="https://azure.microsoft.com/en-us/documentation/articles/service-fabric-overview/">여기에서</a> Service Fabric 자세히 확인할 수 있습니다.


  위의 설명은 Microsoft의 컨테이너 비전, 가장 일반적인 컨테이너 사용 사례 및 컨테이너와 관련된 새로운 업계 동향의 유용한 그림을 그리는 데 도움이 되기를 바랍니다. 언제나 그렇듯이, 특히 더 많은 것을 배우고 싶은 영역이 있다면 여러분의 피드백을 좋아할 것입니다.
