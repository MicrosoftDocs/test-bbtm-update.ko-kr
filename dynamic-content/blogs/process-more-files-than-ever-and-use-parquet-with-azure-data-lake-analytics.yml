### YamlMime:Yaml
ms.openlocfilehash: 1c985135d805bda6e67cb72e8976145bd9b9a7ad
ms.sourcegitcommit: d03bdc7fe5447adb6530886aab848b75fe8fa8ee
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 03/11/2022
ms.locfileid: "139902015"
Slug: process-more-files-than-ever-and-use-parquet-with-azure-data-lake-analytics
Title: 그 어느 때보다 많은 파일을 처리하고 parquet를 사용하여 Azure Data Lake Analytics
Summary: Azure Data Lake Analytics(ADLA)는 Azure Data Lake Store 또는 Azure Blob Storage 저장된 대량의 데이터를 비교할 수 없는 규모로 준비하고 변환하는 Azure의 서버리스 PaaS 서비스입니다. ADLA 이제 Parquet를 비롯한 모든 형식의 파일을 엄청난 규모로 처리하기 위한 몇 가지 새롭고 비교할 수 없는 기능을 제공합니다.
Content: >-
  <p><a href="https://azure.microsoft.com/en-us/services/data-lake-analytics/">Azure Data Lake Analytics</a>(ADLA)는 Azure <a href="https://azure.microsoft.com/en-us/services/data-lake-store/">Data Lake Store</a> 또는 Azure <a href="https://azure.microsoft.com/en-us/services/storage/blobs/">Blob</a> Storage 저장된 대량의 데이터를 비교할 수 없는 규모로 준비하고 변환하는 Azure의 서버리스 PaaS 서비스입니다.</p>


  <p>ADLA 이제 Parquet를 비롯한 모든 형식의 파일을 엄청난 규모로 처리하기 위한 몇 가지 새롭고 비교할 수 없는 기능을 제공합니다.</p>


  <h2>이전에는 수만 개의 파일을 처리하는 것이 고통스러웠습니다.</h2>


  <p>많은 고객이 시도한 모든 빅 데이터 시스템에서 매우 고통스럽지 않다면 많은 수의 파일을 처리하는 것이 어렵다 &ndash; 고 말합니다. 그림 1은 공통 데이터 레이크 시스템의 파일 분포를 보여 냅니다. 대부분의 파일은 1GB 미만이지만 일부 파일은 거대할 수 있습니다.</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/7ec46113-70a0-4f91-af24-99d6fe630156.png"><img alt="1636-1" border="0" height="790" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/7fc2cd74-63e8-495a-94a0-da6b68aec79c.png" style="margin: 0px auto; border: 0px currentcolor; border-image: none; float: none; display: block; background-image: none;" title="1636-1" width="1932"></a></p>


  <p style="text-align: center;"><em>그림 1: 많은 작은 파일의 고통</em></p>


  <p>ADLA 원래 스케일 아웃에 도움이 되는 내부 구조가 있는 매우 큰 파일에서 작동하도록 설계된 시스템에서 개발되었지만 수백~약 3,000개의 파일에서만 작동했습니다. 또한 파일에 하나의 추출 꼭짓점을 제공하여 작은 파일을 처리할 때 리소스를 과도하게 할당합니다(꼭짓점은 데이터 파티션에서 스크립트의 특정 부분을 실행하고 만들고 삭제하는 데 시간이 걸리는 컴퓨팅 컨테이너임). 따라서 다른 분석 엔진과 마찬가지로 많은 작은 파일의 일반적인 사례를 처리할 수 있는 기능이 제대로 갖추어져 있지 않았습니다.</p>


  <h2>단일 U-SQL 작업에서 수십만 개의 파일을 처리합니다.</h2>


  <p>최근 릴리스에서 ADLA 다양한 형식의 대량 파일을 다음 단계로 처리하는 기능을 사용합니다.<br>

  &nbsp;&nbsp; <a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/43b04d9f-86a6-4568-a961-d89d97393ce8.png"><img alt="1636-2" border="0" height="644" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/3594573f-3a13-401b-9120-d0c7767851fb.png" style="margin: 0px auto; border: 0px currentcolor; border-image: none; float: none; display: block; background-image: none;" title="1636-2" width="1612"></a></p>


  <p style="text-align: center;"><em>그림 2: 많은 작은 파일의 처리 개선</em></p>


  <p>ADLA 크기 제한을 늘려 소위 파일 집합을 사용하여 단일 U-SQL 작업에서 <a href="https://github.com/Azure/AzureDataLake/blob/master/docs/Release_Notes/2018/2018_Spring/USQL_Release_Notes_2018_Spring.md#input-file-set-scales-orders-of-magnitudes-better-finally-released">수십만 개의 파일을 스키마화하고 처리</a>합니다. 또한 최대 1GB의 데이터를 가진 최대 200개의 파일을 단일 꼭짓점(미리 보기)으로 그룹화하여 <a href="https://github.com/Azure/AzureDataLake/blob/master/docs/Release_Notes/2018/2018_Spring/USQL_Release_Notes_2018_Spring.md#input-file-set-uses-less-resources-when-operating-on-many-small-files-is-in-public-preview">많은 작은 파일의 처리를 개선</a> 했습니다(그림 2 참조). 추출기는 한 번에 하나의 파일을 처리하지만 이제는 꼭짓점 생성이 더 많은 데이터에서 분할 상환되고 시스템은 추출 단계에서 훨씬 적은 리소스(분석 단위)를 사용하고 비용이 적게 듭니다.</p>


  <p>그림 3은 작업이 꼭짓점을 만드는 데 약 5초가 소요된 후 1초 이내에 데이터를 처리하고 더 많은 꼭짓점을 사용하는 방법을 왼쪽에 보여줍니다. 오른쪽 이미지에서 향상된 파일 집합 처리를 통해 훨씬 적은 수의 리소스(AU)를 사용할 수 있었고 할당된 리소스를 더 잘 사용할 수 있었습니다.</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/d296d0c7-36ab-47f6-ae0f-b59949f2fab5.png"><img alt="1636-3" border="0" height="386" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/cc52e2f4-74f4-486f-9b19-c4ae3eb240f1.png" style="margin: 0px auto; border: 0px currentcolor; border-image: none; float: none; display: block; background-image: none;" title="1636-3" width="1484"></a></p>


  <p style="text-align: center;"><br>

  <em>그림 3: 여러 작은 파일에서 추출할 때 작업 꼭짓점 사용: 파일 그룹화 없음 및 파일 그룹화 사용</em></p>


  <p>이러한 파일 집합을 사용하는 고객은 작업에서 성능이 최대 10배 향상되어 비용이 훨씬 절감되고 단일 작업에서 더 많은 파일을 처리할 수 있습니다.</p>


  <p>시스템이 대용량 파일로 계속 개선되기 때문에 처리할 파일의 크기를 최대화하는 것이 좋습니다.</p>


  <h2>게다가 오늘, ADLA 이제 기본적으로 Parquet 파일을 지원합니다.</h2>


  <p>U-SQL 파일 및 출력자를 스키마화하여 파일에 데이터를 다시 쓸 수 있는 기본 제공 네이티브 추출기와 사용자가 자체 추출기를 추가할 수 있는 기능을 모두 제공합니다. 이 최신 릴리스에서 ADLA <a href="https://github.com/Azure/AzureDataLake/blob/master/docs/Release_Notes/2018/2018_Spring/USQL_Release_Notes_2018_Spring.md#built-in-parquet-extractor-and-outputter-is-in-public-preview">인기 있는 Parquet 파일 형식에 대한 네이티브 추출기 및 출력기의</a> 공개 미리 보기와 &ldquo;ORC용 프라이빗&rdquo; 미리 보기를 추가하여 이러한 인기 있는 데이터 형식을 대규모로 쉽게 사용하고 생성할 수 있도록 합니다. 이렇게 하면 이전에 CSV 형식을 사용하는 것보다 HDInsights&rsquo; Hive LLAP 및 Azure DataBricks와 같은 오픈 소스 빅 데이터 분석 솔루션과 데이터를 보다 효율적으로 교환할 수 있습니다.</p>


  <p><a href="https://blogs.msdn.microsoft.com/azuredatalake">Azure Data Lake 블로그</a>로 이동하여 3TB 파일을 10,000개의 Parquet 파일로 요리한 다음 U-SQL 새 파일 집합 확장성으로 처리하고 Azure Databricks&rsquo; Spark를 사용하여 쿼리하는 방법에 대한 엔드투엔드 예제를 확인하세요.</p>


  <h2>하지만 기다려, 더 있다&rsquo;!</h2>


  <p>동적으로 분할된 파일 생성 미리 보기(사용자 음성 맨 위 요청!) <a href="https://github.com/Azure/AzureDataLake/blob/master/docs/Release_Notes/2018/2018_Spring/USQL_Release_Notes_2018_Spring.md#adl-tools-for-visualstudio-provides-an-improved-analytics-unit-modeler-to-help-improve-a-jobs-performance-and-cost">작업 비용/성능 절차를 최적화하는 새로운 AU 모델러</a>, <a href="https://github.com/Azure/AzureDataLake/blob/master/docs/Release_Notes/2018/2018_Spring/USQL_Release_Notes_2018_Spring.md#built-in-textcsvtsv-extractors-and-outputters-support-ansiwindows-8-bit-codepage-encodings">Windows 코드 페이지를 사용하는 파일에서 추출</a>하는 기능, <a href="https://github.com/Azure/AzureDataLake/blob/master/docs/Release_Notes/2018/2018_Spring/USQL_Release_Notes_2018_Spring.md#u-sql-adds-job-information-system-variable-jobinfo">작업 정보@JobInfo로 스크립트를 보강</a>하는 기능, 가벼운 가중치 등과 같은&nbsp; 새로운 기능이 많이 추가되었습니다.  <a href="https://github.com/Azure/AzureDataLake/blob/master/docs/Release_Notes/2018/2018_Spring/USQL_Release_Notes_2018_Spring.md#u-sql-adds-c-func-typed-variables-in-declare-statements-named-lambdas">람다라는 이름의 스크립트 내 C#</a>과 <a href="https://github.com/Azure/AzureDataLake/blob/master/docs/Release_Notes/2018/2018_Spring/USQL_Release_Notes_2018_Spring.md#u-sql-adds-temporary-script-bound-meta-data-objects-with-declare-statements">스크립트 범위의 U-SQL 개체</a>를 사용하여 자체 포함된 스크립트 개발 <a href="https://github.com/Azure/AzureDataLake/blob/master/docs/Release_Notes/2018/2018_Spring/USQL_Release_Notes_2018_Spring.md">봄 릴리스 정보</a>로 이동하여 새로 도입된 모든 기능을 확인합니다.</p>
