### YamlMime:Yaml
ms.openlocfilehash: e04d34529ea8befd66a326cd73ee8dc9b4de91bf
ms.sourcegitcommit: d03bdc7fe5447adb6530886aab848b75fe8fa8ee
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 03/11/2022
ms.locfileid: "139911873"
Slug: gpus-vs-cpus-for-deployment-of-deep-learning-models
Title: 딥 러닝 모델 배포를 위한 GPU 및 CPU
Summary: 딥 러닝 작업에 적합한 유형의 하드웨어를 선택하는 것은 널리 설명된 항목입니다. 명백한 결론은 의사 결정은 처리량 요구 사항 및 비용과 같은 요인에 따라 현재 작업에 따라 달라야한다는 것입니다.
Content: >-
  <p><em>이 블로그 게시물은 Azure CAT의 수석 데이터 과학자인 매튜 살바리스(Mathew Salvaris)와 Azure CAT의 수석 소프트웨어 엔지니어인 Daniel Grecoe가 공동 저술했습니다.</em></p>


  <p>딥 러닝 작업에 적합한 유형의 하드웨어를 선택하는 것은 널리 설명된 항목입니다. 명백한 결론은 의사 결정은 처리량 요구 사항 및 비용과 같은 요인에 따라 현재 작업에 따라 달라야한다는 것입니다. 딥 러닝 학습의 경우 CPU와 비교할 때 상당한 속도로 GPU를 사용해야 합니다. 그러나 높은 비용으로 인해 학습만큼 리소스가 무겁지 않은 유추와 같은 작업의 경우 일반적으로 CPU가 충분하고 비용 절감으로 인해 더 매력적이라고 생각됩니다. 그러나 유추 속도가 병목 상태인 경우 GPU를 사용하면 재무 및 시간 관점에서 상당한 이익을 얻을 수 있습니다. GPU를 사용하여 <a href="https://blogs.technet.microsoft.com/machinelearning/2018/04/19/deploying-deep-learning-models-on-kubernetes-with-gpus/" target="_blank">Kubernetes에 심층 Learning 모델을 배포하는</a> 이전 <a href="https://github.com/Microsoft/AKSDeploymentTutorial" target="_blank">자습서</a> 및 블로그에서는 미리 학습된 나선형 신경망 모델 로드에서 <a href="https://azure.microsoft.com/en-us/services/container-service/" target="_blank">AKS(Azure Container Service)</a>를 사용하여 GPU가 있는 <a href="https://kubernetes.io/" target="_blank">Kubernetes</a> 클러스터에 호스트되는 컨테이너화된 웹 애플리케이션 만들기에 이르는 단계별 지침을 제공합니다.</p>


  <p>이 이전 작업을 확장하여 후속 분석으로, 여기서는 GPU와 CPU 배포의 처리량 성능에서 눈에 띄는 차이점을 강조하기 위해 다양한 딥 러닝 모델의 배포에 대한 자세한 비교를 제공하여 적어도 테스트된 시나리오에서 GPU가 더 낮은 비용으로 더 나은 처리량과 안정성을 제공한다는 증거를 제공합니다.</p>


  <p>테스트에서는 다음과 같이 크기가 작고 큰 네트워크 크기의 5개 모델에 대해 Tensorflow(1.6) 백 엔드가 있는 Tensorflow(1.8) 및 Keras(2.1.6)라는 두 개의 프레임워크를 사용합니다.</p>


  <ul>
   <li>MobileNetV2(3.4M 매개 변수)</li>
   <li>NasNetMobile(4.2M 매개 변수)</li>
   <li>ResNet50(23.5M 매개 변수)</li>
   <li>ResNet152(58.1M 매개 변수)</li>
   <li>NasNetLarge(84.7M 매개 변수)</li>
  </ul>


  <p>MobileNet과 같은 작은 매개 변수 효율적인 모델에서 NasNetLarge와 같은 대규모 네트워크에 이르기까지 광범위한 네트워크를 테스트하려고 했기 때문에 이러한 모델을 선택했습니다.</p>


  <p>이러한 각 모델에 대해 점수 매기기 이미지에 대한 API가 있는 Docker 이미지가 다음 네 가지 AKS 클러스터 구성에 준비 및 배포되었습니다.</p>


  <ul>
   <li>1개의 Pod가 있는 1개의 노드 GPU 클러스터</li>
   <li>2개의 Pod가 있는 2개 노드 GPU 클러스터</li>
   <li>3개의 Pod가 있는 3개의 노드 GPU 클러스터</li>
   <li>35개의 Pod가 있는 5개 노드 CPU 클러스터</li>
  </ul>


  <p>GPU 클러스터는 K80 GPU가 있는 Azure NC6 시리즈 가상 머신을 사용하여 만들어졌으며 CPU 클러스터는 8코어의 D4 v2 가상 머신을 사용하여 만들어졌습니다. CPU 클러스터는 가장 큰 GPU 클러스터 비용과 거의 일치하도록 전략적으로 구성되었으므로 3개 노드 GPU 클러스터와 5개의 노드 CPU 클러스터 간에 달러당 공정한 처리량을 비교할 수 있습니다. 이 클러스터는 이러한 테스트 시 가깝지만 약간 더 비쌉니다. 최신 가격 책정은 <a href="https://azure.microsoft.com/en-us/pricing/details/virtual-machines/linux/?&amp;OCID=AID719825_SEM_pCdAsET3&amp;lnkd=Bing_Azure_Brand&amp;msclkid=b19169b2735a1cc03d1a32885c0e0394&amp;dclid=CNXZ1qXJgNwCFeGhswodvoUB7A" target="_blank">Azure Virtual Machine 가격 계산기를</a> 사용하세요.</p>


  <p>모든 클러스터가 미국 동부 지역에 설정되었고, 미국 동부 및 서유럽에서 테스트 하네스를 사용하여 클라이언트를 테스트했습니다. 그 목적은 다른 지역의 테스트가 처리량 결과에 영향을 주었는지 확인하는 것이었습니다. 알고 보니 다른 지역의 테스트에는 약간의 영향이 있었지만 거의 영향을 미치지 않으므로 이 분석에 나열된 결과에는 총 40개의 클러스터 구성이 있는 미국 동부 지역의 테스트 클라이언트의 데이터만 포함됩니다.</p>


  <p>테스트는 배포된 채점 서비스와 동일한 지역의 Azure Windows 가상 머신에서 애플리케이션을 실행하여 수행되었습니다. 20~50개의 동시 스레드 범위를 사용하여 1,000개의 이미지를 채점했으며, 기록된 결과는 전체 집합의 평균 처리량이었습니다. 실제 지속 처리량은 테스트의 주기적 특성으로 인해 운영화된 서비스에서 더 높을 것으로 예상됩니다. 아래에 보고된 결과는 테스트 주기에 설정된 50개 스레드의 평균을 사용하며, 이러한 구성을 테스트하는 데 사용되는 애플리케이션은 <a href="https://github.com/grecoe/CloudAI/tree/master/Utilities/DistributedEndpointTesting" target="_blank">GitHub 찾을 수 있습니다</a>.</p>


  <h2>GPU 클러스터 크기 조정</h2>


  <p>GPU 클러스터에 대한 일반적인 처리량 추세는 CPU 클러스터와 다르므로 클러스터에 GPU 노드를 더 추가하면 처리량 성능이 선형적으로 증가합니다. 다음 그래프는 테스트된 각 프레임워크 및 모델에 대한 클러스터에 더 많은 GPU가 추가됨에 따라 처리량의 선형 증가를 보여 줍니다.</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/8f1b9653-f32e-44b0-8f16-98668004fa82.png"><img alt="image" border="0" height="344" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/5533a661-0e2a-42ce-9dd5-1a4ac8616b45.png" style="border: 0px currentcolor; border-image: none; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;" title="이미지" width="622"></a></p>


  <p>클러스터의 관리 오버헤드로 인해 처리량이 크게 증가하지만 증가는 추가된 GPU 수에 비례하지 않으며 추가된 GPU당 100% 미만입니다.</p>


  <h2>GPU 및 CPU 결과</h2>


  <p>앞에서 설명한 대로 테스트의 목적은 딥 러닝 배포가 GPU에서 훨씬 더 나은 성능을 발휘하는지 파악하는 것이며, 이는 모델을 호스트하는 데 드는 재정적 비용 절감으로 이어질 수 있습니다. 아래 그림에서 GPU 클러스터는 각 프레임워크의 모든 모델에 대해 35개의 Pod가 있는 5개 노드 CPU 클러스터와 비교됩니다. 3개의 노드 GPU 클러스터는 대략 이러한 테스트 시 5개의 노드 CPU 클러스터를 사용하여 매월 동일한 달러 비용으로 변환됩니다.</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/47de541e-4a56-450f-9f88-a3c1198c80fb.png"><img alt="image" border="0" height="393" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/96cac5e9-2ac1-4559-ab75-adb0d29bf34f.png" style="border: 0px currentcolor; border-image: none; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;" title="이미지" width="636"></a></p>


  <p>결과는 GPU 클러스터의 처리량이 GPU가 딥 러닝 모델을 유추하기 위한 경제적인 선택임을 증명하는 모든 모델 및 프레임워크의 CPU 처리량보다 항상 더 낫다는 것을 시사합니다. 모든 경우에 35개의 Pod CPU 클러스터는 단일 GPU 클러스터가 186% 이상, 3노드 GPU 클러스터가 비슷한 비용으로 415%의 성능을 보였습니다. 이러한 결과는 단일 노드 GPU 클러스터가 TensorFlow 프레임워크의 CPU 클러스터보다 392% 및 3노드 GPU 804% 더 잘 수행하는 MobileNetV2와 같은 소규모 네트워크에서 더 두드러집니다.</p>


  <p>매개 변수 수가 딥 러닝 모델만큼 높지 않은 표준 기계 학습 모델의 경우 CPU는 여전히 더 효과적이고 비용 효율적인 것으로 간주되어야 합니다. 또한 <a href="https://github.com/intel/mkl-dnn" target="_blank">MKL DNN</a> 및 <a href="https://github.com/Maratyszcza/NNPACK" target="_blank">NNPACK</a>과 같은 CPU 성능을 최적화하는 메서드도 있습니다. 그러나 <a href="https://developer.nvidia.com/tensorrt" target="_blank">TensorRT</a>와 같은 GPU에 대해서도 유사한 메서드가 있습니다. 또한 GPU 클러스터의 성능이 CPU보다 훨씬 더 일관적이라는 것을 발견했습니다.</p>


  <p>모델과 CPU 전용 배포에 있는 웹 서비스 간에 리소스에 대한 경합이 없기 때문이라고 가설을 세웠습니다. 매개 변수 수가 많은 모델을 사용하는 딥 러닝 유추 작업의 경우 GPU 기반 배포는 리소스 경합의 부족의 이점을 활용하고 비슷한 비용의 CPU 클러스터에 비해 훨씬 더 높은 처리량 값을 제공한다는 결론을 얻을 수 있습니다.</p>


  <p>이 비교가 다음 배포 결정에 도움이 되며 질문이나 의견이 있는지 알려 주시기 바랍니다.</p>
