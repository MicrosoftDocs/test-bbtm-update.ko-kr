### YamlMime:Yaml
ms.openlocfilehash: 4a7a8cb58bfedd4fed2462adc3ec71dd2da99dbe
ms.sourcegitcommit: d03bdc7fe5447adb6530886aab848b75fe8fa8ee
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 03/11/2022
ms.locfileid: "139900249"
Slug: structured-streaming-with-databricks-into-power-bi-cosmos-db
Title: Azure Databricks를 사용하여 Power BI & Cosmos DB로의 구조적 스트리밍
Summary: 이 블로그에서는 구조화된 스트리밍의 개념과 Azure Databricks를 사용하여 데이터 수집 경로를 직접 빌드하여 거의 실시간으로 데이터를 스트리밍하는 방법에 대해 설명합니다.
Content: "<p>이 블로그에서는&rsquo; 구조적 스트리밍의 개념과 <a href=\"https://docs.microsoft.com/en-gb/azure/azure-databricks/what-is-azure-databricks\" target=\"_blank\">Azure Databricks</a> 를 사용하여 데이터 수집 경로를 빌드하여 거의 실시간으로 데이터 스트리밍을 사용하도록 설정하는 방법에 대해 설명합니다. Well&rsquo;은 <a href=\"https://docs.microsoft.com/en-gb/azure/cognitive-services/text-analytics/overview\" target=\"_blank\">Text Analytics API</a>를 활용하는 Databricks 내에서 직접 호출할 수 있는 분석 기능 중 일부에 대해 설명하고 추가 분석 및 보고를 위해 Databricks를 <a href=\"https://powerbi.microsoft.com/en-us/\" target=\"_blank\">Power BI</a> 직접 연결하는 방법에 대해서도 설명합니다. 마지막 단계에서는 스트리밍된 데이터를 Databricks에서 영구 스토리지로 <a href=\"https://docs.microsoft.com/en-us/azure/cosmos-db/introduction\" target=\"_blank\">Cosmos DB</a>로 전송하는 방법을 다룹니다.</p>\n\n<p>구조적 스트리밍은 스트리밍 데이터(예: Twitter 피드)에 빠른 계산을 적용할 수 있는 스트림 처리 엔진입니다. 이러한 의미에서 정적 데이터 세트에서 일괄 처리 계산이 실행되는 방식과 매우 유사합니다. 계산은 스트리밍 데이터가 유입될 때 결과를 연속 프로세스로 업데이트하는 Spark SQL 엔진을 통해 증분 방식으로 수행됩니다.</p>\n\n<p><a href=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/0536037d-88b5-4f9f-bf55-014c8e8fa41c.png\"><img alt=\"clip_image002\" border=\"0\" height=\"440\" src=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/145f5167-d149-47f5-ba94-19dc930f3738.png\" style=\"border: 0px currentcolor; border-image: none; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;\" title=\"clip_image002\" width=\"752\"></a></p>\n\n<p>위의 아키텍처는 Databricks를 수집 경로로 직접 사용하여 Twitter에서 데이터를 스트림하는 방법(<a href=\"https://docs.microsoft.com/en-us/azure/event-hubs/event-hubs-what-is-event-hubs\" target=\"_blank\">Event Hubs</a>를 통해 버퍼로 작동)에 대한 가능한 흐름을 보여 줍니다. <a href=\"https://docs.microsoft.com/en-gb/azure/cognitive-services/welcome\" target=\"_blank\">Cognitive Services에서 Text Analytics</a> API를 호출하여 데이터에 인텔리전스를 적용한 다음, 마지막으로 데이터를 Power BI 직접 전송하고 DB를 Cosmos.</p>\n\n<h2>구조적 스트리밍의 개념</h2>\n\n<p>데이터 스트림에서 도착하는 모든 데이터는 바인딩되지 않은 입력 테이블로 처리됩니다. 데이터 스트림 내의 각 새 데이터에 대해 바인딩되지 않은 입력 테이블에 새 행이 추가됩니다. 입력 전체가 저장되지 않지만&rsquo; 최종 결과는 전체 입력을 유지하고 일괄 처리 작업을 실행하는 것과 같습니다.</p>\n\n<p><a href=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/a8a1ff2d-fddc-4194-9389-b4f249d57a34.png\"><img alt=\"image\" border=\"0\" height=\"324\" src=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/662c8096-5b42-4212-8a40-d4d071b322f0.png\" style=\"border: 0px currentcolor; border-image: none; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;\" title=\"이미지\" width=\"602\"></a></p>\n\n<p>입력 테이블을 사용하면 출력 싱크에 기록된 최종 결과 테이블을 계산하는 정적 테이블인 것처럼 쿼리 자체를 정의할 수 있습니다. 이 일괄 처리와 유사한 쿼리는 Spark에서 <strong>증분 실행</strong>이라는 프로세스를 통해 스트리밍 실행 계획으로 자동으로 변환됩니다.</p>\n\n<p>증분 실행은 Spark가 레코드가 도착할 때마다 결과를 업데이트하는 데 필요한 상태를 기본적으로 계산하는 위치입니다. 기본 제공 트리거를 활용하여 결과를 업데이트할 시기를 지정할 수 있습니다. 실행되는 각 트리거에 대해 Spark는 입력 테이블 내에서 새 데이터를 찾고 결과를 증분 방식으로 업데이트합니다.</p>\n\n<p>입력 테이블의 쿼리는 결과 테이블을 생성합니다. 모든 트리거 간격(예: 3초마다)에 대해 새 행이 입력 테이블에 추가되며, 증분 실행 프로세스를 통해 결과 테이블을 업데이트합니다. 결과 테이블이 업데이트될 때마다 변경된 결과가 출력으로 작성됩니다.</p>\n\n<p><a href=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/ded7c1d8-31df-4422-babd-065520b5372a.png\"><img alt=\"image\" border=\"0\" height=\"281\" src=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/e2a471ab-7233-4fc5-89d2-0ba449ec8c8d.png\" style=\"border: 0px currentcolor; border-image: none; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;\" title=\"이미지\" width=\"461\"></a></p>\n\n<p>출력은 외부 스토리지에 기록되는 항목, Databricks 파일 시스템에 직접 쓰여지는지 또는 CosmosDB 예제에 기록되는지를 정의합니다.</p>\n\n<p>Azure Databricks 내에서 이를 구현하기 위해 들어오는 스트림 함수가 호출되어 지정된 입력(이 예제의 Twitter 데이터)에 따라 StreamingDataFrame을 시작합니다. 그런 다음, 스트림이 아래 코드 조각과 같이 내부 Databricks 파일 스토리지에 parquet 형식으로 처리되고 기록됩니다.</p>\n\n<pre>\nval streamingDataFrame = incomingStream.selectExpr(&quot;cast (body as string) AS Content&quot;)\n.withColumn(&quot;body&quot;, toSentiment(%code%nbsp;&quot;Content&quot;))\n \nimport org.apache.spark.sql.streaming.Trigger.ProcessingTime\nval result = streamingDataFrame\n.writeStream.format(&quot;parquet&quot;)\n.option(&quot;path&quot;, &quot;/mnt/Data&quot;)\n.option(&quot;checkpointLocation&quot;, &quot;/mnt/sample/check&quot;)\n.start()</pre>\n\n<p><a href=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/419123be-0b0a-4cec-af9d-210c9e04ef1f.png\"><img alt=\"image\" border=\"0\" height=\"224\" src=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/768d3765-f86b-4b65-bca8-621fff57ab16.png\" style=\"border: 0px currentcolor; border-image: none; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;\" title=\"이미지\" width=\"602\"></a></p>\n\n<h2>Databricks(CosmosDB) 내에 파일 시스템 탑재</h2>\n\n<p><a href=\"https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blobs-introduction\" target=\"_blank\">Blob</a> Storage, Data <a href=\"https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-overview\" target=\"_blank\">Lake Store</a> 및 SQL Data Warehouse와 같은 여러 다른 파일 시스템을 Databricks 내에 직접 탑재할 수 <a href=\"https://docs.microsoft.com/en-us/azure/sql-data-warehouse/sql-data-warehouse-overview-what-is\" target=\"_blank\">있습니다</a>. 이 블로그에서는&rsquo; Databricks와 Cosmos DB 간의 연결 기능을 살펴봅니다.</p>\n\n<p>Apache Spark와 Azure Cosmos DB 간의 빠른 연결은 Azure Cosmos DB를 사용하여 데이터를 빠르게 지속하고 검색할 수 있는 빠르게 움직이는 데이터 과학 문제를 해결하는 기능을 가속화합니다. Spark to Cosmos DB 커넥터를 사용하면 IoT 시나리오를 해결하고,&rsquo; 분석을 수행할 때 열을 업데이트하고, 조건자 필터링을 푸시다운하고, 일관성, 가용성, 짧은 대기 시간 및 처리량에 대한 보장된 SLA를 사용하여 지역에서 복제된 관리되는 문서 저장소에 대해 빠르게 변화하는 데이터에 대해 고급 분석을 수행할 수 있습니다.</p>\n\n<p><a href=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/77217cc4-fea9-4988-aaef-24fecced3112.png\"><img alt=\"image\" border=\"0\" height=\"285\" src=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/81dffcb2-bf54-410f-9250-fce4b6fbd89b.png\" style=\"border: 0px currentcolor; border-image: none; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;\" title=\"이미지\" width=\"602\"></a></p>\n\n<ul>\n <li>Databricks 내에서 Spark 마스터 노드에서 Cosmos DB 게이트웨이 노드로 연결하여 Cosmos 파티션 정보를 가져옵니다.</li>\n <li>파티션 정보는 Spark 마스터 노드로 다시 변환되고 작업자 노드 간에 분산됩니다.</li>\n <li>해당 정보는 Spark로 다시 변환되고 작업자 노드 간에 배포됩니다.</li>\n <li>이렇게 하면 쿼리가 들어올 때 Spark 작업자 노드가 Cosmos DB 파티션과 직접 상호 작용할 수 있습니다. 작업된 노드는 필요한 데이터를 추출하고 Spark 작업자 노드 내의 Spark 파티션으로 데이터를 다시 가져올 수 있습니다.</li>\n</ul>\n\n<p>Spark 작업자 노드와 Cosmos DB 데이터 노드 간에 데이터 이동이 수행되므로 Spark와 Cosmos DB 간의 통신은 훨씬 빠릅니다.</p>\n\n<p>Azure Cosmos DB Spark 커넥터(현재 미리 보기 상태)를 사용하면 Databricks 내에서 Cosmos DB 스토리지 계정에 직접 연결할 수 있으므로 Cosmos DB가 아래 코드 조각과 같이 Spark 작업에 대한 입력 원본 또는 출력 싱크 역할을 할 수 있습니다.</p>\n\n<pre>\nimport com.microsoft.azure.cosmosdb.spark.CosmosDBSpark\nimport com.microsoft.azure.cosmosdb.spark.config.Config\n\nval writeConfig = Config(Map(&quot;Endpoint, MasterKey<ins datetime=\"2018-06-21T19:46\">, Database, PreferredRegions, Collection, WritingBatchSize</ins>&quot;))\n\nimport org.apache.spark.sql.SaveMode\nsentimentdata.write.mode(SaveMode.Overwrite).cosmosDB(writeConfig)</pre>\n\n<h2>Databricks를 PowerBI에 연결</h2>\n\n<p>Microsoft Power BI 셀프 서비스 비즈니스 인텔리전스 기능을 통해 대화형 시각화를 제공하는 비즈니스 분석 서비스로, 최종 사용자가 정보 기술 직원 또는 데이터베이스 관리자에 의존하지 않고도 보고서 및 대시보드를 직접 만들 수 있습니다.</p>\n\n<p>Azure Databricks는 Power BI 직접 데이터 원본으로 사용할 수 있으므로 Azure Databricks의 성능 및 기술 이점을 데이터 과학자 및 데이터 엔지니어를 넘어 모든 비즈니스 사용자에게 제공할 수 있습니다.</p>\n\n<p>Power BI Desktop 기본 제공 Spark 커넥터(현재 미리 보기 상태)를 사용하여 Azure Databricks 클러스터에 직접 연결할 수 있습니다. 커넥터를 사용하면 DirectQuery를 사용하여 Databricks로 처리를 오프로드할 수 있습니다. 이는 Power BI 로드하지 않으려는&rsquo; 많은 양의 데이터가 있거나 이 블로그 게시물 전체에서 설명한 대로 거의 실시간 분석을 수행하려는 경우에 좋습니다.</p>\n\n<p><a href=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/1225955d-d8a4-45dc-9e95-021ec868980a.png\"><img alt=\"image\" border=\"0\" height=\"267\" src=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/895289b5-384d-4583-bc1b-f037c4bd330d.png\" style=\"border: 0px currentcolor; border-image: none; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;\" title=\"이미지\" width=\"602\"></a></p>\n\n<p>이 커넥터는 DirectQuery를 통해 JDBC/ODBC 연결을 활용하여 Databricks를 통해 입력되는 스트리밍 데이터에 대해 탑재된 파일 저장소에 라이브 연결을 사용할 수 있도록 합니다. Databricks에서 스트리밍된 데이터를 파일 저장소에 쓰도록 일정(예: 5초마다)을 설정하고 Power BI 이를 정기적으로 끌어와 거의 실시간으로 데이터 스트림을 가져올 수 있습니다.</p>\n\n<p>Power BI 내에서 스트리밍된 데이터 세트에 다양한 분석 및 시각화를 적용할 수 있습니다.</p>\n\n<p><a href=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/292c6de5-5b3d-4248-9836-63219fcdceec.png\"><img alt=\"image\" border=\"0\" height=\"301\" src=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/ff2e2567-64b4-4a65-b17e-3faf0ca458ca.png\" style=\"border: 0px currentcolor; border-image: none; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;\" title=\"이미지\" width=\"602\"></a></p>\n\n<p>이 아키텍처를 빌드하고 싶으신가요? Databricks의 더 많은 예제는 공식 <a href=\"https://github.com/giulianorapoz/DatabricksStreamingPowerBI\" target=\"_blank\">Azure 설명서를 참조하세요</a>.</p>\n\n<ul>\n <li><a href=\"https://docs.microsoft.com/en-us/azure/azure-databricks/databricks-extract-load-sql-data-warehouse\" target=\"_blank\">Databricks에서 ETL 작업을 수행합니다</a>.</li>\n <li><a href=\"https://docs.databricks.com/spark/latest/structured-streaming/index.html\" target=\"_blank\">Databricks의 구조적 스트리밍입니다</a>.</li>\n <li><a href=\"https://docs.azuredatabricks.net/spark/latest/structured-streaming/kafka.html\" target=\"_blank\">HDInsight Kafka에서 데이터를 스트리밍</a>합니다.</li>\n</ul>\n\n<p><a href=\"https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-power-bi-dashboard\" target=\"_blank\">Power BI 사용하여 Stream Analytics</a>에 대해 자세히 읽어보세요.</p>"
