### YamlMime:Yaml
ms.openlocfilehash: 5a50308904a3fcd5c364c6095791094685f95759
ms.sourcegitcommit: d03bdc7fe5447adb6530886aab848b75fe8fa8ee
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 03/11/2022
ms.locfileid: "139906089"
Slug: build-ai-you-can-trust-with-responsible-ml
Title: 책임 있는 ML 신뢰할 수 있는 AI 빌드
Summary: AI 배포는 이러한 솔루션의 투명성, 책임성 및 공정성에 대한 고객 신뢰가 부족하여 점점 더 많은 영향을 받고 있습니다. Microsoft는 사용자를 최우선으로 하는 원칙과 실제로 이를 가능하게 하는 도구에 따라 AI 및 기계 학습(ML)의 발전에 전념하고 있습니다.
Content: >-
  <p>AI가 산업 및 애플리케이션에서 중요한 모멘텀에 도달함에 따라 AI의 안전하고 <a href="https://blogs.microsoft.com/ai/azure-responsible-machine-learning/" target="_blank">책임감 있는 사용을</a> 보장하는 것이 필수적입니다. AI 배포는 이러한 솔루션의 투명성, 책임성 및 공정성에 대한 고객 신뢰가 부족하여 점점 더 많은 영향을 받고 있습니다. Microsoft는 사용자를 최우선으로 하는 원칙과 실제로 이를 가능하게 하는 도구에 따라 AI 및 기계 학습(ML)의 발전에 전념하고 있습니다.</p>


  <p><a href="https://www.microsoft.com/en-us/research/blog/research-collection-responsible-ai/" target="_blank">Aether 위원회 및 해당 작업 그룹과</a> 협력하여 책임 있는 AI에 대한 최신 연구를 Azure에 도입하고 있습니다. &rsquo;<a href="https://azure.microsoft.com/en-us/services/machine-learning/" target="_blank">Azure Machine Learning</a> 새로운 <a href="https://azure.microsoft.com/en-us/services/machine-learning/responsibleML" target="_blank">책임 있는 ML</a> 기능과 오픈 소스 도구 키트를 통해 데이터 과학자와 개발자가 ML 모델을 <b><i>이해하고</i></b>, 사람과 데이터를 <b><i>보호하고</i></b>, 엔드투엔드 ML 프로세스를 <b><i>제어</i></b>할 수 있는 방법을 살펴보겠습니다.</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/644ab4e9-abc2-4d5e-8550-82e77ce3dfa8.jpg"><img alt="Responsible ML capabilities in Azure Machine Learning help developers and data scientists to understand (with interpretability and fairness), protect (with differential privacy and confidential ML) and control (with audit trail and datasheets) the end-to-end ML process." border="0" height="468" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/3a4710a1-d3bb-42ba-bb8f-8603ebab4033.jpg" style="border: 0px currentcolor; border-image: none; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;" title="Azure Machine Learning 책임 있는 ML 기능은 개발자와 데이터 과학자가 엔드 투 엔드 ML 프로세스를 이해하고(차등 개인 정보 보호 및 기밀 ML 사용하여) 보호하고(감사 내역 및 데이터시트를 사용하여) 제어하는 데 도움이 됩니다." width="626"></a></p>


  <h2>이해</h2>


  <p>ML 일상적인 비즈니스 프로세스에 깊이 통합됨에 따라 투명성이 중요합니다. Azure Machine Learning 모델 동작을 이해할 뿐만 아니라 불공정성을 평가하고 완화하는 데 도움이 됩니다.</p>


  <h3>모델 동작 해석 및 설명</h3>


  <p><a href="https://github.com/interpretml/interpret" target="_blank">InterpretML</a> 도구 키트로 구동되는 <a href="https://docs.microsoft.com/azure/machine-learning/how-to-machine-learning-interpretability" target="_blank">Azure Machine Learning</a> 모델 해석 기능을 통해 개발자와 데이터 과학자는 모델 동작을 이해하고 비즈니스 이해 관계자 및 고객에게 모델 설명을 제공할 수 있습니다.</p>


  <p>모델 해석 기능을 사용하여 다음을 수행합니다.</p>


  <ul>
      <li>정확한 ML 모델을 빌드합니다.</li>
      <li>학습 및 추론 단계 모두에서 심층 신경망을 비롯한 다양한 모델의 동작을 이해합니다.</li>
      <li>가상 분석을 수행하여 기능 값이 변경될 때 모델 예측에 미치는 영향을 확인합니다.</li>
  </ul>


  <p style="text-align: center;"><iframe allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" frameborder="0" height="315" src="https://www.microsoft.com/en-us/videoplayer/embed/RE4wHT2" width="560"></iframe></p>


  <p style="text-align: center;"><em>&quot;Azure Machine Learning AI를 책임감 있게 구축하고 고객과의 신뢰를 구축하는 데 도움이 됩니다. 로열티 프로그램에 대한 사기 탐지 노력의 해석력 기능을 사용하여 모델을 더 잘 이해하고, 사기의 정품 사례를 식별하고, 잘못된 결과의 가능성을 줄일 수 있습니다.&quot;&nbsp; </em></p>


  <p align="center">&mdash;다니엘 엥버그, 스칸디나비아 항공 데이터 분석 및 인공 지능 책임자</p>


  <h3>모델 평가 및 완화</h3>


  <p>오늘날 AI 시스템을 빌드할 때의 과제는 공정성의 우선 순위를 정할 수 없다는 것입니다. 개발자와 데이터 과학자는 <a href="https://docs.microsoft.com/azure/machine-learning/concept-fairness-ml" target="_blank">Azure Machine Learning</a> <a href="https://github.com/fairlearn/fairlearn" target="_blank">Fairlearn</a>을 사용하여 전문 알고리즘을 활용하여 모든 사용자에게 더 공정한 결과를 보장할 수 있습니다.</p>


  <p>공정성 기능을 사용하여 다음을 수행합니다.</p>


  <ul>
      <li>모델 학습 및 배포 중에 모델 공정성을 평가합니다.</li>
      <li>모델 성능을 최적화하면서 불공정을 완화합니다.</li>
      <li>대화형 시각화를 사용하여 불공정을 완화하는 권장 모델 집합을 비교합니다.</li>
  </ul>


  <p style="text-align: center;"><iframe allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" frameborder="0" height="315" src="https://www.microsoft.com/en-us/videoplayer/embed/RE4wz7o" width="560"></iframe></p>


  <p style="text-align: center;"><em>&ldquo;Azure Machine Learning 및 Fairlearn 기능은 고객을 위한 신뢰할 수 있는 AI 솔루션을 배포하는 동시에 이해 관계자의 신뢰와 규정 준수를 가능하게 하는 데 도움이 되는 고급 공정성 및 설명 가능성을 제공합니다.&rdquo;&nbsp; </em>&mdash; Alex Mohelsky, EY Canada 파트너 및 자문 데이터, 분석 및 AI 리더</p>


  <h2>보호</h2>


  <p>ML 의료 환자 또는 인구 조사 데이터와 같은 중요한 정보를 포함하는 시나리오에서 점점 더 사용되고 있습니다. 데이터 편집 또는 마스킹과 같은 현재 사례는 ML 제한될 수 있습니다. 이 문제를 해결하기 위해 차등 개인 정보 보호 및 기밀 기계 학습 기술을 사용하여 조직에서 데이터 개인 정보 보호 및 기밀성을 유지하면서 솔루션을 빌드할 수 있습니다.</p>


  <h3>차등 프라이버시를 통한 데이터 노출 방지</h3>


  <p>데이터 과학 팀은 <a href="https://docs.microsoft.com/azure/machine-learning/concept-differential-privacy" target="_blank">Azure Machine Learning</a> 새로운 <a href="https://aka.ms/diffprivacyrepo" target="_blank">차등 개인 정보 보호 도구 키트</a>를 사용하여 개인 정보를 보존하고 개인&rsquo; 데이터의 가인화를 방지하는 ML 솔루션을 빌드할 수 있습니다. 이러한 차등 개인 정보 보호 기술은 하버드&rsquo; 정량 사회 과학 연구소 (IQSS) 및 공학 학교의 연구원과 협력하여 개발되었습니다.</p>


  <p>차등 개인 정보 보호는 다음을 통해 중요한 데이터를 보호합니다.</p>


  <ul>
      <li>중요한 정확도 손실 없이 개인 정보의 공개를 방지하기 위해 데이터에 통계 노이즈를 주입합니다.</li>
      <li>개별 쿼리에서 사용하는 정보 예산을 추적하고 추가 쿼리를 적절하게 제한하여 노출 위험을 관리합니다.</li>
  </ul>


  <h3>기밀 기계 학습을 사용하여 데이터 보호</h3>


  <p>조직은 데이터 개인 정보 보호 외에도 모든 ML 자산의 보안 및 기밀성을 보장하려고 합니다.</p>


  <p>보안 모델 학습 및 배포를 사용하도록 설정하기 위해 Azure Machine Learning 강력한 데이터 및 네트워킹 보호 기능 집합을 제공합니다. 여기에는 Azure Virtual Networks에 대한 지원, ML 작업 영역에 연결하는 프라이빗 링크, 전용 컴퓨팅 호스트 및 전송 중 및 미사용 암호화를 위한 고객 관리형 키가 포함됩니다.</p>


  <p>이 보안 기반을 기반으로 하는 Azure Machine Learning Microsoft의 데이터 과학 팀이 데이터를 볼 수 없으면 안전한 환경에서 기밀 데이터에 대한 모델을 빌드할 수 있습니다. 이 과정에서 모든 ML 자산은 기밀로 유지됩니다. 이 방법은 오픈 소스 ML 프레임워크 및 다양한 하드웨어 옵션과 완벽하게 호환됩니다. 이러한 기밀 기계 학습 기능을 올해 하반기에 모든 개발자와 데이터 과학자에게 제공하게 되어 기쁩니다.</p>


  <h2>컨트롤</h2>


  <p>책임감 있게 구축하려면 ML 개발 프로세스가 반복 가능하고 안정적이며 관련자에게 책임을 져야 합니다. Azure Machine Learning 통해 의사 결정자, 감사자 및 ML 수명 주기의 모든 사용자가 책임 있는 프로세스를 지원할 수 있습니다.</p>


  <h3>감사 내역을 사용하여 ML 자산 추적</h3>


  <p>Azure Machine Learning 계보를 자동으로 추적하고 ML 자산의 감사 내역을 유지하는 기능을 제공합니다. 세부 정보&mdash; 실행 기록, 학습 환경, 데이터 및 모델 설명&mdash;은 모두 중앙 레지스트리에 캡처되어 조직이 다양한 감사 요구 사항을 충족할 수 있도록 합니다.</p>


  <h3>모델 데이터시트를 사용하여 책임 강화</h3>


  <p>데이터시트는 동기 부여, 용도 등과 같은 ML 정보를 문서화하는 표준화된 방법을 제공합니다. Microsoft에서는 데이터 과학자, 감사자 및 의사 결정자에게 투명성을 제공하기 위해 데이터 <a href="https://www.microsoft.com/en-us/research/publication/datasheets-for-datasets/" target="_blank">시트에 대한 연구를</a> 주도했습니다. 우리는 또한 <a href="https://www.partnershiponai.org/" target="_blank">AI에 대한 파트너십</a> 및 업계, 학계 및 정부 의 리더들과 협력하여 권장 사례와 <a href="https://www.partnershiponai.org/about-ml/" target="_blank">ABOUT ML</a> 프로세스를 개발하고 있습니다. Azure Machine Learning <a href="https://github.com/microsoft/MLOps/blob/master/pytorch_with_datasheet/model_with_datasheet.ipynb" target="_blank">사용자 지정 태그</a> 기능은 현재 데이터시트를 구현하는 데 사용할 수 있으며 시간이 지남에 따라 추가 기능을 릴리스할 예정입니다.</p>


  <h3>책임감 있게 혁신 시작</h3>


  <p><a href="https://azure.microsoft.com/en-us/services/machine-learning/" target="_blank">Azure Machine Learning</a> 및 <a href="https://www.microsoft.com/en-us/ai/responsible-ai-resources?activetab=pivot1%3aprimaryr4" target="_blank">오픈 소스 도구</a>의 새로운 기능 외에도 AI의 책임 있는 사용에 대한 <a href="https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1%3aprimaryr6" target="_blank">원칙도 개발했습니다</a>. 새로운 책임 있는 ML 혁신 및 리소스는 개발자와 데이터 과학자가 보다 안정적이고 공정하며 신뢰할 수 있는 ML 구축할 수 있도록 설계되었습니다. 오늘 저희와 함께 책임 있는 ML 함께 여행을 시작하세요!</p>


  <h3>추가 리소스</h3>


  <ul>
      <li><a href="https://azure.microsoft.com/services/machine-learning/responsibleML" target="_blank">책임 있는 ML</a> 대해 자세히 알아보세요.</li>
      <li><a href="https://azure.microsoft.com/trial/get-started-machine-learning/" target="_blank">Azure Machine Learning 무료 평가판을</a> 시작하세요.</li>
      <li><a href="https://aka.ms/aml-docs" target="_blank">Azure Machine Learning</a> 대해 자세히 알아보고 <a href="https://azure.microsoft.com/en-us/services/machine-learning/#documentation" target="_blank">빠른 시작 가이드 및 자습서를 따르세요</a>.</li>
  </ul>


  <hr>

  <p><em>이 이야기의 이전 버전은 차등 개인 정보 보호 도구 키트를 WhiteNoise라고 불렀습니다.</em></p>
