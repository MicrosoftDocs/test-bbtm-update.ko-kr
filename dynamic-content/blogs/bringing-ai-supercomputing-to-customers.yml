### YamlMime:Yaml
ms.openlocfilehash: ee40ae1733697ca5d57e03ef258373b90689079d
ms.sourcegitcommit: d03bdc7fe5447adb6530886aab848b75fe8fa8ee
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 03/11/2022
ms.locfileid: "139906866"
Slug: bringing-ai-supercomputing-to-customers
Title: 고객에게 AI 슈퍼컴퓨팅 제공
Summary: 대규모 AI 모델을 사용하여 많은 수의 작업에 전력을 공급하는 추세는 강력한 새 기능을 사용하도록 AI를 빌드하고 적용하는 방식을 변화시키고 있습니다.
Content: >-
  <p>대규모 AI 모델을 사용하여 많은 수의 작업에 전력을 공급하는 추세는 AI 빌드 방식을 변화시키고 있습니다. Microsoft Build 2020에서는 Azure에서 최첨단 <a href="https://blogs.microsoft.com/ai/openai-azure-supercomputer/" target="_blank">AI 슈퍼컴퓨팅</a>을 활용하는 <a href="https://innovation.microsoft.com/en-us/ai-at-scale" target="_blank">대규모</a> AI에 대한 비전과 차세대 AI를 지원하는 새로운 수준의 대규모 AI 모델을 공유했습니다. 대규모 모델의 장점은 AI 슈퍼컴퓨팅을 사용하여 대량의 데이터로 한 번만 학습해야 하므로 훨씬 작은 데이터 세트와 리소스가 있는 다양한 작업 및 도메인에 대해 미세 조정할&rdquo; 수 &ldquo;있다는 것입니다. 모델이 갖는 매개 변수가 많을수록 170억 개의 매개 변수인 T-NLG(튜링 자연어 생성) 모델과 처음으로 본 질문에 답하거나 요약&nbsp;할 수 있는 언어를 이해하는 능력에서 설명한 것처럼 데이터의 어려운 뉘앙스를 더 잘 캡처할 수 있습니다. 이와 같은 자연어 모델은 1년 전 최첨단 모델보다 훨씬 크고,&nbsp; 이전 이미지 중심 모델의 크기의 많은 주문이 이제 Bing, Word, Outlook 및 Dynamics 전반에 걸쳐 다양한 작업에 전력을 공급하고 있습니다.</p>


  <p>이 규모의 학습 모델을 사용하려면 컴퓨터 내부 및 전체에서 대역폭이 높은 네트워크와 상호 연결된 특수 AI 가속기가 있는 수백 대의 대규모 클러스터가 필요합니다. Microsoft는 Microsoft 제품 전반에서 새로운 자연어 생성 및 이해 기능을 가능하게 하고 OpenAI가 안전한 인공 일반 지능을 구축하는 임무를 수행하기 위해 이러한 클러스터를 Azure에 구축해 왔습니다. 최신 클러스터는 집계된 컴퓨팅 성능을 제공하므로 AI 슈퍼컴퓨터라고 하며, OpenAI용으로 빌드된 클러스터는 전 세계에서 공개적으로 공개된 상위 5개 슈퍼컴퓨터에 도달합니다. 이 슈퍼컴퓨터를 사용하여 OpenAI는 <a href="https://github.com/openai/gpt-3" target="_blank">5월에 1,750억 개의 매개 변수 GPT-3 모델</a> 과 시나 번역을 포함하여 특별히 학습되지 않은&rsquo; 광범위한 작업을 지원할 수 있는 능력을 공개했습니다.</p>


  <p>대규모 컴퓨팅 클러스터, 선도적인 네트워크 디자인, Azure Machine Learning, ONNX 런타임 및 기타 Azure AI 서비스를 포함한 소프트웨어 스택에서 수행한 작업은 AI at Scale 전략에 직접 부합됩니다. 이 프로세스를 통해 생성된 혁신은 궁극적으로 Azure가 규모에 관계없이 모든 고객의 AI 요구를 더 잘 지원할 수 있도록 합니다. 예를 들어 NDv2 VM 시리즈를 통해 Azure는 대역폭이 짧은 NVIDIA Mellanox InfiniBand 네트워킹으로 연결된 NVIDIAS&rsquo; V100 Tensor Core GPU를 사용하는 VM 클러스터를 제공하는 최초의 유일한 퍼블릭 클라우드였습니다. 좋은 비유는 자동차 기술이 하이 엔드 레이싱 산업에서 개척된 다음 우리가 매일 운전하는 자동차에 진입하는 방법입니다.</p>


  <h2>전례없는 규모의 새로운 국경</h2>


  <blockquote>

  <p style="margin-left: 40px;"><em>&ldquo;AI를 일반 인텔리전스로 발전하려면 점점 더 유능한 모델을 학습시킬 수 있는 강력한 시스템이 부분적으로 필요합니다. 필요한 컴퓨팅 기능은 최근까지 불가능했습니다. Azure AI 및 해당 슈퍼컴퓨팅 기능은 OpenAI CEO인 Sam Altman의 발전을&rdquo;&nbsp; 가속화하는 데 도움이 되는 선도적인 시스템을 제공합니다</em>.-</p>

  </blockquote>


  <p>Azure 혁신&rsquo;의 연속체에서 주문형으로 사용할 수 있는 가장 강력하고 대규모로 확장 가능한 AI VM인 새로운 ND A100 v4 VM 시리즈를 수백 개의 VM에 걸쳐 수천 개의 상호 연결된 NVIDIA GPU로 발표하게 되어 매우 기쁩니다.</p>


  <p>ND A100 v4 VM 시리즈는 단일 VM(가상 머신) 및 8개의 NVIDIA Ampere A100 Tensor Core GPU로 시작하지만, 인간의 뇌가 상호 연결된 뉴런으로 구성된 것처럼 ND A100 v4 기반 클러스터는 전례 없는 1.6Tb/s의 VM당 상호 연결된 대역폭으로 수천 개의 GPU를 확장할 수 있습니다. 각 GPU에는 고유한 전용 토폴로지 독립적 200Gb/s NVIDIA Mellanox HDR InfiniBand 연결이 제공됩니다. 수십, 수백 또는 수천 개의 GPU가 Mellanox InfiniBand HDR 클러스터의 일부로 함께 작동하여 모든 수준의 AI 야망을 달성할 수 있습니다. 모든 AI 목표(모델을 처음부터 학습하거나, 사용자 고유의 데이터를 사용하여 학습을 계속하거나, 원하는 작업에 맞게 미세 조정)는 다른 퍼블릭 클라우드 제품보다 16배 높은 전용 GPU 대역폭으로 훨씬 더 빠르게 달성할 수 있습니다.</p>


  <p>ND A100 v4 VM 시리즈는 모든 주요 시스템 구성 요소에 내장된 PCIe Gen4와 같은 최신 하드웨어 표준을 갖춘 새로운 Azure 엔지니어링 AMD 로마 기반 플랫폼에서 지원됩니다. 각 VM 내에서 가장 빠른 GPU-GPU 간 연결을 위한 PCIe Gen 4 및 NVIDIAs&rsquo; 3세대 NVLINK 아키텍처는 이전보다 2배 이상 빠르게 시스템을 통해 데이터를 이동하도록 유지합니다.&nbsp;</p>


  <p>대부분의 고객은 엔지니어링 작업 없이 NVIDIA V100 GPU를 기반으로 하는 이전 세대 시스템에 비해 컴퓨팅 성능이 2배에서 3배로 즉시 향상됩니다. 스파스 가속 및 MIG(다중 인스턴스 GPU)를 사용하는 다정밀도 Tensor Core와 같은 새로운 A100 기능을 활용하는 고객은 최대 20배의 향상을 달성할 수 있습니다.</p>


  <blockquote>

  <p style="margin-left: 40px;"><em>&ldquo;Azure는 NVIDIAs&rsquo;의 가장 고급 컴퓨팅 및 네트워킹 기능을 활용하여 클라우드에서 대규모로 AI를 위한 놀라운 플랫폼을 설계했습니다.&nbsp; NVIDIA A100 GPU의 단일 파티션에서 NVIDIA Mellanox Infiniband 상호 연결을 사용하여 수천 개의 A100 GPU로 확장할 수 있는 탄력적 아키텍처를 통해 Azure 고객은 가장 까다로운 AI 워크로드를 실행할 수 있습니다.&rdquo; -&nbsp;&rsquo;</em> 이안 벅, NVIDIA의 가속 컴퓨팅 총괄 매니저 겸 부사장</p>

  </blockquote>


  <p>ND A100 v4 VM 시리즈는 VM Scale Sets와 같은 Azure 핵심 확장성 블록을 활용하여 모든 크기의 클러스터를 자동으로 동적으로 투명하게 구성합니다. 이렇게 하면 어디서나 누구나 어떤 규모로든 AI를 달성할 수 있으며, 주문형 AI 슈퍼컴퓨터도 몇 분 안에 인스턴스화할 수 있습니다. 그런 다음, VM에 독립적으로 액세스하거나 Azure Machine Learning 서비스를 사용하여 클러스터 전체에서 학습 작업을 시작하고 관리할 수 있습니다.</p>


  <p>ND A100 v4 VM 시리즈 및 클러스터는 현재 미리 보기 상태이며 Azure 포트폴리오의 표준 제품이 되므로 누구나 클라우드에서 <a href="https://innovation.microsoft.com/en-us/ai-at-scale" target="_blank">규모에 맞게 AI</a> 의 잠재력을 발휘할 수 있습니다. 자세한 내용은 로컬 Microsoft 계정 팀에 문의하세요.</p>
