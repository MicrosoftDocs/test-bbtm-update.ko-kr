### YamlMime:Yaml
ms.openlocfilehash: 2bf9b277b523c7654994cda5391087260c9ebe51
ms.sourcegitcommit: d03bdc7fe5447adb6530886aab848b75fe8fa8ee
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 03/11/2022
ms.locfileid: "139908808"
Slug: onnx-runtime-for-inferencing-machine-learning-models-now-in-preview
Title: 지금 미리 보기로 기계 학습 모델을 유추하기 위한 ONNX 런타임
Summary: ONNX 형식의 기계 학습 모델을 위한 고성능 유추 엔진인 ONNX(Open Neural Network Exchange) 런타임의 미리 보기를 출시하게 되어 기쁩니다.
Content: "<p>ONNX<a href=\"https://onnx.ai/\" target=\"_blank\">(Open Neural Network Exchange)</a> 형식의 기계 학습 모델을 위한 고성능 유추 엔진인 ONNX 런타임의 미리 보기를 출시하게 되어 기쁩니다. ONNX 런타임은 ONNX 버전 1.2와 호환되며 <a href=\"https://pypi.org/project/onnxruntime/\" target=\"_blank\">CPU</a> 및 <a href=\"https://pypi.org/project/onnxruntime-gpu\" target=\"_blank\">GPU</a>를 모두 지원하는 Python 패키지로 제공되어 <a href=\"https://azure.microsoft.com/en-us/blog/what-s-new-in-azure-machine-learning-service/\" target=\"_blank\">Azure Machine Learning 서비스</a> 및 Ubuntu 16을 실행하는 모든 Linux 머신에서 추론을 사용하도록 설정합니다.</p>\n\n<p>ONNX는 딥 러닝 및 기존 기계 학습을 위한 오픈 소스 모델 형식입니다. 2017년 12월 ONNX를 출시한 이래 20개 이상의 업계 주요 기업으로부터 지원을 받고 있습니다. ONNX는 데이터 과학자와 개발자가 자신의 작업에 적합한 프레임워크를 자유롭게 선택할 수 있게 해주며, 선택한 하드웨어를 사용하여 다양한 플랫폼에서 모델을 효율적으로 실행할 수 있는 자신감을 제공합니다.</p>\n\n<p><a href=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/a811fb6a-c4eb-478c-b2e2-c94f710c7e9d.png\"><img alt=\"ONNX\" border=\"0\" height=\"355\" src=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/094b1b5f-5e21-483b-927d-f5d76422e9c1.png\" style=\"margin: 0px auto; border: 0px currentcolor; border-image: none; float: none; display: block; background-image: none;\" title=\"ONNX\" width=\"1176\"></a></p>\n\n<p>ONNX 런타임 유추 엔진은 ONNX에 정의된 모든 연산자를 포괄적으로 적용하고 지원합니다. 확장성 및 성능을 염두에 두고 개발된 이 기능은 플랫폼 및 하드웨어 선택에 따라 다양한 사용자 지정 가속기를 활용하여 컴퓨팅 대기 시간 및 리소스 사용량을 최소화합니다. 모델 내에서 정의된 플랫폼, 하드웨어 구성 및 연산자를 고려할 때 ONNX 런타임은 가장 효율적인 실행 공급자를 활용하여 추론을 위한 최상의 전반적인 성능을 제공할 수 있습니다.</p>\n\n<p>실행 공급자를 위한 플러그형 모델을 사용하면 ONNX 런타임이 새로운 소프트웨어 및 하드웨어 발전에 빠르게 적응할 수 있습니다. 실행 공급자 인터페이스는 하드웨어 가속기가 해당 기능을 ONNX 런타임에 노출하는 표준 방법입니다. Microsoft는 Intel 및 NVIDIA를 비롯한 회사와 적극적으로 협업하여 ONNX 런타임이 특수 하드웨어의 컴퓨팅 가속에 최적화되도록 합니다. 이러한 실행 공급자의 예로는 Intel&#39;MKL-DNN 및 nGraph뿐만 아니라 NVIDIA&#39;최적화된 TensorRT가 있습니다.</p>\n\n<p><a href=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/228d22d3-6e3e-48b1-811c-1d48353f031c.png\"><img alt=\"ONNXModel\" border=\"0\" height=\"563\" src=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/e7373906-1a6d-425c-8c03-da4bffd47fbb.png\" style=\"margin: 0px auto; border: 0px currentcolor; border-image: none; float: none; display: block; background-image: none;\" title=\"ONNXModel\" width=\"1193\"></a></p>\n\n<p>ONNX 런타임 릴리스는 Microsoft&#39;ONNX의 기존 지원을 통해 확장되어 다양한 플랫폼 및 디바이스에서 ONNX 모델의 추론을 실행할 수 있습니다.</p>\n\n<p><strong>Azure:</strong> ONNX 런타임 Python 패키지를 사용하여 Azure Machine Learning Azure Container Instance 또는 프로덕션 규모의 Azure Kubernetes Service로 사용하여 ONNX 모델을 클라우드에 배포할 수 있습니다. 다음은 시작하기 위한 몇 가지 <a href=\"https://aka.ms/onnxnotebooks\" target=\"_blank\">예</a> 입니다.</p>\n\n<p><strong>.NET:</strong>&nbsp; <a href=\"https://www.microsoft.com/net/apps/machinelearning-ai/ml-dotnet\" target=\"_blank\">ML.NET</a>을 사용하여 .NET 앱에 ONNX 모델을 통합할 수 있습니다.</p>\n\n<p><strong>Windows 디바이스:</strong> 최신 Windows 10 2018년 10월 업데이트에서 사용할 수 있는 기본 제공 Windows Machine Learning API를 사용하여 다양한 <a href=\"https://docs.microsoft.com/en-us/windows/ai/\" target=\"_blank\">Windows</a> 디바이스에서 ONNX 모델을 실행할 수 있습니다.</p>\n\n<p><a href=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/f9f13ccb-d84f-484a-a7c2-40d934e58635.png\"><img alt=\"CreateDeploy\" border=\"0\" height=\"613\" src=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/13189eea-5f0f-4ef9-83d1-92679b3a60f6.png\" style=\"margin: 0px auto; border: 0px currentcolor; border-image: none; float: none; display: block; background-image: none;\" title=\"CreateDeploy\" width=\"1271\"></a></p>\n\n<h2>ONNX 사용</h2>\n\n<h3>ONNX 모델 가져오기</h3>\n\n<p>ONNX 모델 가져오기는 간단합니다. <a href=\"https://github.com/onnx/models\" target=\"_blank\">ONNX 모델 Zoo</a>에서 미리 학습된 인기 있는 ONNX 모델 중에서 선택하거나, Azure Custom Vision 서비스를 사용하여 고유한 이미지 분류 모델을 빌드하거나, <a href=\"https://docs.microsoft.com/en-us/windows/ai/convert-model-winmltools\" target=\"_blank\">기존 모델을</a> 다른 프레임워크에서 ONNX로 변환하거나, <a href=\"https://github.com/Azure/MachineLearningNotebooks/tree/master/training\" target=\"_blank\">AzureML에서 사용자 지정 모델을 학습</a> 하고 ONNX 형식으로 저장합니다.</p>\n\n<p><a href=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/bd82ae3d-c003-4ffa-be31-213ab02b2c4f.png\"><img alt=\"4Ways\" border=\"0\" height=\"616\" src=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/a4b73ece-3c76-4e4a-a867-d6a8314fdc82.png\" style=\"margin: 0px auto; border: 0px currentcolor; border-image: none; float: none; display: block; background-image: none;\" title=\"4Ways\" width=\"821\"></a></p>\n\n<h2>ONNX 런타임을 사용한 추론</h2>\n\n<p>ONNX 형식의 학습된 모델이 있으면 유추를 위해 ONNX 런타임을 통해 모델을 공급할 준비가&#39;있습니다. 미리 빌드된 Python 패키지에는 다양한 실행 공급자와의 통합이 포함되며, 컴퓨팅 대기 시간 및 리소스 사용률이 낮습니다. GPU 빌드에는 CUDA 9.1이 필요합니다.</p>\n\n<p>시작하려면 Python 환경에서 PyPi에서 원하는 패키지를 설치합니다.</p>\n\n<pre>\npip install onnxruntime \npip install onnxruntime-gpu</pre>\n\n<p>그런 다음 유추 세션을 만들어 모델 작업을 시작합니다.</p>\n\n<pre>\nimport onnxruntime\nsession = onnxruntime.InferenceSession(&quot;your_model.onnx&quot;)  </pre>\n\n<p>마지막으로, 선택한 출력 및 입력을 사용하여 유추 세션을 실행하여 예측된 값을 가져옵니다.</p>\n\n<pre>\nprediction = session.run(None, {&quot;input1&quot;: value})</pre>\n\n<p>자세한 내용은 <a href=\"https://aka.ms/onnxruntime-python\" target=\"_blank\">전체 API 설명서를 참조하세요</a>.  </p>\n\n<p>이제 애플리케이션 또는 서비스에서 사용할 <a href=\"https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-build-deploy-onnx\" target=\"_blank\">ONNX 모델을 배포</a> 할 준비가 되었습니다.</p>\n\n<h2>오늘 시작</h2>\n\n<p>개방적이고 상호 운용 가능한 AI의 챔피언으로서 Microsoft는 새롭고 흥미로운 AI 혁신을 효율적으로 제공할 수 있도록 제품 및 도구를 구축하는 데 적극적으로 투자하고 있습니다. 커뮤니티가 참여하고 ONNX 런타임을 사용해 볼 수 있게 되어 기쁩니다! <a href=\"https://pypi.org/project/onnxruntime\" target=\"_blank\">ONNX 런타임을 설치하여</a> 오늘 시작하고 <a href=\"https://social.msdn.microsoft.com/Forums/en-US/home?forum=AzureMachineLearningService\" target=\"_blank\">Azure Machine Learning 서비스 포럼</a>에 대한 피드백을 알려주세요.</p>"
