### YamlMime:Yaml
ms.openlocfilehash: da23d3253c37a716e4476c3e95c836745090259c
ms.sourcegitcommit: d03bdc7fe5447adb6530886aab848b75fe8fa8ee
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 03/11/2022
ms.locfileid: "139900123"
Slug: understanding-hdinsight-spark-jobs-and-data-through-visualizations-in-the-jupyter-notebook
Title: Jupyter Notebook의 시각화를 통해 HDInsight Spark 작업 및 데이터 이해
Summary: HDInsight Spark 클러스터의 Jupyter Notebook은 데이터 세트를 빠르게 탐색하거나 추세 분석을 수행하거나 다른 기계 학습 모델을 시도해야 하는 경우에 유용합니다. Spark 작업 및 중간 데이터의 상태를 추적할 수 없으면 데이터 과학자가 Jupyter Notebook 내에서 수행하는 작업을 모니터링하고 최적화하기가 어려울 수 있습니다.
Content: >-
  <p>HDInsight Spark 클러스터의 Jupyter Notebook은 데이터 세트를 빠르게 탐색하거나 추세 분석을 수행하거나 다른 기계 학습 모델을 시도해야 하는 경우에 유용합니다. Spark 작업 및 중간 데이터의 상태를 추적할 수 없으면 데이터 과학자가 Jupyter Notebook 내에서 수행하는 작업을 모니터링하고 최적화하기가 어려울 수 있습니다.</p>


  <p>이러한 문제를 해결하기 위해 HDInsight Spark 클러스터 내 Jupyter Notebook에 최첨단 작업 실행 및 시각화 환경을 추가합니다. 오늘 실시간 <strong>Spark 작업 진행률 표시</strong>기, <strong>PySpark DataFrame에 대한 네이티브 matplotlib 지원</strong> 및 <strong>셀 실행 상태 표시</strong>기의 릴리스를 공유하게 되어 기쁩니다.</p>


  <h2>Spark 작업 진행률 표시기</h2>


  <p>Notebook 내에서 대화형 Spark 작업을 실행하면 작업 실행 상태를 이해하는 데 도움이 되는 실시간 진행률 표시줄이 있는 Spark 작업 진행률 표시기가 나타납니다. 탭을 전환하여 활성 작업 및 할당된 코어에 대한 리소스 사용률 보기 또는 전체 워크로드에 대한 작업, 단계 및 작업의 Gantt 차트를 볼 수도 있습니다.</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/2ad1b902-1396-4702-b922-77bae9895abd.gif"><img alt="Spark job progress indicator_thumb[2]" height="632" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/c87efc15-c26e-47d0-8f0e-07568d50ab49.gif" style="border-image: none; display: inline;" title="Spark 작업 진행률 indicator_thumb[2]" width="1037"></a></p>


  <h2>PySpark DataFrame에 대한 네이티브 matplotlib 지원</h2>


  <p>이전에는 PySpark가 matplotlib을 지원하지 않았습니다. 무언가를 그리려면 먼저 Spark 컨텍스트에서 PySpark DataFrame을 내보내고, 로컬 Python 세션으로 변환하고, 여기에서 플롯해야 합니다. 이 릴리스에서는 PySpark DataFrame에 대한 네이티브 matplotlib 지원을 제공합니다. 로컬에 있는 것처럼 PySpark DataFrame에서 직접 matplotlib을 사용할 수 있습니다. 클러스터 Spark 컨텍스트와 로컬 Python 세션 간에 데이터를 앞뒤로 전송할 필요가 없습니다.</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/b50132e2-a5c3-42c3-9d0a-58d834712e63.png"><img alt="Native matplotlib support for PySpark DataFrame_thumb[2]" border="0" height="661" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/88f0e5ea-deff-4d60-b1e5-b65ec5b7adaf.png" style="margin: 0px; border: 0px currentcolor; border-image: none; display: inline; background-image: none;" title="PySpark DataFrame_thumb 대한 네이티브 matplotlib 지원[2]" width="1430"></a></p>


  <h2>셀 실행 상태 표시기</h2>


  <p>현재 진행률을 확인할 수 있도록 셀 아래에 단계별 셀 실행 상태가 표시됩니다. 셀 실행이 완료되면 총 기간 및 종료 시간이 포함된 실행 요약이 표시되고 나중에 참조할 수 있습니다.</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/0f70a1aa-8aec-435c-91a0-689ab6ac1534.png"><img alt="Cell execution status indicator_thumb[4]" border="0" height="307" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/48f8bf95-01f0-4a1d-a07f-9e767f9fc253.png" style="border: 0px currentcolor; border-image: none; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;" title="셀 실행 상태 indicator_thumb[4]" width="654"></a></p>


  <h2>시작</h2>


  <p>이러한 기능은 HDInsight Spark Jupyter Notebook에 기본 제공됩니다. 시작하려면 <a href="https://portal.azure.com/" target="_blank">Azure Portal</a>에서 HDInsight에 액세스합니다. Spark 클러스터를 열고 빠른 링크에서 <strong>Jupyter Notebook</strong> 을 선택합니다.</p>


  <h2>피드백</h2>


  <p>여러분의 의견과 피드백을 기대합니다. 기능 요청, 요청 또는 제안이 있는 경우 메모를 <a href="mailto:cosctcs@microsoft.com">cosctcs@microsoft.com</a>보내주세요. 버그 제출의 경우 <a href="https://adsdevtool.visualstudio.com/AdsNotebook/_workitems/create/Bug?templateId=823ea6ab-c4bf-49a7-901c-992c28a3dfae&amp;ownerId=c1de5965-8400-47ec-9e5f-6018369d1f30" target="_blank">새 티켓을 여</a>세요.</p>


  <p>자세한 내용은 다음을 확인하세요:</p>


  <ul>
   <li><a href="https://docs.microsoft.com/en-us/azure/hdinsight/spark/apache-spark-jupyter-notebook-kernels" target="_blank">Azure HDInsight의 Spark 클러스터에서 Jupyter Notebook용 커널</a></li>
  </ul>
