### YamlMime:Yaml
ms.openlocfilehash: 380a710a5e145474436f20671ceb012749c18406
ms.sourcegitcommit: d03bdc7fe5447adb6530886aab848b75fe8fa8ee
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 03/11/2022
ms.locfileid: "139899972"
Slug: azure-hdinsight-now-supports-apache-spark-2-3
Title: 이제 Azure HDInsight에서 Apache Spark 2.3을 지원합니다.
Summary: Apache Spark 2.3.0은 이제 관리되는 빅 데이터 서비스 Azure HDInsight에서 프로덕션에 사용할 수 있습니다. 버그 수정(이 릴리스에서 1,400개 이상의 티켓이 수정됨)에서 새로운 실험적 기능 Apache Spark 2.3.0에 이르기까지 통합 데이터 플랫폼의 모든 영역에 향상된 기능과 세련미를 제공합니다.
Content: >-
  <p>Apache Spark 2.3.0은 이제 관리되는 빅 데이터 서비스 Azure HDInsight에서 프로덕션에 사용할 수 있습니다. 버그 수정(이 릴리스에서 1,400개 이상의 티켓이 수정됨)에서 새로운 실험적 기능에 이르기까지 Apache Spark 2.3.0은 통합 데이터 플랫폼의 모든 영역에 향상된 기능과 세련미를 제공합니다.</p>


  <p>Python UDF를 사용하는 데이터 엔지니어는 Spark 런타임과 Python 간의 향상된 개체 직렬화 덕분에 10배에서 100배 더 빠른 속도를 얻을 수 있습니다. 데이터 과학자는 TensorFlow와 같은 Deep Learning 프레임워크와 Spark Machine Learning 파이프라인의 더 나은 통합을 기쁘게 생각합니다. 비즈니스 분석가는 ORC 파일 형식에 대해 빠른 벡터화된 판독기의 가용성을 제공합니다. 그러면 Spark의 대화형 분석이 인기 있는 열 형식 데이터 형식보다 실용적입니다. 실시간 애플리케이션을 빌드하는 개발자는 이벤트 처리 대기 시간을 밀리초 수준으로 끌어올리는 Spark 구조적 스트리밍에서 새로운 연속 처리 모드를 실험하는 데 관심이 있을 수 있습니다.</p>


  <h2>Python UDF의 벡터화된 개체 직렬화</h2>


  <p>PySpark는 이미 빠르며 DataFrame API를 사용하는 한 핵심 Spark 엔진에서 벡터화된 데이터 처리를 활용합니다. Spark 2.x에 대한 <a href="https://channel9.msdn.com/Shows/Data-Exposed/Spark-Performance-Series-1-with-Maxim-Lukiyanov" target="_blank">모범 사례를</a> 따르는 경우 대부분의 사용 사례를 나타내기 때문에 좋은 소식입니다. 그러나 Spark 2.3까지는 이 규칙에 큰 예외가 하나 있었습니다. Python UDF를 사용하여 데이터를 처리한 경우 Spark는 표준 Python Pickle serialization 메커니즘을 사용하여 Java 런타임과 Python 런타임 간에 한 번에 한 행씩 데이터를 앞뒤로 전달합니다. Pickle은 강력한 메커니즘&rsquo;이지만 빅 데이터 워크로드가 테라바이트 단위의 데이터를 정기적으로 처리하는 경우 이 설정에서 효율적이지 않습니다. 버전 2.3부터 Spark는 Java와 Spark 런타임 간에 공통된 이진 형식의 열 형식 데이터 표현을 사용하는 새 화살표 serializer를 사용하도록 선택합니다. 이렇게 하면 최신 프로세서에서 벡터화된 처리가 가능하여 성능이 크게 향상됩니다. 새로운 기능은 새로운 Pandas UDF API를 통해 노출되므로 Python UDF에서 인기 있는 Pandas API를 사용할 수도 있습니다. 새 Pandas UDF API를 사용하여 UDF를 프로그래밍하면 성능이 10배에서 100배로 크게 향상됩니다. 새 기능은 기본적으로 사용하지 않도록 설정됩니다. 사용하도록 설정하려면 다음 속성을 true로 설정합니다.</p>


  <pre style="margin-left: 40px;">

  spark.sql.execution.arrow.enabled = true</pre>


  <h2>ORC 형식에 대한 빠른 네이티브 판독기</h2>


  <p>ORC 파일 형식에 대한 Spark 지원은 경쟁 Parquet에 비해 하위입니다. 두 형식 모두 데이터에 대한 효율적이고 열 지향적인 액세스와 동일한 문제를 해결합니다. 그러나 오랫동안 Spark는 ORC보다 Parquet 파일을 훨씬 더 잘 사용했습니다. Hortonworks가 ORC 파일 형식에 대한 빠른 네이티브 벡터화 판독기 제공 Spark 2.3.0에서 이러한 모든 변경 내용. 새로운 네이티브 리더는 쿼리 속도를 2배에서 5배로 단축하여 Parquet 속도와의 경쟁에 정면으로 맞섰습니다. 이 수준의 성능은 혼합 시나리오를 실용적으로 만듭니다. 예를 들어 HDInsight의 고객은 Hive LLAP 기술로 구동되는 <a href="https://docs.microsoft.com/en-us/azure/hdinsight/interactive-query/apache-interactive-query-get-started" target="_blank">대화형 쿼리</a> 클러스터의 ORC 형식을 자주 선택합니다. 이제 공유 ORC 데이터 세트에 대해 Spark에서 데이터 과학을 보다 효율적으로 수행할 수 있습니다.</p>


  <p>새로운 벡터화된 판독기/작성기는 네이티브 구현을 제공 할뿐만 아니라 이전 코드 베이스의 몇 가지 문제를 해결하는 완전히 다시 디자인 된 코드 기반입니다. 이제 ORC 작성기는 최신 ORC 형식과 호환되는 버전을 생성하고, 조건자 푸시다운을 지원하며, 구조적 스트리밍 작업에서 형식 사용 문제를 해결합니다. 이제 새 ORC 형식은 테이블에 추가된 데이터 파일이 진화함에 따라 사용자가 열을 추가/제거할 수 있는 스키마 진화를 지원합니다. Parquet 판독기와 달리 열 형식을 서로 업캐스트할 수 있는 경우(예: float -&gt; double) 변경도 지원합니다. 이로 인해 ORC 판독기는 Parquet보다 앞서지만 몇 가지 제한 사항은 남아 있습니다. 그 중 하나는 ORC 판독기에서 아직 지원되지 않고 Parquet에서만 사용할 수 있는 강력한 기술 버킷팅입니다. Spark 2.3.0에서는 이전 버전과의 호환성을 위해 기본적으로 새 네이티브 판독기는 사용하도록 설정되지 않습니다. 사용 사례의 스펙트럼에서 사용하도록 설정하려면 다음 속성을 변경합니다.</p>


  <pre style="margin-left: 40px;">

  spark.sql.orc.impl=native

  spark.sql.hive.convertMetastoreOrc=true</pre>


  <h2>구조적 스트리밍의 연속 처리(실험적)</h2>


  <p>연속 처리 모드는 이제 Spark 구조적 스트리밍의 일부입니다. Spark의 마이크로 일괄 처리 아키텍처에서 벗어나 개별 이벤트의 진정한 스트리밍 처리를 제공하는 스트리밍 작업을 위한 새로운 실행 엔진입니다. 새 모드의 장점은 이벤트 처리 대기 시간이 크게 향상되어 이제는 밀리초 미만이 될 수 있습니다. 이는 사기 감지, 광고 배치 및 메시지 버스 아키텍처와 같은 대기 시간에 중요한 사용 사례에 중요합니다. 또한 구조화된 스트리밍 작업에서 활성화하는 것은 매우 쉬울 뿐이며 트리거 모드를 <strong>Trigger.Continuous</strong> 로 설정하고 나머지 작업은 변경되지 않은 상태로 유지됩니다.</p>


  <p>실험적 기능 외에도 이 새로운 기능에는 상당한 제한 사항이 있습니다. 연속 처리 모드(map-select, filter-where)에서 맵 형식의 작업만 지원되며 메시지 처리의 배달 보장은 약합니다. 구조적 스트리밍의 표준 마이크로 일괄 처리 모드는 정확히 한 번만 지원하지만 연속 모드는 최소 한 번 이상의 이벤트 처리 보장만 지원합니다.</p>


  <p style="margin-left: 40px;"><img alt="Code" border="0" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/Spark-2-3-0-continuous-streaming.png" style="border: 0px currentcolor; border-image: none; width: 513px; height: 146px; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;"></p>


  <h2>기타 개선 기능</h2>


  <h3>스트림-스트림 조인</h3>


  <p>원래 Spark 2.0에서 구조적 스트리밍이 도입되었을 때 정적 조인에 대한 스트림만 지원되었습니다. 이는 두 개의 데이터 스트림을 상호 연결해야 하는 여러 시나리오에 대해 제한됩니다. Spark 2.3을 사용하면 이제 두 개의 스트림을 조인할 수 있습니다. 워터마크 및 시간 제약 조건을 사용하여 조인을 수행하기 위해 버퍼링할 두 스트림의 데이터 양을 제어할 수 있습니다.</p>


  <h3>딥 러닝 통합</h3>


  <p>이제 Spark를 사용하여 인기 있는 Deep Learning 라이브러리 TensorFlow(및 Keras)의 모델을 Spark ML 라이브러리 변환기로 통합할 수 있습니다. 이를 돕기 위해 파일에서 이미지를 읽고 DataFrame으로 나타내는 기본 제공 함수도 제공합니다.</p>


  <h3>DataSource API v2(베타)</h3>


  <p>Spark의 장점 중 하나는 다양한 데이터 원본에 대한 광범위한 지원입니다. Cassandra, HBase, Azure Blob Storage, 새 <a href="https://azure.microsoft.com/en-us/blog/a-closer-look-at-azure-data-lake-storage-gen2/" target="_blank">Azure Data Lake Storage(gen2)</a> 또는 많은 다른 사용자에 연결하고 Spark를 사용하여 일관된 방식으로 데이터를 처리할 수 있습니다. 새 버전에서 이 데이터 원본을 만드는 데 사용되는 API는 주요 리팩터링을 가져옵니다. 새 API는 SparkContext 및 DataFrame과 같은 상위 수준 클래스에 대한 종속성을 없애고 데이터 원본 개발자가 더 많은 최적화를 구현할 수 있도록 하는 광범위한 기본 형식 집합을 위한 컴팩트하고 정확한 인터페이스를 제공합니다. 여기에는 데이터 크기 및 분할 정보, 스트리밍 원본에 대한 지원, 일괄 처리 지향 데이터 및 트랜잭션 쓰기에 대한 지원이 포함됩니다. 이러한 모든 변경 내용은 Spark 최종 사용자에게 투명합니다.</p>


  <h3>Kubernetes의 Spark(실험적)</h3>


  <p>Kubernetes 클러스터링 프레임워크의 인기가 증가함에 따라 Spark는 Kubernetes 클러스터에서 직접 Spark 작업을 예약하는 네이티브 기능을 가져옵니다. 기본 이미지는 Spark와 함께 제공되며 동적으로 또는 사용자 지정 이미지의 기반으로 앱을 로드하는 데 사용할 수 있지만 작업은 리포지토리의 어딘가에 Docker 이미지로 지정되어야 합니다.</p>


  <p><a href="https://azure.microsoft.com/en-us/services/hdinsight/apache-spark/" target="_blank">HDInsight Spark</a>에 대한 자세한 내용을 확인할 수 있습니다. <a href="https://spark.apache.org/releases/spark-release-2-3-0.html" target="_blank">Spark 2.3.0 릴리스 정보</a>에서 해결된 문제에 대한 자세한 목록을 찾을 수도 있습니다.</p>


  <h2>지금 HDInsight 사용해 보기</h2>


  <p>새로운 Spark 기능을 최대한 활용할 수 있기를 바라며, Azure HDInsight를 사용하여 빌드할 기능을 확인하게 되어 기쁩니다. <a href="https://azure.microsoft.com/en-us/blog/azure-hdinsight-training-resources-learn-about-big-data-using-open-source-technologies/" target="_blank">이 개발자 가이드를 읽고</a> 빠른 시작 가이드에 따라 Azure HDInsight에서 이러한 파이프라인 및 아키텍처를 구현하는 방법에 대해 자세히 알아보세요. Twitter <a href="https://twitter.com/search?q=%23HDInsight&amp;src=typd" target="_blank">#HDInsight</a> 및 에 대한 팔로우를 통해 최신 Azure HDInsight 뉴스 및 <a href="https://twitter.com/AzureHDInsight" target="_blank">@AzureHDInsight</a>기능을 최신 상태로 유지하세요. 질문 및 피드백은 다음으로 <a href="mailto:AskHDInsight@microsoft.com">AskHDInsight@microsoft.com</a>문의하세요.</p>


  <h2>HDInsight 정보</h2>


  <p>Azure HDInsight는 Azure에서 오픈 소스 워크로드를 실행하기 위한 Microsofts&rsquo; 프리미엄 관리 제품입니다. 오늘 다양한 OSS 프레임워크에서 몇 가지 새로운 기능을 발표하게 되어 기쁩니다.</p>


  <p>Azure HDInsight는 제조, 소매 교육, 비영리, 정부, 의료, 미디어, 은행, 통신, 보험 및 ETL에서 데이터 웨어하우징에 이르는 사용 사례, Machine Learning IoT 등 다양한 분야에 이르는 다양한 분야에 이르는 최고의 고객&rsquo; 업무용 애플리케이션을 지원합니다.</p>
