### YamlMime:Yaml
ms.openlocfilehash: a47a88cce646bd961f880ddf4069d42461bc2516
ms.sourcegitcommit: d03bdc7fe5447adb6530886aab848b75fe8fa8ee
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 03/11/2022
ms.locfileid: "139912968"
Slug: face-and-emotion-detection
Title: Azure Media Analytics에 대한 얼굴 및 감정 감지 발표
Summary: 공개 미리 보기용 Azure Face Detector 미디어 프로세서를 발표하게 되어 기쁩니다.
Content: >-
  <p>Azure Media Analytics는 엔터프라이즈 규모, 규정 준수, 보안 및 글로벌 범위에서 제공되는 음성 및 비전 서비스의 컬렉션입니다. Azure Media Analytics의 일부로 제공되는 서비스는 핵심 Azure Media Services 플랫폼 구성 요소를 사용하여 빌드되므로 첫날 자체에 대규모로 미디어 처리를 처리할 준비가 되어 있습니다. 이 공지 사항에 포함된 다른 미디어 프로세서는 Milan Gadas 블로그 게시물 <a href="https://azure.microsoft.com/en-us/blog/introducing-azure-media-analytics" target="_blank">소개 Azure Media Analytics를 참조하세요</a>.</p>


  <p>우리는 Azure Media Face Detector 무료 공개 미리 보기에 매우 기쁘게 생각하고,이 블로그는이 기술의 사용과 출력을 자세히 설명합니다. 이 MP(미디어 프로세서)는 얼굴 표정을 통해 계산, 이동 추적 및 청중 참여 및 반응을 측정하는 데 사용할 수 있습니다. 새 Azure Portal, 아래 사전 설정이 있는 API를 통해 또는 무료 Azure Media Services 탐색기 도구를 사용하여 이러한 기능에 액세스할 수 있습니다. 이 서비스에는 얼굴 감지 및 감정 감지라는 두 가지 기능이 포함되어 있으며&rsquo; Ill은 해당 순서대로 세부 정보를 확인합니다.</p>


  <h2>얼굴 감지</h2>


  <p>얼굴 검색은 동영상 내의 얼굴을 찾아 추적합니다. 여러 얼굴이 검색될 수 있으며 이후 JSON 파일로 반환되는 시간 및 위치 메타데이터를 사용하여 얼굴이 움직일 때마다 추적할 수 있습니다. 추적하는 동안 화면에서 사용자가 움직일 때, 가려지거나 프레임에서 잠시 벗어나는 경우에도 동일한 얼굴에 일관된 ID를 지정하려고 합니다.</p>


  <blockquote>

  <p>참고: 이 서비스는 얼굴 인식을 수행하지 않습니다. 너무 오래 프레임에서 벗어나있거나 가려지는 경우에는 다시 돌아왔을 때 새 ID가 지정됩니다.</p>

  </blockquote>


  <h3>입력 사전 설정</h3>


  <p>얼굴 감지를 위한 JSON 구성 사전 설정의 이단&rsquo; 및 예제입니다.</p>


  <pre class="prettyprint">


  &nbsp;</pre>


  <p>{&quot;version&quot;:&quot;1.0&quot;}</p>


  <h3>입력 동영상</h3>


  <p><iframe align="center" frameborder="no" height="350" name="azuremediaplayer" scrolling="no" src="//aka.ms/ampembed?url=https%3A%2F%2Freferencestream-samplestream.streaming.mediaservices.windows.net%2Fc8834d9f-0b49-4b38-bcaf-ece2746f1972%2FMicrosoft%20Convergence%202015%20%20Keynote%20Highlights.ism%2Fmanifest&amp;autoplay=false" width="625"></iframe></p>


  <h3>JSON 출력</h3>


  <p>(잘림)</p>


  <pre class="prettyprint">


  &nbsp;</pre>


  <p><a href="https://nimbuspmblu.blob.core.windows.net/asset-65042ee0-c677-47af-a5f7-b3a10425dae5/Microsoft%20Convergence%202015%20%20Keyn_1280x720_4500_facedetection.json?sv=2012-02-12&amp;sr=c&amp;si=1efac1f3-db57-4ed0-ae66-ed311fda02f3&amp;sig=TvEfqSQB6d8mT7kV7J%2BgfbueQg3TF9BWTDCcdX3JhwQ%3D&amp;se=2026-04-10T18%3A43%3A37Z" target="_blank">전체 다운로드</a></p>


  <div class="csharpcode-wrapper" id="codeSnippetWrapper">

  <p>{<br>

  &nbsp;&quot;버전&quot;: 1,<br>

  &nbsp;&quot;timescale&quot;: 30000,<br>

  &nbsp;&quot;offset&quot;: 0,<br>

  &nbsp;&quot;framerate&quot;: 29.97,<br>

  &nbsp;&quot;width&quot;: 1280,<br>

  &nbsp;&quot;높이&quot;: 720,<br>

  &nbsp;&quot;&quot;조각: [<br>

  &nbsp;&nbsp;&nbsp; {<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;start&quot;: 0,<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;기간&quot;: 60060<br>

  &nbsp;&nbsp;&nbsp; },<br>

  &nbsp;&nbsp;&nbsp; {<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;start&quot;: 60060,<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;기간&quot;: 60060,<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;간격&quot;: 1001,<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;events&quot;: [<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; {<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;id&quot;: 0,<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;x&quot;: 0.519531,<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;y&quot;: 0.180556,<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;width&quot;: 0.0867188,<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;height&quot;: 0.154167<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ],<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; {<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;id&quot;: 0,<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;x&quot;: 0.517969,<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;y&quot;: 0.181944,<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;width&quot;: 0.0867188,<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;height&quot;: 0.154167<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ],</p>

  </div>


  <h2>감정 감지</h2>


  <p>감정 감지는 행복, 슬픔, 두려움, 분노 등을 포함하여 감지된 얼굴의 여러 정서적 특성에 대한 분석을 반환하는 얼굴 감지 미디어 프로세서의 선택적 구성 요소입니다. 이 데이터는 현재 사용자 지정 가능한 창 및 간격을 통해 전체 창의 집계 값으로 반환됩니다.</p>


  <h3>입력 구성</h3>


  <p>JSON 사전 설정 샘플:</p>


  <pre class="prettyprint">


  &nbsp;</pre>


  <p>{<br>

  &nbsp; &#39;버전&#39;: &#39;1.0&#39;<br>

  &nbsp; &#39;옵션&#39;: {<br>

  &nbsp;&nbsp;&nbsp; &#39;aggregateEmotionWindowMs&#39;: &#39;987&#39;<br>

  &nbsp;&nbsp;&nbsp; &#39;모드&#39;: &#39;aggregateEmotion&#39;<br>

  &nbsp;&nbsp;&nbsp; &#39;aggregateEmotionIntervalMs&#39;: &#39;342&#39;<br>

  &nbsp; }<br>

  }</p>


  <table border="0" cellpadding="2" cellspacing="0" width="791">
      <tbody>
          <tr>
              <td valign="top" width="133">
              <p>특성 이름</p>
              </td>
              <td valign="top" width="677">
              <p>설명</p>
              </td>
          </tr>
          <tr>
              <td valign="top" width="133">Mode</td>
              <td valign="top" width="677">얼굴: 얼굴 감지만<br>
              AggregateEmotion: 프레임의 모든 얼굴에 대한 평균 감정 값을 반환합니다.</td>
          </tr>
          <tr>
              <td valign="top" width="133">AggregateEmotionWindowMs</td>
              <td valign="top" width="677">AggregateEmotion 모드가 선택된 경우 사용: 각 집계 결과를 생성하는 데 사용되는 비디오 길이(밀리초)입니다.</td>
          </tr>
          <tr>
              <td valign="top" width="133">AggregateEmotionIntervalMs</td>
              <td valign="top" width="677">AggregateEmotion 모드가 선택된 경우 사용: 집계 결과를 생성하는 빈도입니다.</td>
          </tr>
      </tbody>
  </table>


  <h3>집계 기본값</h3>


  <p>집계 창 및 간격 설정에는 아래 값이 권장됩니다. 기간은 간격보다 길어야 합니다.</p>


  <table border="0" cellpadding="2" cellspacing="0" width="400">
      <tbody>
          <tr>
              <td valign="top" width="107">&nbsp;</td>
              <td valign="top" width="107">기본값(s)</td>
              <td valign="top" width="97">최대(s)</td>
              <td valign="top" width="87">최소(s)</td>
          </tr>
          <tr>
              <td valign="top" width="107">창 길이</td>
              <td valign="top" width="107">2</td>
              <td valign="top" width="97">3</td>
              <td valign="top" width="87">1</td>
          </tr>
          <tr>
              <td valign="top" width="107">간격</td>
              <td valign="top" width="111">0.5</td>
              <td valign="top" width="106">1</td>
              <td valign="top" width="106">0.25</td>
          </tr>
      </tbody>
  </table>


  <h3>출력</h3>


  <p>집계 감정에 대한 JSON 출력(잘림)</p>


  <pre class="prettyprint">


  &nbsp;</pre>


  <p><a href="https://referencestream-samplestream.streaming.mediaservices.windows.net/2b4a8e81-f2b6-419c-9a1d-0db02cec994c/Microsoft%20Convergence%202015%20%20Keyn_1280x720_4500_aggregateemotion.json" target="_blank">전체 다운로드</a></p>


  <p>{<br>

  &nbsp;&quot;버전&quot;: 1,<br>

  &nbsp;&quot;timescale&quot;: 30000,<br>

  &nbsp;&quot;offset&quot;: 0,<br>

  &nbsp;&quot;framerate&quot;: 29.97,<br>

  &nbsp;&quot;width&quot;: 1280,<br>

  &nbsp;&quot;높이&quot;: 720,<br>

  &nbsp;&quot;&quot;조각: [<br>

  &nbsp;&nbsp;&nbsp; {<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;start&quot;: 0,<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;기간&quot;: 60060,<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;간격&quot;: 15015,<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;events&quot;: [<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; {<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;windowFaceDistribution&quot;: {<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;중립&quot;: 0,<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;&quot;행복: 0,<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;서프라이즈&quot;: 0,<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;슬픔&quot;: 0,<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;분노&quot;: 0,<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;혐오&quot;: 0,<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;두려움&quot;: 0,<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;경멸&quot;: 0<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; },<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;windowMeanScores&quot;: {<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;중립&quot;: 0,<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;&quot;행복: 0,<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;서프라이즈&quot;: 0,<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;슬픔&quot;: 0,<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;분노&quot;: 0,<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;혐오&quot;: 0,<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;두려움&quot;: 0,<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;경멸&quot;: 0<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<br>

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ],</p>


  <h2>출력 이해</h2>


  <p>얼굴 검색 및 추적 API는 한 동영상 내에서 최대 64명의 얼굴을 검색할 수 있는 고정밀도 얼굴 위치 검색 및 추적을 제공합니다. 정면이 최상의 결과를 제공하며 측면 또는 작은 얼굴(24x24 픽셀보다 작거나 같음)의 경우에는 어려울 수 있습니다.</p>


  <p>검색 및 추적된 얼굴은 개별적인 추적을 나타내는 얼굴 ID 번호뿐만 아니라 이미지 내에서 얼굴의 위치를 픽셀 단위로 나타내는 좌표(왼쪽, 위쪽, 너비 및 높이)와 함께 반환됩니다. 얼굴 ID 번호는 프레임 안에 정면 얼굴이 없거나 겹쳐진 상황에서 재설정될 가능성이 크므로 결과적으로 일부 사용자에게 여러 ID가 할당될 수 있습니다.</p>


  <h3>JSON 참조</h3>


  <p>얼굴 검색 및 추적 작업의 경우 출력 결과는 지정된 파일 내에서 얼굴에 대한 메타데이터를 JSON 형식으로 포함합니다.</p>


  <p>얼굴 검색 및 추적 JSON에는 다음 특성이 포함됩니다.</p>


  <ul>
      <li><b>버전</b>: Video API의 버전을 참조합니다.</li>
      <li><b>시간 표시줄</b>: &ldquo;비디오의 초당 틱&rdquo; 수입니다.</li>
      <li><b>오프셋</b>: 타임스탬프의 시간 오프셋입니다. 동영상 API 버전 1.0에서는 항상 0입니다. 향후 지원하는 시나리오에서는 이 값이 변경될 수 있습니다.</li>
      <li><b>프레임 속도</b>: 비디오의 초당 프레임 수입니다.</li>
      <li><b>조각</b>: 메타데이터는 조각이라고 하는 여러 세그먼트로 분할됩니다. 각 조각에는 시작, 기간, 간격 번호 및 이벤트가 포함됩니다.</li>
      <li><b>시작</b>: 첫 번째 이벤트의 시작 시간(틱) &lsquo;입니다&rsquo;.</li>
      <li><b>기간</b>: 조각의 길이(틱) &ldquo;입니다&rdquo;.</li>
      <li><b>간격</b>: 조각 내의 각 이벤트 항목 간격(틱) &ldquo;입니다&rdquo;.</li>
      <li><b>이벤트</b>: 각 이벤트에는 해당 기간 내에 감지되고 추적된 얼굴이 포함됩니다. 이벤트 배열입니다. 외부 배열은 하나의 시간 간격을 나타냅니다. 내부 배열은 해당 특정 시점에 발생한 0개 이상의 이벤트로 구성됩니다. 빈 대괄호 []는 얼굴이 검색되지 않음을 의미합니다.</li>
      <li><b>ID</b>: 추적 중인 얼굴의 ID입니다. 이 번호는 얼굴이 검색되지 않는 경우 실수로 변경될 수 있습니다. 지정된 사용자는 동영상 전체에서 동일한 ID를 가져야 하지만 검색 알고리즘의 한계(폐색 등)로 인해 보장될 수 없습니다.</li>
      <li><b>X, Y</b>: 0.0에서 1.0으로 정규화된 배율로 얼굴 경계 상자의 왼쪽 위 X 및 Y 좌표입니다.
      <ul>
          <li>X 및 Y 좌표는 항상 가로를 기준으로 하므로 세로(또는 iOS의 경우 거꾸로) 비디오가 있는 경우 그에 따라 좌표를 변환해야&#39;.</li>
      </ul>
      </li>
      <li><b>너비</b>, <b>높이</b>: 0.0에서 1.0까지의 정규화된 눈금에 있는 얼굴 경계 상자의 너비 및 높이입니다.</li>
      <li><b>facesDetected</b>: JSON 결과의 끝에서 발견되며 비디오 중에 알고리즘이 감지한 얼굴 수를 요약합니다. 얼굴이 검색되지 않는 경우(예: 얼굴이 화면 밖으로 나가거나 멀어짐) ID가 재설정될 수 있으므로 이 수는 동영상 내에 있는 실제 얼굴 수와 항상 같지 않을 수도 있습니다.</li>
  </ul>


  <p>이러한 방식으로 JSON 형식을 지정한 이유는 향후 시나리오에 맞게 API를 설정하기 위해서입니다. 메타데이터를 신속하게 검색하고 대량의 결과 스트림을 관리하는 것이 중요합니다. 조각화 기법(필요한 것만 다운로드할 수 있는 시간 기반 청크에서 메타데이터를 분할할 수 있음) 및 분할(이벤트가 너무 커지면 이벤트를 분할할 수 있음)을 모두 사용합니다. 몇 가지 간단한 계산으로 데이터를 변환할 수 있습니다. 예를 들어 이벤트가 6300(틱)에서 시작하고 날짜 표시줄이 2997(틱/초), 프레임 속도가 29.97(프레임/초)인 경우 다음과 같습니다.</p>


  <p>&middot; 시작/시간 표시줄 = 2.1초</p>


  <p>&middot; 초 x(프레임 속도/날짜 표시줄) = 63프레임</p>


  <p>다음은 얼굴 검색 및 추적을 위해 JSON을 프레임 형식별로 추출하는 간단한 샘플 예제입니다.</p>


  <pre class="prettyprint">


  &nbsp;</pre>


  <p>var faceDetectionResultJsonString = operationResult.ProcessingResult;<br>

  var faceDetecionTracking =<br>

  &nbsp;&nbsp;&nbsp;JsonConvert.DeserializeObjectFaceDetectionResult&lt;&gt;(faceDetectionResultJsonString, settings);</p>


  <h2>시작</h2>


  <p>이 서비스를 사용하려면 azure 구독 내에서 Media Services 계정을 만들고 <a href="https://azure.microsoft.com/en-us/develop/media-services/">REST API/SDK</a> 또는 <a href="https://aka.ms/amse">Azure Media Services Explorer</a>와 함께&nbsp; 사용하기만 하면 됩니다.</p>


  <p>샘플 코드는 <a href="https://azure.microsoft.com/en-us/documentation/articles/media-services-face-and-emotion-detection/" target="_blank">설명서 페이지에서</a> 샘플 코드를 확인하세요.</p>


  <h3>제한 사항</h3>


  <ul>
      <li>지원되는 입력 동영상 형식에는 MP4, MOV 및 WMV가 있습니다.</li>
      <li>검색 가능한 얼굴 크기 범위는 24x24 픽셀에서 2048x2048 픽셀입니다. 이 범위를 벗어난 얼굴은 검색되지 않습니다.</li>
      <li>각 동영상에서 반환되는 최대 얼굴 수는 64입니다.</li>
      <li>일부 얼굴은 기술적인 문제(예: 매우 큰 얼굴 각도(머리 포즈) 및 큰 폐색)로 인해 검색되지 않을 수 있습니다. 정면 및 정면에 가까운 얼굴이 최상의 결과를 생성합니다.</li>
  </ul>


  <h3>문의처</h3>


  <p>얼굴 감지 미디어 프로세서 및 Media Analytics 이니셔티브에 대한 추가 업데이트를 들으려면 <a href="https://azure.microsoft.com/en-us/blog/topics/media-services-2/">Azure Media Services 블로그</a>를 계속 진행하세요!</p>


  <p>Media Analytics 제품에 대한 질문이 있는 경우 전자 메일을 <a href="mailto:amsanalytics@microsoft.com">amsanalytics@microsoft.com</a>보내세요.</p>
