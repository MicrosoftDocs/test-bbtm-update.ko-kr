### YamlMime:Yaml
ms.openlocfilehash: 534f505325791320a1be2fec3bf833373c963fd1
ms.sourcegitcommit: d03bdc7fe5447adb6530886aab848b75fe8fa8ee
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 03/11/2022
ms.locfileid: "139899332"
Slug: azure-data-factory-update-new-data-stores
Title: Azure Data Factory 업데이트 – 새 데이터 저장소
Summary: 최신 서비스 업데이트 및 데이터 관리 게이트웨이 릴리스를 사용하면 새 데이터 저장소에 연결하고 새 기능을 활용하여 Azure Data Factory를 사용하여 데이터를 이동할 수 있습니다.
Content: >-
  최신 서비스 업데이트 및 <a href="https://www.microsoft.com/en-us/download/details.aspx?id=39717">데이터 관리 게이트웨이</a> 릴리스를 사용하면 새 데이터 저장소에 연결하고 새 기능을 활용하여 다음을 포함하여 Azure Data Factory를 사용하여 데이터를 이동할 수 있습니다.

  <ul>
      <li>온-프레미스 파일 시스템에서 Azure Blob으로 복사</li>
      <li>온-프레미스 Oracle Database에서 Azure Blob으로 복사</li>
      <li>텍스트 파일에 대한 인코딩 지정</li>
      <li>SQL 싱크로 복사하기 위한 추가 매개 변수를 사용하여 저장 프로시저 호출</li>
  </ul>

  자세한 내용은 다음 섹션을 참조하세요.


  <!--more-->

  <h2>온-프레미스 파일 시스템에서 Azure Blob으로 파일 복사</h2>

  Azure Data Factory는 온-프레미스 파일 시스템, Windows 및 Linux 네트워크 공유 또는 Windows 로컬 호스트에서 데이터 팩터리 파이프라인을 사용하여 Azure Blob으로 파일을 복사할 수 있는 새로운 기능을 릴리스했습니다.


  다음 예제를 시작해 보겠습니다.

  <ul>
      <li>호스트: \\contoso</li>
      <li>폴더: marketingcampaignregionaldata\\\\{slice}, 파일은 2014121112(2014년, 월 12일, 11일, 시간 12)과 같이 {slice}라는 폴더에 분할됩니다.</li>
  </ul>

  호스트는 Windows 또는 Samba가 구성된 Linux일 수 있습니다. 데이터 관리 게이트웨이는 호스트에 연결할 수 있는 Windows 컴퓨터에 설치해야 합니다.


  이제 Azure Data Factory를 활용하여 조각에 포함된 파일을 Azure Blob에 복사해 보겠습니다.


  먼저 온-프레미스 파일 시스템 연결된 서비스를 정의해 보겠습니다.

  <pre>{
      "name": "FolderDataStore",
      "properties": {
          "type": "OnPremisesFileSystemLinkedService",
          "host": "\\\\contoso",
          "userId": "username",
          "password": "password",
          "gatewayName": "ContosoGateway"
      }
  }

  </pre>

  JSON에 필요한 호스트 이름에서 "\" 문자를 이스케이프해야 합니다.


  다음 JSON 스크립트는 이전에 정의된 온-프레미스 파일 시스템을 참조하는 입력 테이블을 정의합니다.

  <pre>{
      "name": "OnPremFileSource",
      "properties": {
          "location": {
              "type": "OnPremisesFileSystemLocation",
              "folderPath": "marketingcampaign\\regionaldata\\{Slice}",
              "partitionedBy": [
                  { "name": "Slice", "value": { "type": "DateTime", "date": "SliceStart", "format": "yyyyMMddHH" } }
              ],
              "linkedServiceName": "FolderDataStore"
          },
          "availability": {
              "waitOnExternal": { },
              "frequency": "Hour",
              "interval": 24
          }
      }
  }

  </pre>

  여기서 partitonedBy 속성은 조각을 정의하는 데 사용됩니다. 호스트 이름에서 "\" 문자를 이스케이프해야 하며, folderPath에 선행 "\"을 추가하지 마세요.


  이제 복사 작업으로 파이프라인을 쉽게 작성하여 파일 시스템의 파일을 Azure Blob에 복제할 수 있습니다. 콘텐츠는 구문 분석이나 변환 없이 이진 파일로 복사됩니다.

  <pre>{
      "name": "CopyFileToBlobPipeline",
      "properties": {
          "activities": [
              {
                  "name": "Ingress",
                  "inputs": [ { "name": "OnPremFileSource" } ],
                  "outputs": [ { "name": "AzureBlobDest" } ],
                  "type": "CopyActivity",
                  "transformation": {
                      "source": {
                          "type": "FileSystemSource"
                      },
                      "sink": {
                          "type": "BlobSink"
                      }
                  },
                  "policy": {
                      "concurrency": 4,
                      "timeout": "00:05:00"
                  }
              }
          ]
      }
  }

  </pre>

  동시성을 활용하여 파일 조각을 병렬로 복사할 수 있습니다. 이는 과거에 이미 발생한 조각을 이동하려는 경우에 유용합니다.


  주의 사항: 다른 사용자 계정이 있는 UNC 경로를 통해 동일한 호스트와 동시 복사 작업을 수행하면 오류가 발생할 수 있습니다. 예를 들어 "둘 이상의 사용자 이름을 사용하는 동일한 사용자가 서버 또는 공유 리소스에 여러 번 연결할 수 없습니다."와 같은 오류가 발생할 수 있습니다. 이는 보안상의 이유로 OS의 제한 사항입니다. 다른 게이트웨이를 사용하여 복사 작업을 예약하거나 호스트 내에 게이트웨이를 설치하고 UNC 경로 대신 "localhost" 또는 "local"을 사용하세요.


  파티션 외에도 더 많은 복사 시나리오를 사용할 수 있습니다.


  <strong>예제 1:</strong> 특정 폴더 아래에 있는 모든 파일 복사

  <pre>{
      "name": "OnPremFileSource",
      "properties": {
          "location": {
              "type": "OnPremisesFileSystemLocation",
              "folderPath": "marketingcampaign\\regionaldata\\na",
              "linkedServiceName": "FolderDataStore"
          },
          ...
      }
  }

  </pre>

  <strong>예제 2:</strong> 특정 폴더 아래에 있는 모든 CSV 파일 복사

  <pre>{
      "name": "OnPremFileSource",
      "properties": {
          "location": {
              "type": "OnPremisesFileSystemLocation",
              "folderPath": "marketingcampaign\\regionaldata\\na",
              "fileFilter": "*.csv",
              "linkedServiceName": "FolderDataStore"
          },
          ...
      }
  }

  </pre>

  <strong>예제 3:</strong> 특정 파일 복사

  <pre>{
      "name": "OnPremFileSource",
      "properties": {
          "location": {
              "type": "OnPremisesFileSystemLocation",
              "folderPath": "marketingcampaign\\regionaldata\\na",
              "fileFilter": "201501.csv",
              "linkedServiceName": "FolderDataStore"
          },
          ...
      }
  }

  </pre>

  자세한 내용은 <a href="https://msdn.microsoft.com/en-us/library/azure/dn930836.aspx">온-프레미스 파일 시스템 연결된 서비스를 확인하세요</a>.

  <h2>온-프레미스 Oracle Database에서 Azure Blob으로 복사</h2>

  Azure Data Factory는 추가 데이터 처리를 위해 온-프레미스 Oracle 데이터베이스에서 Azure Blob으로 파일을 복사할 수 있도록 하는 새로운 기능을 릴리스했습니다.


  먼저 Oracle 연결된 서비스를 정의해 보겠습니다. 자세한 연결 문자열 형식은 <a href="https://docs.oracle.com/cd/B28359_01/win.111/b28375/featConnecting.htm">Oracle 커넥트 설명자를</a> 참조하세요.

  <pre>{
      "name": "LinkedServiceOracle",
      "properties": {
          "type": "OnPremisesOracleLinkedService",
          "ConnectionString": "data source=ds;User Id=uid;Password=pwd;",
          "gatewayName": "SomeGateway"
      }
  }

  </pre>

  그런 다음, 온-프레미스 Oracle 테이블을 참조하는 입력 테이블을 정의할 수 있습니다.

  <pre>{
      "name": "TableOracle",
      "properties": {
          "location": {
              "type": "OnPremisesOracleTableLocation",
              "tableName": "LOG",
              "linkedServiceName": "LinkedServiceOracle"
          },
          "availability": {
              "frequency": "Day",
              "interval": "1",
              "waitOnExternal": {}
          },
          "policy": {}
      }
  }

  </pre>

  이제 Oracle 판독기 쿼리에서 매크로를 사용하여 시간 조각에 기반한 레코드를 Azure Blob에 복사하는 복사 작업을 작성하기가 매우 쉽습니다. 동시성 번호를 지정하여 정규화된 복사 작업을 병렬로 실행할 수 있습니다.

  <pre>{
      "name": "PipelineCopyOracleToBlob",
      "properties": {
          "activities": [
              {
                  "name": "CopyActivity",
                  "description": "copy slices of oracle records to azure blob",
                  "type": "CopyActivity",
                  "inputs": [ { "name": "TableOracle" } ],
                  "outputs": [ { "name": "TableAzureBlob" } ],
                  "transformation": {
                      "source": {
                          "type": "OracleSource",
                          "oracleReaderQuery": "$$Text.Format('select * from LOG where \"Timestamp\" &gt;= to_date(\\'{0:yyyy-MM-dd}\\', \\'YYYY-MM-DD\\') AND \"Timestamp\" &lt; to_date(\\'{1:yyyy-MM-dd}\\', \\'YYYY-MM-DD\\')', SliceStart, SliceEnd)"
                      },
                      "sink": {
                          "type": "BlobSink"
                      }
                  },
                  "policy": {
                      "concurrency": 3,
                      "timeout": "00:05:00"
                  }
              }
          ],
          "start": "2015-03-01T00:00:00Z",
          "end": "2015-03-15T00:00:00Z",
          "isPaused": false
      }
  }</pre>

  <h2>텍스트 파일에 대한 인코딩 지정</h2>

  UTF-8 인코딩은 매우 인기가 있지만 Azure Blob의 시간 텍스트 파일은 기록적인 이유로 인해 다른 인코딩을 따르는 경우가 많습니다. 새로 도입된 encodingName을 사용하면 이제 사용자가 TextFormat 유형의 테이블에 대한 코드 페이지 이름으로 인코딩을 지정할 수 있습니다(예: "gb2312", "windows-1255"). 값을 생략하면 BOM이 다른 유니코드 인코딩을 표시하지 않는 한 커넥터는 평소와 같이 UTF-8로 대체됩니다. 지원되는 인코딩 이름은 <a href="https://msdn.microsoft.com/en-us/library/system.text.encoding(v=vs.110).aspx">이 링크를</a> 참조하세요.


  다음은 텍스트 파일의 인코딩을 gb2312로 설정하는 예제입니다.

  <pre>"location": {
      "type": "AzureBlobLocation",
      "folderPath": "encode",
      "format": {
          "type": "TextFormat",
          "columnDelimiter": ",",
          "encodingName": "gb2312"
      },
      "linkedServiceName": "LinkedServiceAzureBlob"
  }

  </pre>

  <h2>SQL 싱크로 복사하기 위한 추가 매개 변수를 사용하여 저장 프로시저 호출</h2>

  데이터를 SQL Server 또는 Azure SQL Database 복사할 때 사용자가 지정한 저장 프로시저를 구성하고 추가 매개 변수를 사용하여 호출할 수 있습니다.


  <strong>예제</strong>


  출력 테이블의 JSON을 다음과 같이 정의합니다(예제로 Azure SQL Database 테이블 사용).

  <pre>{
      "name": "MyAzureSQLTable",
      "properties": {
          "location": {
              "type": "AzureSqlTableLocation",
              "tableName": "Marketing",
              "linkedServiceName": "AzureSqlLinkedService"
          },
          "availability": {
              "frequency": "Hour",
              "interval": 1
          }
      }
  }

  </pre>

  복사 작업 JSON의 SqlSink 섹션을 다음과 같이 정의합니다. 데이터를 삽입하는 동안 저장된 프로시저를 호출하려면  SqlWriterStoredProcedureName 및 SqlWriterTableType 속성이 모두 필요합니다.

  <pre>"sink": {
      "type": "SqlSink",
      "SqlWriterTableType": "MarketingType",
      "SqlWriterStoredProcedureName": "spOverwriteMarketing",
      "storedProcedureParameters": {
          "stringData": {
              "value": "str1"
          }
      }
  }

  </pre>

  데이터베이스에서  SqlWriterStoredProcedureName과 동일한 이름으로 저장 프로시저를 정의합니다. 지정된 원본에서 입력 데이터를 처리하고 출력 테이블로 삽입합니다. 저장 프로시저의 매개 변수 이름은 Table JSON 파일에 정의된 tableName과 동일해야 합니다.

  <pre>CREATE PROCEDURE spOverwriteMarketing @Marketing [dbo].[MarketingType] READONLY, @stringData varchar(256)

  AS

  BEGIN
      DELETE FROM [dbo].[Marketing] where ProfileID = @stringData
      INSERT [dbo].[Marketing](ProfileID, State)
      SELECT * FROM @Marketing
  END

  </pre>

  데이터베이스에서 SqlWriterTableType과 동일한 이름으로 테이블 형식을 정의합니다. 테이블 형식의 스키마가 입력 데이터에서 반환된 스키마와 동일해야 합니다.

  <pre>CREATE TYPE [dbo].[MarketingType] AS TABLE(
      [ProfileID] [varchar](256) NOT NULL,
      [State] [varchar](256) NOT NULL
  )

  </pre>

  &nbsp;

  <h2>요약</h2>

  Azure Data Factory에 대한 데이터 저장소가 점점 더 추가되고 있습니다. 마음에 이름이 있는 경우 <a href="https://feedback.azure.com/forums/270578-azure-data-factory">Azure Data Factory 사용자 음성</a>을 통해 피드백을 보내주세요. 수신 대기 중입니다.-)
