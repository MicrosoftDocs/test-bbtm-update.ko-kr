### YamlMime:Yaml
ms.openlocfilehash: a2389f51d6b9b1ac9cd4989a06e106e610c80884
ms.sourcegitcommit: d03bdc7fe5447adb6530886aab848b75fe8fa8ee
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 03/11/2022
ms.locfileid: "139901658"
Slug: how-is-ai-for-video-different-from-ai-for-images
Title: 비디오용 AI와 이미지의 AI는 어떻게 다른가요?
Summary: 비디오에서 인사이트 추출(AI 기술 사용)은 이미지에 비해 추가적인 과제(및 최적화 기회)를 제공합니다. AI가 비디오에 대한 오해가 있습니다...
Content: >-
  <p>비디오에서 인사이트를 추출하거나 AI 기술을 사용하면 이미지에 비해 최적화를 위한 추가적인 과제와 기회를 제공합니다. 비디오용 AI가 단순히 비디오에서 프레임을 추출하고 각 비디오 프레임에서 컴퓨터 비전 알고리즘을 실행한다는 오해가 있습니다. 당신은 확실히 그렇게 할 수 있지만, 당신이 진정으로 후 인사이트를 얻을 도움이되지 않습니다. 이 블로그 게시물에서는 몇 가지 예제를 사용하여 개별 비디오 프레임을 처리하는 접근 방식의 단점을 설명합니다. 나는 이러한 단점을 극복하는 데 필요한 추가 알고리즘의 세부 사항을 통해 가지 않을 것이다. Video Indexer는 이러한 여러 비디오 관련 알고리즘을 구현합니다.</p>


  <h2>비디오의 사람 현재 상태</h2>


  <p>이 비디오의 처음 25초를 확인합니다.</p>


  <p><iframe align="center" allowfullscreen="" frameborder="no" height="280" name="azuremediaplayer" scrolling="no" src="//aka.ms/ampembed?url=https%3A%2F%2Freferencestream-samplestream.streaming.mediaservices.windows.net%2F7175d3d0-840c-46c7-b612-829f2db86bbc%2FRuler_PM_Emily.ism%2Fmanifest&amp;autoplay=false" width="500"></iframe></p>


  <p>더그는 전체 25 초 동안 존재합니다.</p>


  <p>더그가 비디오에있을 때에 대한 타임 라인을 그릴 경우, 그것은 다음과 같은 것이어야한다.</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/4b2eaeaf-87ab-4ddc-9296-a47e57926e0d.png"><img alt="image" border="0" height="233" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/af8a7441-0f79-49e6-95f0-82b149c40bce.png" style="border: 0px currentColor; border-image: none; padding-top: 0px; padding-right: 0px; padding-left: 0px; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;" title="이미지" width="1200"></a></p>


  <p>&nbsp;</p>


  <p>더그가 항상 카메라를 마주보고 있는 것은 아니라는 사실에 유의하십시오. 비디오에서 7초 동안 그는 에밀리를 바라보고 있습니다. 같은 일이 23 초에서 발생합니다.</p>


  <p>비디오에서 이러한 시간에 얼굴 감지를 실행하면 Dougs&rsquo; 얼굴이 검색되지 않습니다(아래 스크린샷 참조).</p>


  <p>&nbsp;</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/f2d791ff-acf0-443b-9d8c-ddf382e99ea3.png"><img alt="image" border="0" height="437" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/26c5916c-705f-422f-b535-d0116eb7db3b.png" style="border: 0px currentColor; border-image: none; padding-top: 0px; padding-right: 0px; padding-left: 0px; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;" title="이미지" width="1193"></a></p>


  <p>&nbsp;</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/4e7a8216-dc2d-4897-bd06-f6f11e25db2b.png"><img alt="image" border="0" height="443" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/a76a9659-b2bc-4ab9-b99e-44204382281c.png" style="border: 0px currentColor; border-image: none; padding-top: 0px; padding-right: 0px; padding-left: 0px; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;" title="이미지" width="1203"></a></p>


  <p>&nbsp;</p>


  <p>즉, 각 비디오 프레임에서 얼굴 감지만 수행하면 위와 같이 타임라인을 그릴 수 없습니다. 타임라인에 액세스하려면 비디오 프레임에서 얼굴을 추적하고 그 사이에 있는 얼굴의 측면 보기를 설명할 수 있어야 합니다. Video Indexer는 얼굴 추적을 수행하며, 그 결과 이전에 소개된 전체 타임라인이 표시됩니다.</p>


  <h2>광학 문자 인식을 사용하여 토픽/키워드 추출</h2>


  <p>다음 두 프레임을 살펴봅니다.</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/71f319b5-eac9-4239-8a28-d8b1bd2a56c4.png"><img alt="image" border="0" height="720" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/ea4fe55f-e073-4d08-ac7b-567d68e546d5.png" style="border: 0px currentColor; border-image: none; padding-top: 0px; padding-right: 0px; padding-left: 0px; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;" title="이미지" width="886"></a></p>


  <p>이 두 프레임은 발표자가 무대에 서서 뒷벽에 각인된 Microsoft&rdquo;라는 단어를 &ldquo;가리는 비디오에서 가져옵니다. 인간으로서 여러분은 Microsoft&rdquo;라는 단어가 무엇인지 알고 있습니다&ldquo;. 이 두 이미지 &ldquo;에 대해 OCR을 실행하면 Microsc&rdquo; 및 &ldquo;crosoft&rdquo; 가 출력으로 표시됩니다. 비디오 클립에서 전체 프레임 시퀀스를 처리하는 경우 다음과 같은 부분 단어를 많이 얻게 됩니다. 노이즈를 줄이고 샷의 프레임 시퀀스에 대해 올바른 단어를 추출하려면 부분 단어에 알고리즘을 적용해야 합니다. Video Indexer를 사용하면 비디오에서 더 나은 인사이트를 얻을 수 있습니다.</p>


  <h2>얼굴 인식</h2>


  <p>얼굴 인식 시스템은 1인당 학습 이미지 집합을 사용하여 빌드된 얼굴 데이터베이스로 구성됩니다. 또한 쿼리 이미지에서 얼굴 기능을 추출하고 얼굴 데이터베이스와 일치시키는 작업을 수행하는 쿼리 함수를 제공합니다. 쿼리 함수의 출력은 신뢰도 값과 함께 가능한 일치 목록으로 구성됩니다. 쿼리 함수의 출력 품질은 얼굴 데이터베이스 및 쿼리 이미지의 품질에 따라 달라집니다.</p>


  <p>비디오의 경우, 사람이 다른 머리 포즈와 조명 조건에 존재하는 비디오의 여러 프레임이있을 것입니다. 사람이 있는 각 프레임을 가져와 얼굴 인식 시스템을 쿼리하는 방법을 사용할 수 있습니다. 이렇게 하면 얼굴 데이터베이스의 가능한 일치 항목 목록이 서로 다른 신뢰도 값으로 표시됩니다. 또한 잠재적 일치가 프레임 시퀀스에서 동일할 것이라는 보장은 없습니다. 즉, 일치하는 얼굴을 확인하기 위해 추가 논리 계층이 필요합니다. 얼굴 인식 시스템에 대해 쿼리할 적절한 프레임 하위 집합을 선택하여 얼굴 인식 시스템에 대한 쿼리 수를 줄일 수 있는 최적화 기회도 있습니다.</p>


  <p>또한 비디오는 여러 비디오 프레임의 사용자에 대해 올바른 학습 이미지 변형을 사용하여 얼굴 데이터베이스를 빌드하고 보강할 수 있는 기회를 제공합니다. 프레임 간에 사람을 추적하는 논리와 변형을 평가하는 추론 알고리즘이 있는 경우 가능합니다. Video Indexer는 이를 수행하므로 제공된 비디오에서 더 높은 품질의 얼굴 데이터베이스를 빌드할 수 있습니다.</p>
