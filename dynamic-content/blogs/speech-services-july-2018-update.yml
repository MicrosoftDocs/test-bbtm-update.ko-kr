### YamlMime:Yaml
ms.openlocfilehash: 533e8bc53644d2ce380321b9a7383204e06e35f1
ms.sourcegitcommit: d03bdc7fe5447adb6530886aab848b75fe8fa8ee
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 03/11/2022
ms.locfileid: "139900533"
Slug: speech-services-july-2018-update
Title: Speech Services 2018년 7월 업데이트
Summary: Speech Services가 현재 미리 보기 상태라고 발표한 이후 많은 일이 일어났으며 Cognitive Services Speech SDK 2018년 6월 업데이트를 릴리스했습니다. 오늘, 우리는 우리가 방금 가지고 있음을 발표하게되어 기쁩니다 ...
Content: >-
  <p><a href="https://azure.microsoft.com/en-us/blog/speech-services-now-in-preview/">Speech Services가 현재 미리 보기 상태</a>라고 발표한 이후 많은 일이 일어났으며 Cognitive <a href="https://azure.microsoft.com/en-us/updates/speechsdkupdatejune2018/">Services Speech SDK 2018년 6월 업데이트를</a> 릴리스했습니다.</p>


  <p>오늘 0.5.0 버전의 <a href="https://docs.microsoft.com/azure/cognitive-services/speech-service/">Speech SDK</a>를 방금 출시했다는 사실을 발표하게 되어 기쁩니다. 이 업데이트를 통해 <a href="https://docs.microsoft.com/azure/cognitive-services/speech-service/quickstart-csharp-uwp">UWP</a>(Windows 버전 1709), <a href="https://docs.microsoft.com/azure/cognitive-services/speech-service/quickstart-csharp-netcore-windows">.NET Standard 2.0</a>(Windows) 및 Android 6.0(Marshmallow, API 수준 23) 이상의 <a href="https://docs.microsoft.com/azure/cognitive-services/speech-service/quickstart-java-android">Java</a>에 대한 지원이 추가되었습니다. 몇 가지 기능을 변경하고 몇 가지 버그 수정을 수행했습니다. 특히, 이제 <strong>장기 실행 오디오</strong> 및 자동 다시 연결을 지원합니다. 이렇게 하면 시간 제한, 네트워크 오류 또는 서비스 오류가 발생할 경우 Speech Service의 전반적인 복원력이 향상됩니다. 또한 Weve&rsquo;는 오류를 보다 쉽게 처리할 수 있도록 오류 메시지를 개선했습니다. 자세한 내용은 <a href="https://docs.microsoft.com/azure/cognitive-services/speech-service/releasenotes">릴리스 정보</a> 페이지를 참조하세요. 올 가을 <a href="https://docs.microsoft.com/azure/cognitive-services/speech-service/">Speech SDK</a> 를 일반 공급하기 위해 노력하면서 더 많은 플랫폼 및 프로그래밍 언어에 대한 지원을 계속 추가할 예정입니다.</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/5dde03c1-de7e-47ea-8675-38131ae9d631.png"><img alt="image" border="0" height="252" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/cda0d013-5933-4c5e-809b-05c2cad543fe.png" style="margin: 0px auto; border: 0px currentcolor; border-image: none; float: none; display: block; background-image: none;" title="이미지" width="466"></a></p>


  <p>Speech SDK 외에도 <a href="https://customvoice.ai/">Custom Voice</a> 는 더 많은 학습 데이터 형식을 지원하는 새로운 기능을 출시했습니다. 이제 샘플링 속도가 16khz 이상인 모든 &lsquo;.wav&rsquo; 파일(RIFF)이 허용됩니다. 또한 더 많은 일반 텍스트 인코딩 형식(ANSI/UTF-8/UTF-8-BOM/UTF-16-LE/UTF-16-BE)에 대한 지원이 확장되었습니다. 자세한 내용은 <a href="https://docs.microsoft.com/en-us/azure/cognitive-services/speech-service/how-to-customize-voice-font#prepare-recordings-and-transcripts">데이터를 준비하고 음성 글꼴을 사용자 지정하는 방법에</a> 대한 문서를 참조하세요. 음성 학습 데이터 준비 중에 발생할 수 있는 문제에 중점을 두고 인간 음성의 고품질 오디오 샘플을 만드는 데 도움이 되는 새 문서가 릴리스되었습니다. 자세한 내용은 <a href="https://docs.microsoft.com/en-us/azure/cognitive-services/speech-service/record-custom-voice-samples">사용자 지정 음성에 대한 음성 샘플을 녹음하는 방법을</a> 참조하세요.</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/fc575b5c-2ffd-4be2-8a2e-8f0814b39936.png"><img alt="CustomVoice" border="0" height="726" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/501c6d5d-2e08-4df5-a547-b9f443eebc49.png" style="margin: 0px auto; border: 0px currentcolor; border-image: none; float: none; display: block; background-image: none;" title="CustomVoice" width="1105"></a></p>


  <p>또한 Speech(미리 보기) <a href="https://docs.microsoft.com/en-us/azure/cognitive-services/Speech-service/how-to-customize-pronunciation">설명서</a>의 새 콘텐츠를 발표하게 되어 매우 기쁩니다.</p>


  <p>콘텐츠 업데이트는 개발자가 개발 중인 애플리케이션 유형에 따라 올바른 콘텐츠로 빠르게 이동할 수 있도록 돕는 것을 목표로 합니다.</p>


  <p>음향 적응, 언어 적응, 발음 및 음성 글꼴을 포함하여 엔드투엔드 사용자 지정 프로세스에 대한 새로운 별도의 섹션이 있습니다. Weve&rsquo;는 스토리지에 대량의 오디오 파일이 있는 고객에게 적합한 Batch Transcription API에 대한 설명서를 추가했습니다.</p>


  <p>또한 설명서는 다음 섹션을 사용하여 이 SDK 업데이트를 보완합니다.</p>


  <ul>
   <li>애플리케이션 요구 사항에 따라 설명서를 탐색하는 데 도움이 되는 새로운 <a href="https://docs.microsoft.com/en-us/azure/cognitive-services/speech-service/speech-scenarios">시나리오</a> 섹션입니다.</li>
   <li>통합 e2e <a href="https://docs.microsoft.com/en-us/azure/cognitive-services/speech-service/how-to-customize-acoustic-models">사용자 지정</a> 섹션(GitHub <a href="https://github.com/Microsoft/Cognitive-Custom-Speech-Service">대한 데이터</a> 및 <a href="https://github.com/Microsoft/Cognitive-Custom-Speech-Service/blob/master/tutorials.md">자습서</a> 포함)</li>
   <li>GitHub <a href="https://github.com/PanosPeriorellis/Speech_Service-BatchTranscriptionAPI">샘플을</a> 포함한 새로운 <a href="https://docs.microsoft.com/en-us/azure/cognitive-services/speech-service/batch-transcription">Batch Transcription API</a></li>
   <li>리소스 아래의 각 하위 서비스에 대한 자세한 내용과 자세한 <strong>FAQ</strong> 섹션 <strong>입니다</strong>.</li>
  </ul>


  <p><a href="https://docs.microsoft.com/en-us/azure/cognitive-services/Speech-service/how-to-customize-pronunciation">설명서는</a> 현재 라이브로 제공됩니다. 설명서 페이지의 맨 아래에 있는 피드백 섹션을 사용하여 의견을 알려주세요.&rdquo;</p>


  <p>Microsoft Speech Services에 관심이 있으세요? <a href="https://docs.microsoft.com/azure/cognitive-services/speech-service/get-started">무료로 사용해 볼</a> 수 있습니다. 샘플 코드를 자세히 알아보고 검토하려면 <a href="https://aka.ms/csspeech">설명서 페이지를</a> 참조하세요. Twitter에 @msspeech3 따라 향후 업데이트에 대한 알림을 받으세요.</p>
