### YamlMime:Yaml
ms.openlocfilehash: 5fb412d376b94799ba067b9ebcbfe669d6b6c71b
ms.sourcegitcommit: d03bdc7fe5447adb6530886aab848b75fe8fa8ee
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 03/11/2022
ms.locfileid: "139906045"
Slug: cloudera-adls
Title: Cloudera는 이제 Azure Data Lake Store를 지원합니다.
Summary: Cloudera Enterprise Data Hub 5.12 릴리스를 사용하면 이제 ADLS(Azure Data Lake Store)의 Cloudera 클러스터에서 Spark, Hive, HBase, Impala 및 MapReduce 워크로드를 실행할 수 있습니다.
Content: "<p><a href=\"https://www.cloudera.com/documentation/enterprise/release-notes/topics/cdh_rn_new_in_cdh_512.html#cdh_rn_new_in_cdh_512\" target=\"_blank\">Cloudera Enterprise Data Hub 5.12</a> 릴리스를 사용하면 이제 ADLS(Azure Data Lake Store)의 Cloudera 클러스터에서 Spark, Hive, HBase, Impala 및 MapReduce 워크로드를 실행할 수 있습니다. ADLS에서 실행하면 다음과 같은 이점이 있습니다.</p>\n\n<ul>\n <li>데이터 크기에 관계없이 클러스터를 늘리거나 축소합니다.</li>\n <li>클러스터를 스핀업하거나 분해할 때 데이터는 독립적으로 유지됩니다. Azure Data Lake Analytics 또는 Azure SQL Data Warehouse와 같은 다른 클러스터 및 컴퓨팅 엔진은 동일한 데이터에서 워크로드를 실행할 수 있습니다.</li>\n <li>Azure Active Directory 통합된 역할 기반 액세스 제어를 사용하도록 설정하고 세분화된 POSIX 기반 ACL을 사용하여 사용자 및 그룹에 권한을 부여합니다.</li>\n <li>분석 워크로드에 최적화된 성능이 있는 클라우드 HDFS는 수백 테라바이트 단위의 데이터를 동시에 읽고 쓸 수 있습니다.</li>\n <li>계정 크기 또는 개별 파일 크기에 제한이 없습니다.</li>\n <li>데이터는 기본적으로 Azure Key Vault에서 서비스 관리 또는 고객 관리형 키를 사용하여 미사용 시 암호화되며 전송 중에 SSL로 암호화됩니다.</li>\n <li>데이터 복제는 HDFS 및 클라우드 스토리지 인프라 수준에서 데이터를 복제하지 않고도 Data Lake Store에서 관리되고 HDFS 호환 인터페이스에서 노출되므로 저렴한 비용으로 높은 데이터 내구성을 제공합니다.</li>\n</ul>\n\n<p>시작하려면 <a href=\"https://azuremarketplace.microsoft.com/en-us/marketplace/apps/cloudera.clouderaedh\" target=\"_blank\">Cloudera Enterprise Data Hub 템플릿</a> 또는 Azure Marketplace의 <a href=\"https://azuremarketplace.microsoft.com/en-us/marketplace/apps/cloudera.director-on-azure\" target=\"_blank\">Cloudera Director 템플릿</a>을 사용하여 Cloudera 클러스터를 만들 수 있습니다. 클러스터가 설정되면 다음 방법 중 하나 또는 둘 다를 사용하여 ADLS를 사용하도록 설정합니다.</p>\n\n<h3>클러스터 전체 액세스를 위한 Data Lake Store 추가</h3>\n\n<p><strong>1단계</strong>: ADLS는 ID 관리 및 인증에 Azure Active Directory 사용합니다. Cloudera 클러스터에서 ADLS에 액세스하려면 먼저 <a href=\"https://docs.microsoft.com/en-us/azure/azure-resource-manager/resource-group-create-service-principal-portal\" target=\"_blank\">Azure AD에서 서비스 주체를 만듭니</a>다. 서비스 주체의 <em>애플리케이션 ID</em>, <em>인증 키</em> 및 <em>테넌트 ID</em> 가 필요합니다.</p>\n\n<p><strong>2단계</strong>: ADLS에 액세스하려면 이전 단계에서 만든 서비스 주체에 대한 권한을 할당합니다. 이렇게 하려면 Azure Portal로 이동하여 Data Lake Store로 이동한 다음, 데이터 탐색기를 선택합니다. 그런 다음 대상 경로로 이동하여 Access를 선택하고 적절한 액세스 권한이 있는 서비스 주체를 추가합니다. ADLS의 액세스 제어에 대한 자세한 내용은 <a href=\"https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-access-control\" target=\"_blank\">이 문서를</a> 참조하세요.</p>\n\n<p><a href=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/cff17378-2988-4540-ac41-f71c58cfddd0.png\"><img alt=\"adls2_acl\" border=\"0\" height=\"357\" src=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/5ce750a1-4741-480c-9388-ef8ea49eb51b.png\" style=\"border-width: 0px; padding-top: 0px; padding-right: 0px; padding-left: 0px; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;\" title=\"adls2_acl\" width=\"858\"></a></p>\n\n<p><strong>3단계:</strong> Cloudera Manager -&gt; HDFS -&gt; 구성으로 이동합니다. core-site.xml 다음 구성을 추가합니다.</p>\n\n<p><a href=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/0c71da7d-e625-42e7-a4bc-d5b901a4cb2d.png\"><img alt=\"adls1_hdfscfg\" border=\"0\" height=\"413\" src=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/0dda749c-1f25-44d1-918e-8f4f3cc8f5b5.png\" style=\"border-width: 0px; padding-top: 0px; padding-right: 0px; padding-left: 0px; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;\" title=\"adls1_hdfscfg\" width=\"851\"></a></p>\n\n<p><strong>1단계</strong>에서 얻은 서비스 주체 속성 값을 사용하여 다음 매개 변수를 설정합니다.</p>\n\n<pre class=\"prettyprint\">\n&lt;property&gt;\n    &lt;name&gt;dfs.adls.oauth2.client.id&lt;/name&gt;\n    &lt;value&gt;<em>Application ID</em>&lt;/value&gt;\n&lt;/property&gt;\n&lt;property&gt;\n    &lt;name&gt;dfs.adls.oauth2.credential&lt;/name&gt;\n    &lt;value&gt;<em>Authentication Key</em>&lt;/value&gt;\n&lt;/property&gt;\n&lt;property&gt;\n    &lt;name&gt;dfs.adls.oauth2.refresh.url&lt;/name&gt;\n    &lt;value&gt;https://login.microsoftonline.com/&lt;<em>Tenant ID</em>&gt;/oauth2/token&lt;/value&gt;\n&lt;/property&gt; \n&lt;property&gt;\n    &lt;name&gt;dfs.adls.oauth2.access.token.provider.type&lt;/name&gt;\n    &lt;value&gt;ClientCredential&lt;/value&gt;\n&lt;/property&gt;\n</pre>\n\n<p><strong>4단계: </strong> 예를 들어 Hadoop 명령을 실행하여 ADLS에 액세스할 수 있는지 확인합니다.</p>\n\n<pre class=\"prettyprint\">\nhdfs dfs -ls adl://&lt;your adls account&gt;.azuredatalakestore.net/&lt;path to file&gt;/</pre>\n\n<h3>Hadoop 명령줄에서 Data Lake Store 지정</h3>\n\n<p>클러스터 전체 액세스를 위해 Data Lake Store를 구성하는 대신 MapReduce 또는 Spark 작업의 명령줄에서 ADLS 액세스 정보를 제공할 수도 있습니다. 이 메서드를 사용하면 서비스 주체 대신 Azure AD 새로 고침 토큰을 사용하고 자격 증명을 암호화합니다. 사용자&rsquo; 홈 디렉터리 아래의 JCEKS 파일은 다음과 같은 이점을 얻을 수 있습니다.</p>\n\n<ul>\n <li>각 사용자는 클러스터 전체 자격 증명이 있는 대신 자체 자격 증명을 사용할 수 있습니다.</li>\n <li>에서 암호화되므로&rsquo; 다른 사용자&rsquo; 자격 증명을 볼 수 없습니다. 사용자&rsquo; 홈 디렉터리의 JCEKS</li>\n <li>구성 파일에 자격 증명을 명확한 텍스트로 저장할 필요가 없습니다.</li>\n <li>Azure AD에서 서비스 주체를 만들 수 있는 권한이 있는 사용자를 기다릴 필요가 없습니다.</li>\n</ul>\n\n<p>다음 단계에서는 Azure 플랫폼 간 클라이언트 도구에 로그인하여 얻은 새로 고침 토큰을 사용하여 이를 설정하는 방법의 예를 보여 줍니다.</p>\n\n<p><strong>1단계</strong>: Azure 로그인&rdquo; 명령을 &ldquo;실행하여 Azure cli에 로그인한 다음, 사용자&rsquo; 홈 디렉터리 아래의 .azure/accessTokens.json에서 <em>refreshToken</em> 및 <em>_clientId</em> 가져옵니다.</p>\n\n<p><strong>2단계</strong>: 다음 명령을 실행하여 ADLS에 액세스하는 자격 증명을 설정합니다.</p>\n\n<pre class=\"prettyprint\">\nexport HADOOP_CREDSTORE_PASSWORD=&lt;your encryption password&gt; \nhadoop credential create dfs.adls.oauth2.client.id -value &lt;_clientId from Step 1&gt; -provider jceks://hdfs/user/&lt;username&gt;/cred.jceks \nhadoop credential create dfs.adls.oauth2.refresh.token -value &lsquo;&lt;refreshToken from Step 1&gt;&rsquo; -provider jceks://hdfs/user/&lt;username&gt;/cred.jceks </pre>\n\n<p><strong>3단계</strong>: 예를 들어 Hadoop 명령을 실행하여 ADLS에 액세스할 수 있는지 확인합니다.</p>\n\n<pre class=\"prettyprint\">\nhdfs dfs -Ddfs.adls.oauth2.access.token.provider.type=RefreshToken -Dhadoop.security.credential.provider.path=jceks://hdfs/user/&lt;username&gt;/cred.jceks -ls adl://&lt;your adls account&gt;.azuredatalakestore.net/&lt;path to file&gt;\nhadoop jar /opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/hadoop-examples.jar teragen -Dmapred.child.env=&quot;HADOOP_CREDSTORE_PASSWORD=$HADOOP_CREDSTORE_PASSWORD&quot; -Dyarn.app.mapreduce.am.env=&quot;HADOOP_CREDSTORE_PASSWORD=$HADOOP_CREDSTORE_PASSWORD&quot; -Ddfs.adls.oauth2.access.token.provider.type=RefreshToken -Dhadoop.security.credential.provider.path=jceks://hdfs/user/&lt;username&gt;/cred.jceks 1000 adl://&lt;your adls account&gt;.azuredatalakestore.net/&lt;path to file&gt;\n</pre>\n\n<h3>EDH 5.12의 ADLS 지원 제한 사항</h3>\n\n<ul>\n <li>ADLS는 보조 스토리지로 지원됩니다. ADLS에 액세스하려면 파일에&gt; 대한 adl:// your adls account.azuredatalakestore.net/&lt;&lt;&gt; path 형식의 정규화된 URL을 사용합니다.</li>\n</ul>\n\n<h3>추가 리소스</h3>\n\n<ul>\n <li><a href=\"https://www.cloudera.com/documentation/enterprise/latest/topics/admin_adls_config.html\" target=\"_blank\">ADLS 지원에 대한 Cloudera 설명서</a></li>\n</ul>"
