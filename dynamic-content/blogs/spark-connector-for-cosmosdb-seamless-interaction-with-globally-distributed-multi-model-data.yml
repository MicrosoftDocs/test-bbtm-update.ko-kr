### YamlMime:Yaml
ms.openlocfilehash: bc1a7da28d1bf4fb074b1754fdae6283ccc9eaa1
ms.sourcegitcommit: d03bdc7fe5447adb6530886aab848b75fe8fa8ee
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 03/11/2022
ms.locfileid: "139900544"
Slug: spark-connector-for-cosmosdb-seamless-interaction-with-globally-distributed-multi-model-data
Title: '#CosmosDB Spark 커넥터 - 전역적으로 분산된 다중 모델 데이터와의 원활한 상호 작용'
Summary: '오늘 Azure Cosmos DB용 Spark 커넥터가 이제 진정한 다중 모델임을 발표하게 되어 기쁩니다! 최근 발표된 Azure Cosmos DB: 업계 최초의 글로벌 분산 다중 모델 데이터베이스 서비스인 Microsoft의 목표는 이미 익숙한 도구와 API를 사용하여 전역적으로 분산된 앱을 보다 쉽게 작성할 수 있도록 돕는 것입니다.'
Content: "<p><a href=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/dca42937-94b4-4152-9b82-54b590901fe5.png\"><img alt=\"image\" border=\"0\" height=\"288\" src=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/dd8fa093-06c9-4ba5-9cb6-29725da4c678.png\" style=\"border-width: 0px; padding-top: 0px; padding-right: 0px; padding-left: 0px; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;\" title=\"이미지\" width=\"920\"></a></p>\n\n<p>오늘 Azure&rsquo; Cosmos DB용 Spark 커넥터가 이제 진정한 다중 모델임을 발표하게 되어 매우 기쁩니다! 최근 발표된 <a href=\"https://azure.microsoft.com/blog/azure-cosmos-db-microsofts-globally-distributed-multi-model-database-service/\">Azure Cosmos DB: 업계&rsquo; 최초로 전 세계에 분산된 다중 모델 데이터베이스 서비스</a>인 Microsoft의 목표는 이미 익숙한 도구와 API를 사용하여 전역적으로 분산된 앱을 보다 쉽게 작성할 수 있도록 돕는 것입니다. Azure Cosmos DB&rsquo; 데이터베이스 엔진은 기본적으로 <a href=\"https://docs.microsoft.com/en-us/azure/cosmos-db/documentdb-introduction\">SQL(DocumentDB) API</a>, <a href=\"https://docs.microsoft.com/en-us/azure/cosmos-db/mongodb-introduction\">MongoDB API</a>, <a href=\"https://docs.microsoft.com/en-us/azure/cosmos-db/graph-introduction\">Gremlin(그래프) API</a> 및 <a href=\"https://docs.microsoft.com/en-us/azure/cosmos-db/table-introduction\">Azure Table Storage API</a>를 지원합니다. Azure Cosmos DB용 업데이트된 Spark 커넥터를 사용하여 Apache Spark는 이제 모든 Azure Cosmos DB 데이터 모델인 문서, 테이블 및 그래프와 상호 작용할 수 있습니다.</p>\n\n<h2>Azure Cosmos DB란?</h2>\n\n<p>Azure Cosmos DB는 중요 업무용 애플리케이션을 위한 Microsoft&#39;<a href=\"https://aka.ms/acdbglobaldist\">전역적으로 분산된</a> 다중 모델 데이터베이스 서비스입니다. Azure Cosmos DB는 <a href=\"https://docs.microsoft.com/azure/cosmos-db/tutorial-global-distribution-documentdb\">턴키 글로벌 배포</a>, 전 세계 <a href=\"https://docs.microsoft.com/azure/cosmos-db/partition-data\">처리량 및 스토리지의 탄력적 확장</a>, 99번째 백분위수의 한 자리 밀리초 대기 시간, <a href=\"https://docs.microsoft.com/azure/cosmos-db/consistency-levels\">5개의 잘 정의된 일관성 수준</a> 및 보장된 고가용성을 제공하며, 모두 <a href=\"https://azure.microsoft.com/support/legal/sla/cosmos-db/\">업계 최고의 포괄적인 SLA</a>를 통해 지원됩니다. Azure Cosmos DB는 스키마 및 인덱스 관리를 처리할 필요 없이 <a href=\"https://www.vldb.org/pvldb/vol8/p1668-shukla.pdf\">모든 데이터를 자동으로</a> 인덱싱합니다. 또한 다중 모델 방식이며, 문서, 키-값, 그래프 및 열 형식 데이터 모델을 지원합니다. 클라우드 서비스인 Azure Cosmos DB는 다중 테넌트 및 전역 배포를 사용하여 처음부터 세심하게 설계되었습니다.</p>\n\n<h2>Apache Spark 및 Azure Cosmos DB를 사용하여 Globally-Distributed 데이터에서 실시간 Machine Learning 수행</h2>\n\n<p>Azure Cosmos DB용 Spark 커넥터를 사용하면 Azure Cosmos DB에서 전역적으로 분산된 데이터에 대한 실시간 데이터 과학, 기계 학습, 고급 분석 및 탐색이 가능합니다. Apache Spark를 Azure Cosmos DB에 연결하면 빠르게 움직이는 데이터 과학 문제를 해결하는 고객의&rsquo; 기능이 가속화되며, Azure Cosmos DB를 사용하여 데이터를 빠르게 지속하고 쿼리할 수 있습니다. 네이티브 Azure Cosmos DB 관리형 인덱스를 효율적으로 활용하고 분석을 수행할 때 업데이트 가능한 열을 사용하도록 설정합니다.&nbsp; 또한 다양한 <a href=\"https://github.com/Azure/azure-cosmosdb-spark/wiki\">IoT, 데이터 과학 및 분석 시나리오</a> 집합을 해결하는 빠르게 변화하는 글로벌 분산 데이터에 대한 푸시다운 조건자 필터링을 활용합니다.</p>\n\n<p>Azure Cosmos DB + Spark의 다른 사용 사례는 다음과 같습니다.</p>\n\n<ul>\n <li>스트리밍 추출, 변환 및 데이터 로드(ETL)</li>\n <li>데이터 보강</li>\n <li>트리거 이벤트 검색</li>\n <li>복잡한 세션 분석 및 개인 설정</li>\n <li>시각적 데이터 탐색 및 대화형 분석</li>\n <li>데이터 탐색, 정보 공유 및 공동 작업을 위한 Notebook 환경</li>\n</ul>\n\n<p>Azure Cosmos DB용 Spark 커넥터는 <a href=\"https://github.com/Azure/azure-documentdb-java\">Azure DocumentDB Java SDK</a>를 사용합니다. 오늘 <a href=\"https://aka.ms/spark-documentdb\">시작해</a> <a href=\"https://github.com/Azure/azure-cosmosdb-spark\">GitHub</a> Spark 커넥터를 다운로드할 수 있습니다.</p>\n\n<h2>Azure Cosmos DB 테이블 작업</h2>\n\n<p>Azure Cosmos DB는 예측 가능한 성능 및 글로벌 배포를 통해 유연한 스키마가 있는 키-값 저장소가 필요한 애플리케이션을 위한 <a href=\"https://docs.microsoft.com/azure/cosmos-db/table-introduction\">Table API</a>를 제공합니다. <a href=\"https://docs.microsoft.com/azure/storage/storage-introduction\">Azure Table Storage</a> SDK 및 REST API를 사용하여 Azure Cosmos DB와 작업할 수 있습니다. Azure Cosmos DB는 현재 공개 미리 보기로 처리량 최적화 테이블(비공식적으로 프리미엄 테이블&quot;이라고 함&quot;)을 지원합니다.</p>\n\n<p><a href=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/a6a0e709-d9aa-4ae0-9aca-d86d1f691299.png\"><img alt=\"image\" border=\"0\" height=\"314\" src=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/01802a5a-3937-44cb-b21f-171c7a4e22d0.png\" style=\"border-width: 0px; padding-top: 0px; padding-right: 0px; padding-left: 0px; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;\" title=\"이미지\" width=\"920\"></a></p>\n\n<p>Apache Spark를 Azure Cosmos DB Table API에 연결하려면 다음과 같이 Azure Cosmos DB용 Spark 커넥터를 사용할 수 있습니다.</p>\n\n<pre class=\"prettyprint\">\n// Initialization\nimport com.microsoft.azure.cosmosdb.spark.schema._\nimport com.microsoft.azure.cosmosdb.spark._\nimport com.microsoft.azure.cosmosdb.spark.config.Config\n\nval readConfig = Config(Map(&quot;Endpoint&quot; -&gt; &quot;https://$tableContainer$.documents.azure.com:443/&quot;,\n&quot;Masterkey&quot; -&gt; &quot;$masterkey$&quot;,\n&quot;Database&quot; -&gt; &quot;$tableDatabase$&quot;,\n&quot;Collection&quot; -&gt; &quot;$tableCollection$&quot;,\n&quot;SamplingRatio&quot; -&gt; &quot;1.0&quot;))\n\n \n// Create collection connection \nval tblCntr = spark.sqlContext.read.cosmosDB(readConfig)\ntblCntr.createOrReplaceTempView(&quot;tableContainer&quot;)</pre>\n\n<p>테이블에 연결한 후에는 Spark DataFrame을 만들 수 있습니다(이전 예제에서는 tblCntr).</p>\n\n<pre class=\"prettyprint\">\n// Print tblCntr DataFrame Schema\nscala&gt; tblCntr.printSchema()\nroot\n |-- _etag: string (nullable = true)\n |-- $id: string (nullable = true)\n |-- _rid: string (nullable = true)\n |-- _attachments: string (nullable = true)\n |-- City: struct (nullable = true)\n |    |-- $t: integer (nullable = true)\n |    |-- $v: string (nullable = true)\n |-- State: struct (nullable = true)\n |    |-- $t: integer (nullable = true)\n |    |-- $v: string (nullable = true)\n |-- $pk: string (nullable = true)\n |-- id: string (nullable = true)\n |-- _self: string (nullable = true)\n |-- _ts: integer (nullable = true)\n\n\n\n// Run Spark SQL query against your Azure Cosmos DB table\nscala &gt; spark.sql(&quot;select `$id`, `$pk`, City.`$v` as City, State.`$v` as State from tableContainer where City.`$v` = &#39;Seattle&#39;&quot;).show()\n+----+-----+-------+-----+\n| $id|  $pk|   City|State|\n+----+-----+-------+-----+\n|John|Smith|Seattle|   WA|\n+----+-----+-------+-----+\n</pre>\n\n<p>스키마와 빠르고 쉽게 상호 작용하고 기본 Azure Cosmos DB 테이블에 대해 Spark SQL 쿼리를 실행할 수 있습니다.</p>\n\n<h2>Azure Cosmos DB 그래프 작업</h2>\n\n<p>Azure Cosmos DB는 턴키 글로벌 배포, 탄력적 확장 확장 스토리지&nbsp; 및 처리량, 99번째 백분위수에서 10ms 읽기 대기 시간 및 15ms, &lt;자동 인덱싱 및 &lt;쿼리, 조정 가능한 일관성 수준 및 99.99%의 가용성을 포함한 포괄적인 SLA와 함께 <a href=\"https://docs.microsoft.com/azure/cosmos-db/graph-introduction\">그래프 모델링 및 순회</a> API를 제공합니다. Azure Cosmos DB<a href=\"https://tinkerpop.apache.org/\">는 Apache TinkerPop&#39;</a> 그래프 순회 언어인 <a href=\"https://tinkerpop.apache.org/docs/current/reference/#graph-traversal-steps\">Gremlin</a>을 사용하여 쿼리할 수 있으며 <a href=\"https://docs.microsoft.com/en-us/azure/cosmos-db/spark-connector-graph\">Apache Spark GraphX</a>와 같은 다른 TinkerPop 호환 그래프 시스템과 원활하게 통합됩니다.</p>\n\n<p><a href=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/dd59c5ac-aff0-4bfb-b9cf-4970ca3b3908.png\"><img alt=\"image\" border=\"0\" height=\"197\" src=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/3af75d53-9ca6-4efa-8ca3-e80081a5117d.png\" style=\"border-image: none; padding-top: 0px; padding-right: 0px; padding-left: 0px; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;\" title=\"이미지\" width=\"640\"></a></p>\n\n<p class=\"prettyprint\">Apache Spark를 Azure Cosmos DB Graph 연결하려면 다음과 같이 Azure Cosmos DB용 Spark 커넥터를 사용합니다.</p>\n\n<pre class=\"prettyprint\">\n// Initialization\nimport com.microsoft.azure.cosmosdb.spark.schema._\nimport com.microsoft.azure.cosmosdb.spark._\nimport com.microsoft.azure.cosmosdb.spark.config.Config\n\n\n// Maps\nval baseConfigMap = Map(\n&quot;Endpoint&quot; -&gt; &quot;https://$graphContainer$.documents.azure.com:443/&quot;,\n&quot;Masterkey&quot; -&gt; &quot;$masterKey$&quot;\n&quot;Database&quot; -&gt; &quot;$database$&quot;,\n&quot;Collection&quot; -&gt; &quot;$collection$&quot;, \n&quot;SamplingRatio&quot; -&gt; &quot;1.0&quot;,\n&quot;schema_samplesize&quot; -&gt; &quot;1000&quot;\n)\n\nval airportConfigMap = baseConfigMap ++ Map(&quot;query_custom&quot; -&gt; &quot;select * from c where c.label=&#39;airport&#39;&quot;) \nval delayConfigMap = baseConfigMap ++ Map(&quot;query_custom&quot; -&gt; &quot;select * from c where c.label=&#39;flight&#39;&quot;) \n\n\n// Configs\n// get airport data (vertices)\nval airportConfig = Config(airportConfigMap)\nval airportColl = spark.sqlContext.read.cosmosDB(airportConfig)\nairportColl.createOrReplaceTempView(&quot;airportColl&quot;) \n\n// get flight delay data (edges)\nval delayConfig = Config(delayConfigMap)\nval delayColl = spark.sqlContext.read.cosmosDB(delayConfig)\ndelayColl.createOrReplaceTempView(&quot;delayColl&quot;) </pre>\n\n<p>여기서는 공항 데이터(꼭짓점)와 비행 지연 데이터(에지)에 대한 Spark DataFrames &ndash; 를 만들었습니다. Azure Cosmos DB에 저장한 그래프는 아래 그림과 같이 시각적으로 표시될 수 있습니다. 여기서 꼭짓점은 공항을 나타내는 파란색 원이고 가장자리는 해당 도시 간 항공편을 나타내는 검은색 선입니다.&nbsp; 이 예제에서 해당 항공편(가장자리)의 원래 도시는 시애틀(모든 가장자리가 시작되는 지도의 왼쪽 위 파란색 원)입니다.</p>\n\n<p><a href=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/5408d9ab-53b1-4d5f-8b6e-bfa06a96bc7d.png\"><img alt=\"image\" border=\"0\" height=\"575\" src=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/5a4233c7-c18e-46ee-9e7c-210b791b3354.png\" style=\"border-image: none; padding-top: 0px; padding-right: 0px; padding-left: 0px; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;\" title=\"이미지\" width=\"920\"></a></p>\n\n<p align=\"center\"><em>그림: 공항 D3.js 도시 간 항공편인 공항(파란색 원) 및 가장자리(검은색 선)의 시각화입니다.</em></p>\n\n<h2 align=\"left\">Cosmos DB&nbsp; 그래프를 Spark와 통합하는 이점</h2>\n\n<p align=\"left\">Azure Cosmos DB 그래프 및 Spark 커넥터로 작업할 때의 주요 이점 중 하나는 Gremlin 쿼리 및 Spark 데이터 프레임(뿐만 아니라 다른 Spark 쿼리)을 동일한 데이터 컨테이너(그래프, 테이블 또는 문서 컬렉션)에 대해 실행할 수 있다는 것입니다.&nbsp; 예를 들어 아래는 Azure Cosmos DB 그래프에 저장된 이 플라이트 그래프에 대한 간단한 Gremlin Groovy 쿼리입니다.</p>\n\n<pre class=\"prettyprint\">\n         \\,,,/\n         (o o)\n-----oOOo-(3)-oOOo-----\nplugin activated: tinkerpop.server\nplugin activated: tinkerpop.utilities\nplugin activated: tinkerpop.tinkergraph\ngremlin&gt; :remote connect tinkerpop.server conf/remote-secure.yaml\n==&gt;Configured tychostation.graphs.azure.com/52.173.137.146:443\n\ngremlin&gt; // How many flights into each city leaving SEA\n==&gt;true\ngremlin&gt; :&gt; g.V().has(&#39;iata&#39;, &#39;SEA&#39;).outE(&#39;flight&#39;).inV().values(&#39;city&#39;).groupCount()\n==&gt;[Chicago:1088,New York:432,Dallas:800,Miami:90,Washington DC:383,Newark:345,Boston:315,Orlando:116,Philadelphia:193,Fort Lauderdale:90,Minneapolis:601,Juneau:180,Ketchikan:270,Anchorage:1097,Fairbanks:260,San Jose:611,San Francisco:1698,San Diego:617,Oakland:798,Sacramento:629,Los Angeles:1804,Orange County:569,Burbank:266,Ontario:201,Palm Springs:236,Las Vegas:1204,Phoenix:1228,Tucson:90,Austin:90,Denver:1231,Spokane:269,San Antonio:90,Salt Lake City:860,Houston:568,Atlanta:521,St. Louis:90,Kansas City:95,Honolulu, Oahu:415,Kahului, Maui:270,Lihue, Kauai:128,Long Beach:345,Detroit:244,Cincinnati:4,Omaha:90,Santa Barbara:90,Fresno:142,Colorado Springs:90,Portland:602,Jackson Hole:13,Cleveland:6,Charlotte:169,Albuquerque:105,Reno:90,Milwaukee:82]\n\n\ngremlin&gt; // SEA -&gt; Reno flight delays\n==&gt;true\ngremlin&gt; :&gt; g.V().has(&#39;iata&#39;, &#39;SEA&#39;).outE(&#39;flight&#39;).as(&#39;e&#39;).inV().has(&#39;iata&#39;, &#39;RNO&#39;).select(&#39;e&#39;).values(&#39;delay&#39;).sum()\n==&gt;963</pre>\n\n<p>위의 코드는 <strong>tychostation </strong>그래프(tychostation.graphs.azure.com)에 연결하여 다음 Gremlin Groovy 쿼리를 실행합니다.</p>\n\n<ul>\n <li>그래프 순회 및 groupCount()를 사용하여 이 데이터 세트에 시애틀에서 출발하여 나열된 목적지 도시(예: 시애틀에서 시카고로 가는 항공편 1088편)의 수를 결정합니다.</li>\n <li>그래프를 사용하여 시애틀에서 리노로 가는 90개 항공편(즉, 지연 963분)의 총 지연 시간(분)을 결정합니다.</li>\n</ul>\n\n<p>동일한 타이코스테이션 그래프를 사용하는 Spark 커넥터를 사용하여 자체 Spark DataFrame 쿼리를 실행할 수도 있습니다. 위의 Spark 커넥터 코드&rsquo; 조각에 따라 이 경우&rsquo; HDInsight Jupyter Notebook 서비스를 사용하여 Spark SQL 쿼리 &ndash; 를 실행할 수 있습니다.</p>\n\n<h3>시애틀에서 출발하는 상위 5개 목적지 도시</h3>\n\n<pre class=\"prettyprint\">\n%%sql\nselect a.city, sum(f.delay) as TotalDelay \nfrom delays f \njoin airports a \n  on a.iata = f.dst \nwhere f.src = &#39;SEA&#39; and f.delay &lt; 0 \ngroup by a.city \norder by sum(f.delay) limit 5\n</pre>\n\n<p><a href=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/596d31e9-6b5a-4a98-a0d5-ccbbaeefd47e.png\"><img alt=\"image\" border=\"0\" height=\"261\" src=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/c68f83f3-90c6-45d6-a42f-e9c16a4b26af.png\" style=\"border-image: none; padding-top: 0px; padding-right: 0px; padding-left: 0px; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;\" title=\"이미지\" width=\"640\"></a></p>\n\n<h3>시애틀에서 출발하는 대상 도시별 지연 중앙값 계산</h3>\n\n<pre class=\"prettyprint\">\n%%sql\nselect a.city, percentile_approx(f.delay, 0.5) as median_delay \nfrom delays f \njoin airports a \n  on a.iata = f.dst \nwhere f.src = &#39;SEA&#39; and f.delay &lt; 0 \ngroup by a.city \norder by median_delay\n</pre>\n\n<p><a href=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/7bc67496-97fa-4471-b83e-a5f41d542d6d.png\"><img alt=\"image\" border=\"0\" height=\"259\" src=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/ad11342c-9068-4ab6-be3f-3e02a27f75f5.png\" style=\"border: 0px currentColor; border-image: none; padding-top: 0px; padding-right: 0px; padding-left: 0px; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;\" title=\"이미지\" width=\"640\"></a></p>\n\n<p>Azure Cosmos DB를 사용하면 <em><u>동일한</u></em> 그래프를 대상으로 하는 Apache Tinkerpop Gremlin 쿼리와 Apache Spark DataFrame 쿼리를 모두 사용할 수 있습니다.</p>\n\n<h2>Azure Cosmos DB 문서 데이터 모델 작업</h2>\n\n<p>Azure Cosmos DB 그래프, 테이블 또는 문서를 사용하든, Azure Cosmos DB용 Spark 커넥터의 관점에서 보면 코드는 동일합니다.&nbsp; 궁극적으로 이러한 데이터 모델에 연결하는 템플릿은 아래에 나와 있습니다.</p>\n\n<ol>\n <li>연결을 구성합니다.</li>\n <li>구성 및 DataFrame을 빌드합니다.</li>\n <li>또한 voila &ndash; Apache Spark는 Azure Cosmos DB와 함께 작동합니다.</li>\n</ol>\n\n<pre class=\"prettyprint\">\n// Initialization\nimport com.microsoft.azure.cosmosdb.spark.schema._\nimport com.microsoft.azure.cosmosdb.spark._\nimport com.microsoft.azure.cosmosdb.spark.config.Config\n\n\n// Configure your connection\nval baseConfigMap = Map(\n&quot;Endpoint&quot; -&gt; &quot;https://$documentContainer$.documents.azure.com:443/&quot;,\n&quot;Masterkey&quot; -&gt; &quot;$masterKey$&quot;\n&quot;Database&quot; -&gt; &quot;$database$&quot;,\n&quot;Collection&quot; -&gt; &quot;$collection$&quot;, \n&quot;SamplingRatio&quot; -&gt; &quot;1.0&quot;,\n&quot;schema_samplesize&quot; -&gt; &quot;1000&quot;\n)\n\n// Build config and DataFrame\nval baseConfig = Config(baseConfigMap)\nval baseColl = spark.sqlContext.read.cosmosDB(baseConfig)\n</pre>\n\n<p>또한 Azure Cosmos DB용 Spark 커넥터를 사용하면 Spark 작업자 노드와 Azure Cosmos DB 데이터 파티션 간에 데이터가 병렬화됩니다.&nbsp; 따라서 데이터가 테이블, Graph 또는 문서에 저장되든, Apache Spark를 사용하여 Machine Learning 및 데이터 과학 문제를 해결할 때 Azure Cosmos DB에서 지원되는 성능, 확장성, 처리량 및 일관성을 모두 얻을 수 있습니다.</p>\n\n<p><a href=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/b57acb00-bbd4-4580-82e0-312f69853eec.png\"><img alt=\"image\" border=\"0\" height=\"332\" src=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/8c63299d-8122-4ca2-97f7-aa18c59408a6.png\" style=\"border-image: none; padding-top: 0px; padding-right: 0px; padding-left: 0px; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;\" title=\"이미지\" width=\"920\"></a></p>\n\n<h2>다음 단계</h2>\n\n<p>이 블로그 게시물&rsquo;에서는 Azure Cosmos DB용 Spark 커넥터가 Azure Cosmos DB에서 지원하는 여러 데이터 모델과 원활하게 상호 작용하는 방법을 살펴보았습니다. Azure Cosmos DB를 사용하는 Apache Spark를 사용하면 빅 데이터에 대한 임시 대화형 쿼리뿐만 아니라 고급 분석, 데이터 과학, 기계 학습 및 인공 지능을 모두 사용할 수 있습니다. Azure Cosmos DB는 전 세계 다양한 원본에서 증분 방식으로 수집되는 데이터를 캡처하는 데 사용할 수 있습니다. 여기에는 소셜 분석, 시계열, 게임 또는 애플리케이션 원격 분석, 소매 카탈로그, 최신 추세 및 카운터, 감사 로그 시스템이 포함됩니다. 그런 다음 Spark를 사용하여 Azure Cosmos DB에서 데이터&nbsp; 조각을 기반으로 대규모로 전역적으로 고급 분석 및 AI 알고리즘을&nbsp; 실행할 수 있습니다.&nbsp; Azure Cosmos DB가 <a href=\"https://azure.microsoft.com/blog/azure-cosmos-db-microsofts-globally-distributed-multi-model-database-service/\">업계&rsquo; 최초로 전 세계에 분산된 다중 모델 데이터베이스 서비스</a>인 경우 Azure Cosmos DB용 Spark 커넥터는 테이블, 그래프 및 문서 데이터 모델 &ndash; 에서 더 많은 작업을 수행할 수 있습니다.</p>\n\n<p>쿼리 실행을 시작하려면 <a href=\"https://portal.azure.com/#create/Microsoft.DocumentDB\">Azure Portal에서 새 Azure Cosmos DB 계정을 만들고</a> <a href=\"https://github.com/Azure/azure-cosmosdb-spark\">Azure-CosmosDB-Spark GitHub</a> 리포지토리에서 프로젝트를 사용합니다.</p>\n\n<p>Twitter <a href=\"https://twitter.com/AzureCosmosDB\">@AzureCosmosDB</a> 및 CosmosDB에서 Microsoft를 팔로우하여 최신 Azure Cosmos DB 뉴스 및 <a href=\"https://twitter.com/search?q=%23cosmosdb&amp;lang=en\">#</a> 기능을 최신 상태로 유지하고 <a href=\"https://stackoverflow.com/questions/tagged/azure-cosmosdb\">Stack Overflow의 개발자 포럼에</a> 문의하세요.</p>"
