### YamlMime:Yaml
ms.openlocfilehash: 7506d3a66066246c76f53811e51d852110afa3e9
ms.sourcegitcommit: d03bdc7fe5447adb6530886aab848b75fe8fa8ee
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 03/11/2022
ms.locfileid: "139911852"
Slug: how-to-extract-building-footprints-from-satellite-images-using-deep-learning
Title: 딥 러닝을 사용하여 위성 이미지에서 건물 공간을 추출하는 방법
Summary: '지구용 AI 팀의 일환으로 Microsoft 내의 파트너 및 다른 연구원들과 협력하여 기계 학습 및 기타 AI 접근 방식을 사용하여 글로벌 환경 문제를 해결하는 새로운 방법을 개발합니다. 이 게시물에서는 지리 공간적 데이터로부터 인사이트를 얻기 위해 딥 러닝 모델을 학습하기 위해 Azure 인프라를 사용하는 샘플 프로젝트를 강조합니다. '
Content: >-
  <p><a href="https://www.microsoft.com/en-us/aiforearth" target="_blank">지구용 AI</a> 팀의 일환으로 Microsoft 내의 파트너 및 다른 연구원들과 협력하여 기계 학습 및 기타 AI 접근 방식을 사용하여 글로벌 환경 문제를 해결하는 새로운 방법을 개발합니다. 이 게시물에서는 지리 공간적 데이터로부터 인사이트를 얻기 위해 딥 러닝 모델을 학습하기 위해 Azure 인프라를 사용하는 <a href="https://github.com/aiforearth/SpaceNetExploration" target="_blank">샘플 프로젝트를</a> 강조합니다. 이러한 도구를 통해 마침내 삼림 벌채 및 인간-야생 동물 분쟁과 같은 문제에 대한 솔루션의 영향을 정확하게 모니터링하고 측정하여 가장 효과적인 보존 노력에 투자할 수 있습니다.</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/6ba6b1d1-cae5-468a-b22b-8276a7c0b263.png"><img alt="Image1" border="0" height="750" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/ac1cbed4-ec9e-420f-bff0-1417621b349b.png" style="margin: 0px auto; border: 0px currentcolor; border-image: none; float: none; display: block; background-image: none;" title="Image1" width="1452"></a></p>


  <h2>지리 공간적 데이터에 기계 학습 적용</h2>


  <p>환경 공간에서 가장 널리 사용되는 도구와 데이터 세트를 살펴보면 위성 이미지 형태의 원격 감지 데이터가 뛰어올랐습니다.</p>


  <p>오늘날 지리 공간적 데이터에 대한 실무 전문가는 기존 소프트웨어의 도움으로 이러한 컬렉션을 수동으로 살펴보고, 측정값과 추세를 얻기 위해 관심 있는 개체를 찾고, 계산하고, 요약하는 등의 작업을 수행합니다. 고해상도 위성 이미지를 매주 또는 매일 쉽게 사용할 수 있게 됨에 따라 데이터를 활용하여 보다 정보에 입각한 결정을 내릴 수 있도록 이러한 노력에 AI를 참여시키는 것이 필수적입니다.</p>


  <p>AI의 활성 필드인 지리 공간적 데이터와 컴퓨터 비전은 일반적인 알고리즘으로 자동화할 수 없는 시각적 데이터와 관련된 작업, 레이블이 지정된 데이터의 풍부, 그리고 적시에 이해되기를 기다리는 레이블이 지정되지 않은 데이터 등 자연 파트너입니다. 지리 공간적 데이터와 기계 학습 커뮤니티는 이 전면에 참여하여 사람들이 오버헤드 이미지에 대한 컴퓨터 비전 솔루션을 만들 수 있도록 <a href="https://www.iarpa.gov/challenges/fmow.html" target="_blank">fMoW</a>(기능 지도) 및 xView 데이터 세트와 같은 여러 데이터 세트를 게시했습니다.</p>


  <p>지리 공간적 데이터와 AI를 매일 사용하는 애플리케이션에 주입하는 예는 위성 이미지를 사용하여 건물의 거리 지도 주석을 추가하는 것입니다. 2018년 6월, Bing 동료들은 많은 위치 기반 서비스 및 애플리케이션을 지원하는 오픈 데이터 이니셔티브인 오픈 스트리트 맵 프로젝트를 지원하기 위해 미국에서 1억 2,400만 개의 건물 발자국을 출시했다고 <a href="https://blogs.bing.com/maps/2018-06/microsoft-releases-125-million-building-footprints-in-the-us-as-open-data" target="_blank">발표</a>했습니다. Bing 팀은 각 픽셀을 건물 또는 비건축으로 분류하는 심층 신경망 모델을 학습하고 적용하여 위성 이미지에서 많은 건물 공간을 만들 수 있었습니다. 이제 직접 수행할 수 있습니다!</p>


  <p>이 블로그 게시물과 함께 <a href="https://github.com/aiforearth/SpaceNetExploration" target="_blank">제공되는 샘플 프로젝트를</a> 통해 Azure <a href="https://azuremarketplace.microsoft.com/en-ca/marketplace/apps/microsoft-ads.dsvm-deep-learning" target="_blank">DLVM</a>(Deep Learning Virtual Machine)에서 이러한 모델을 학습하는 방법을 안내합니다. <a href="https://spacenetchallenge.github.io/" target="_blank">SpaceNet</a> 이니셔티브에서 사용할 수 있는 레이블이 지정된 데이터를 사용하여 딥 러닝을 사용하여 시각적 환경 데이터에서 정보를 추출하는 방법을 보여 줍니다. 시작하려는 경우 GitHub <a href="https://github.com/aiforearth/SpaceNetExploration" target="_blank">리포지토리</a>로 이동하여 코드 실행 또는 사용자 고유의 데이터 세트에 대한 수정에 대한 데이터 세트, 스토리지 옵션 및 지침을 읽을 수 있습니다.</p>


  <h2>의미 체계 구분</h2>


  <p>Computer Vision에서 배경 또는 사람과 같은 다양한 개체 클래스에 속하는 픽셀을 마스킹하는 작업을 의미 체계 구분이라고 합니다. 의미 체계 세분화 모델 (PyTorch에서 구현 된 <a href="https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/" target="_blank">U-Net</a>, Bing 팀이 사용한 것과는 다른) 우리가 훈련하는 것은 위성, 항공 또는 무인 항공기 이미지를 &ndash; 분석하는 다른 작업에 사용할 수 있습니다 당신은 위성 이미지에서 도로를 추출하는 동일한 방법을 사용할 수 있습니다, <a href="https://blogs.technet.microsoft.com/machinelearning/2018/03/12/pixel-level-land-cover-classification-using-the-geo-ai-data-science-virtual-machine-and-batch-ai/" target="_blank">토지 사용을 유추</a>하고 <a href="https://www.microsoft.com/developerblog/2018/07/05/satellite-images-segmentation-sustainable-farming/" target="_blank">지속 가능한 농업 관행을 모니터링</a>, 뿐만 아니라 CT 스캔에서 폐 찾기와 같은 광범위한 도메인의 응용 프로그램에 대한 <a href="https://blogs.technet.microsoft.com/machinelearning/2018/03/07/using-microsoft-ai-to-build-a-lung-disease-prediction-model-using-chest-x-ray-images/" target="_blank"> 폐 질환 예측</a> 및 거리 장면 평가.</p>


  <p align="center"><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/e722da44-5a11-44c6-962e-a12018bf10c1.png"><img alt="Image2_semantic_segmentation" border="0" height="256" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/5a721afb-b364-4c07-89cb-9b8dafd8dc4d.png" style="margin: 0px auto; border: 0px currentcolor; border-image: none; float: none; display: block; background-image: none;" title="" width="585"></a> Image2_semantic_segmentation<em> 토론토 대학교 팅우 왕(Tingwu Wang)의 슬라이드 일러스트레이션(<a href="https://www.cs.toronto.edu/~tingwuwang/semantic_segmentation.pdf" target="_blank">출처</a>).</em></p>


  <h2>위성 이미지 데이터</h2>


  <p>스페이스넷의 데이터는 파리, 상하이, 하르툼, 라스베가스 등 건물이 풍부한 4개 도시에 걸쳐 있는 3 채널 고해상도(31cm) 위성 이미지입니다. 샘플 코드에서는 650 x 650 제곱 픽셀 크기의 3854개 이미지로 구성된 Vegas 하위 집합을 사용합니다. 교육 이미지의 약 17.37%는 건물이 없습니다. 이는 데이터의 비교적 적은 비율이므로 이미지를 제외하거나 다시 샘플화하지 않았습니다. 또한 학습 데이터의 모든 픽셀 중 76.9%가 배경이고, 15.8%는 건물 내부, 7.3%는 테두리 픽셀입니다.</p>


  <p>원본 이미지는 SpaceNet에서 제공하는 유틸리티 함수( <a href="https://github.com/aiforearth/SpaceNetExploration" target="_blank">리포지토리</a>의 세부 정보)를 사용하여 일부 겹치는 9개의 작은 칩으로 잘립니다. 레이블은 맵에서 벡터 기하 도형 개체를 나타내는 태그 언어인 <a href="https://en.wikipedia.org/wiki/Well-known_text" target="_blank">WKT</a>(잘 알려진 텍스트)를 사용하여 정의된 다각형 셰이프로 릴리스됩니다. 이러한 레이블은 입력 이미지와 동일한 차원의 2D 레이블로 변환됩니다. 여기서 각 픽셀은 건물의 배경, 건물 경계 또는 내부 중 하나로 레이블이 지정됩니다.</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/b726f753-2690-4b53-9e46-d6f4377264e8.png"><img alt="Image3" border="0" height="328" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/f9e57c53-9c00-4940-9a09-f3ef39321dca.png" style="margin: 0px auto; border: 0px currentcolor; border-image: none; float: none; display: block; background-image: none;" title="Image3" width="640"></a></p>


  <p>일부 칩은 아래 예제와 같이 부분적으로 또는 완전히 비어 있습니다. 이는 원래 위성 이미지의 아티팩트이며 모델은 빈 지역에 건물 공간을 제안하지 않을 만큼 견고해야 합니다.</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/331e323f-fe23-4214-91ac-3871897d2613.png"><img alt="Image4" border="0" height="284" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/3092e8ce-e7d1-4ccf-aeaf-e2c08cc1f165.png" style="margin: 0px auto; border: 0px currentcolor; border-image: none; float: none; display: block; background-image: none;" title="Image4" width="1024"></a></p>


  <h2>모델 학습 및 적용</h2>


  <p>샘플 코드에는 DLVM에서 학습 및 평가 파이프라인을 수행하는 연습이 포함되어 있습니다. 다음 구분 결과는 위에 표시된 입력 이미지 및 레이블 쌍에 대해 학습하는 동안 다양한 Epoch에서 모델에 의해 생성됩니다. 이 이미지는 다양한 색상, 도로, 포장, 나무 및 야드의 지붕이있는 건물을 특징으로합니다. 우리는 처음에 네트워크가 건물 블록과 붉은 지붕 (도로의 색상과 다른)을 가진 건물의 가장자리를 식별하는 법을 배우고 Epoch 5 이후 모든 지붕 색의 건물을 식별하는 법을 배운다는 것을 관찰합니다. Epoch 7 이후, 네트워크는 빌드 픽셀이 테두리 픽셀로 묶여 도로 픽셀과 분리된다는 것을 알게 되었습니다. Epoch 10 이후에는 건물의 모양이 더 정의됨에 따라 건물 픽셀의 작고 시끄러운 클러스터가 사라지기 시작합니다.</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/36551886-5a72-4fcc-914a-7e43bd6cb752.png"><img alt="Image5" border="0" height="768" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/4f7d85ef-1537-4d2c-9d4c-d62154f75048.png" style="margin: 0px auto; border: 0px currentcolor; border-image: none; float: none; display: block; background-image: none;" title="Image5" width="718"></a></p>


  <p>마지막 단계는 <em>경계를 빌드</em> 할 것으로 예측되는 모든 픽셀을 <em>백그라운드</em> 로 할당하여 문서 픽셀의 Blob을 격리하여 다각형을 생성하는 것입니다. 연결된 건물 픽셀의 Blob은 가양성 제안을 줄이기 위해 튜닝할 수 있는 매개 변수인 최소 다각형 영역 임계값에 따라 다각형 형식으로 설명됩니다.</p>


  <h2>학습 및 모델 매개 변수</h2>


  <p>학습 프로세스, 모델 아키텍처 및 튜닝할 수 있는 다각형 단계에 대한 여러 매개 변수가 있습니다. Adam 최적화 프로그램(다른 매개 변수의 기본 설정)에 대해 0.0005의 학습 속도와 10개의 칩의 일괄 처리 크기를 선택했는데, 이는 상당히 잘 작동했습니다.</p>


  <p>절차의 CNN 부분과 관련이없는 또 다른 매개 변수는 건물 픽셀의 Blob이 삭제되는 아래의 최소 다각형 영역 임계값입니다. 이 임계값을 0에서 300 제곱 픽셀로 늘리면 시끄러운 거짓 세그먼트가 제외됨에 따라 가양성 수가 빠르게 감소합니다. 최적 임계값은 약 200 제곱 픽셀입니다.</p>


  <p>학습 중 총 손실을 계산하는 세 가지 클래스(배경, 건물 경계, 건물 내부)의 가중치는 실험할 또 다른 매개 변수입니다. <em>건물 내부에</em> 더 많은 가중치를 부여하면 모델이 훨씬 더 작은 건물을 감지하는 데 도움이 되는 것으로 나타났습니다(아래 그림 참조).</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/8a35d853-2b16-47bd-980d-5c81ae2b18e1.png"><img alt="Image6" border="0" height="1086" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/f410efc0-8fe8-4268-8303-09cd4189bc64.png" style="margin: 0px auto; border: 0px currentcolor; border-image: none; float: none; display: block; background-image: none;" title="Image6" width="1888"></a></p>


  <p align="center"><em>그림의 각 플롯은 300 평방 픽셀에서 6000까지 영역별로 설정된 유효성 검사에서 다각형을 빌드하는 히스토그램입니다. 오렌지의 참 긍정 검출 횟수는 제안된 다각형이 일치하는 접지 진리 다각형의 영역을 기반으로 합니다. 위쪽 히스토그램은 배경에 대한 손실 함수에서 비율 1:1:1의 가중치에 대한 것입니다. 내부 빌드: 경계 빌드; 아래쪽 히스토그램은 비율 1:8:1의 가중치에 대한 것입니다. 우리는 작은 건물이 표현되는 히스토그램의 왼쪽을 향해, 오렌지의 진정한 긍정적 인 제안에 대한 막대가 하단 플롯에서 훨씬 더 높은 것을 볼 수 있습니다.</em></p>


  <h2>마지막 생각</h2>


  <p>이러한 방식으로 생성된 건물 발자국 정보를 사용하여 정착지의 공간 분포를 문서화하여 연구원들이 도시화 추세와 기후 이주와 같은 기후 변화의 발달 영향을 정량화할 수 있습니다. 이 기법은 다양한 상황에서 적용할 수 있으며 이 구체적인 예제가 특정 문제를 해결하는 지침이 되기를 바랍니다.</p>


  <p>지리 공간적 데이터를 다루는 사람들에게 좋은 또 다른 소식은 Azure가 이미 ESRIs&rsquo; <a href="https://www.esri.com/arcgis/products/arcgis-pro/overview" target="_blank">ArcGIS Pro</a> 지리적 정보 시스템을 갖춘 지리적 인공 지능 데이터 과학 가상 머신(<a href="https://docs.microsoft.com/en-gb/azure/machine-learning/data-science-virtual-machine/geo-ai-dsvm-overview" target="_blank">Geo-DSVM</a>)을 제공한다는 것입니다. 또한 딥 러닝 모델을 학습하고 ArcGIS Pro 통합하여 시작하는 데 도움이 되는 Geo-DSVM을 사용하는 방법에 대한 <a href="https://github.com/Azure/pixel_level_land_classification" target="_blank">자습서</a>를 만들었습니다.</p>


  <p>마지막으로, 조직에서 데이터 및 기계 학습을 사용하여 환경 문제를 해결하기 위한 솔루션을 찾고 있는 경우 Azure 리소스를 활용하는 데 더 잘 지원되고 이 목적 커뮤니티의 일부가 될 수 있도록 <a href="https://www.microsoft.com/en-us/aiforearth/grants.aspx" target="_blank">지구용 AI 보조금을</a> 신청하는 것이 좋습니다.</p>


  <h3>Acknowledgement</h3>


  <p>2018년 봄 스탠포드&rsquo; CS231n 교육 과정의 일환으로 저와 함께 이 프로젝트의 원래 버전을 작업한 Microsoft의 소프트웨어 엔지니어 빅터 리앙(Victor Liang)과 이 블로그 게시물 초안 작성에 도움을 준 Microsoft의 수석 데이터 과학자 인 Wee Hyong Tok에게 감사드립니다.</p>
