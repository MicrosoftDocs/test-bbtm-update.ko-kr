### YamlMime:Yaml
ms.openlocfilehash: c2039c1d7aec90fbb8d2f7e9d01b879726ca16cf
ms.sourcegitcommit: d03bdc7fe5447adb6530886aab848b75fe8fa8ee
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 03/11/2022
ms.locfileid: "139911732"
Slug: microsoft-and-nvidia-bring-gpu-accelerated-machine-learning-to-more-developers
Title: Microsoft 및 NVIDIA는 더 많은 개발자에게 GPU 가속 기계 학습을 제공합니다.
Summary: 데이터 볼륨 및 대기 시간 요구 사항이 계속 증가함에 따라 GPU는 대규모로 기계 학습(ML)을 수행하기 위한 필수 도구가 되었습니다. 이번 주에 Microsoft와 NVIDIA가 함께 구축한 두 가지 통합을 발표하여 더 많은 개발자와 데이터 과학자를 위한 업계 최고의 GPU 가속을 실현할 수 있게 되어 기쁩니다.
Content: >-
  <p>데이터 볼륨 및 대기 시간 요구 사항이 계속 증가함에 따라 GPU는 대규모로 기계 학습(ML)을 수행하기 위한 필수 도구가 되었습니다. 이번 주에 Microsoft와 NVIDIA가 함께 구축한 두 가지 통합을 발표하여 더 많은 개발자와 데이터 과학자를 위한 업계 최고의 GPU 가속을 실현할 수 있게 되어 기쁩니다.</p>


  <ul>
      <li><a href="https://azure.microsoft.com/en-us/services/machine-learning-service/">Azure Machine Learning 서비스는</a> 기존 기계 학습 실무자가 NVIDIA GPU를 사용하여 파이프라인을 쉽게 가속화할 수 있도록 하는 NVIDIA의 오픈 소스 소프트웨어 라이브러리인 RAPIDS를 통합한 최초의 주요 클라우드 ML 서비스입니다.</li>
      <li><a href="https://azure.microsoft.com/en-us/blog/onnx-runtime-is-now-open-source/">ONNX 런타임</a> 은 NVIDIA TensorRT 가속 라이브러리를 통합하여 딥 러닝 실무자가 프레임워크 선택에 관계없이 빠른 추론을 달성할 수 있도록 합니다.</li>
  </ul>


  <p>이러한 통합은 Azure에서 이미 풍부한 NVIDIA GPU 기술을 사용하여 빌드되어 전체 ML 파이프라인의 속도를 향상합니다.</p>


  <p><em>&ldquo;NVIDIA와 Microsoft는 프레임워크&rdquo; 선택에 관계없이 개발자와 데이터 과학자를 위한 엔드투엔드 데이터 과학 파이프라인을 가속화하기 위해 최선을 다하고 있다고 NVIDIA의 가속 컴퓨팅 소프트웨어 제품 관리 수석 디렉터 Kari Briski는 말합니다. &ldquo; NVIDIA TensorRT와 ONNX 런타임 및 RAPIDS를 Azure Machine Learning 서비스와&rsquo; 통합하면 기계 학습 실무자가 데이터 과학 워크플로에서 NVIDIA GPU를 더 쉽게 활용할 수 있습니다.&rdquo;</em></p>


  <h2>NVIDIA RAPIDS와 Azure Machine Learning 서비스 통합</h2>


  <p>Azure Machine Learning 서비스는 RAPIDS를 통합한 최초의 주요 클라우드 ML 서비스로, 기존 기계 학습 파이프라인에 최대 20배의 속도를 제공합니다. RAPIDS는 GPU 가속 기계 학습을 수행하여 더 빠른 데이터 준비 및 모델 학습을 가능하게 하는 NVIDIA CUDA를 기반으로 하는 라이브러리 모음입니다. RAPIDS는 NVIDIA GPU의 기능을 활용하여 일반적인 데이터 과학 작업을 크게 가속화합니다.</p>


  <p>간단한 <a href="https://github.com/Azure/MachineLearningNotebooks/blob/master/contrib/RAPIDS/azure-ml-with-nvidia-rapids.ipynb">Jupyter Notebook</a>으로 Azure Machine Learning 서비스에 노출된 RAPIDS는 고성능 GPU 실행을 위해 NVIDIA CUDA를 사용하여 사용자에게 친숙한 Python 인터페이스를 통해 GPU 병렬 처리 및 높은 메모리 대역폭을 노출합니다. 여기에는 Pandas 사용자에게 친숙한 cuDF라는 데이터 프레임 라이브러리와 Scikit-learn에서 사용할 수 있는 모든 기계 학습 알고리즘의 GPU 버전을 제공하는 cuML이라는 ML 라이브러리가 포함되어 있습니다. 또한 DASK를 사용하면 RAPIDS는 Azure에서 다중 노드 다중 GPU 구성을 활용할 수 있습니다.</p>


  <p>Azure Machine Learning 서비스의 <a href="https://aka.ms/rapids-blog">RAPIDS에 대해 자세히 알아보</a>거나 NVIDIA GTC에서 <a href="https://gputechconf2019.smarteventscloud.com/connect/search.ww#loadSearch-searchPhrase=microsoft&amp;searchType=session&amp;tc=0&amp;sortBy=dayTime&amp;p=">Azure의 RAPIDS 세션에</a> 참석하세요.</p>


  <h2>미리 보기에서 NVIDIA TensorRT와 ONNX 런타임 통합</h2>


  <p>ONNX 런타임에서 NVIDIA TensorRT 실행 공급자의 미리 보기를 오픈 소스로 제공하게 되어 기쁩니다. 이 릴리스에서는 개발자가 프레임워크 선택에 관계없이 업계 최고의 GPU 가속을 쉽게 활용할 수 있도록 하여 개방형 및 상호 운용 가능한 AI를 향해 한 걸음 더 나아가고 있습니다. 이제 개발자는 ONNX 런타임을 통해 TensorRT의 기능을 활용하여 PyTorch, TensorFlow, <a href="https://onnx.ai/">MXNet</a> 및 기타 많은 인기 프레임워크에서 내보내거나 변환할 수 있는 ONNX 모델의 추론을 가속화할 수 있습니다. 현재 ONNX 런타임은 Bing, Office 등에서 수십억 명의 사용자에게 서비스를 제공하는 핵심 시나리오를 지원합니다.</p>


  <p>TensorRT 실행 공급자를 사용하면 ONNX 런타임이 일반 GPU 가속에 비해 동일한 하드웨어에서 더 나은 추론 성능을 제공합니다. Bing MultiMedia 서비스의 내부 워크로드에서 TensorRT 실행 공급자를 사용하여 성능이 최대 2배 향상되었습니다.</p>


  <p>자세한 내용은 ONNX 런타임 및 TensorRT 통합에 대한 <a href="https://aka.ms/trt-blog">심층 블로그</a> 를 확인하거나 NVIDIA GTC의 <a href="https://gputechconf2019.smarteventscloud.com/connect/search.ww#loadSearch-searchPhrase=ONNX&amp;searchType=session&amp;tc=0&amp;sortBy=dayTime&amp;p=">ONNX 세션에</a> 참석하세요.</p>


  <h2>모두를 위한 기계 학습 가속화</h2>


  <p>NVIDIA와의 협업은 개발자와 데이터 과학자가 혁신을 더 빠르게 제공할 수 있도록 돕는 벤처의 또 다른 이정표입니다. Microsoft는 프레임워크, 도구 및 애플리케이션 선택에 관계없이 모든 기계 학습 실무자의 생산성을 가속화하기 위해 최선을 다하고 있습니다. 이러한 새로운 통합을 통해 AI 혁신을 더 쉽게 추진할 수 있고 커뮤니티가 이를 사용해 보도록 강력히 장려하기를 바랍니다. 여러분의 의견을 기대하세요!</p>
