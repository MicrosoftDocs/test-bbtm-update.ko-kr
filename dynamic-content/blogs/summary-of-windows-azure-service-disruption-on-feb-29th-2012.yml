### YamlMime:Yaml
ms.openlocfilehash: b81e0cd47bfd499c4f80891d774644b4e5e6805f
ms.sourcegitcommit: d03bdc7fe5447adb6530886aab848b75fe8fa8ee
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 03/11/2022
ms.locfileid: "139900235"
Slug: summary-of-windows-azure-service-disruption-on-feb-29th-2012
Title: 2012년 2월 29일에 Windows Azure 서비스 중단 요약
Summary: 소개 내 3 월 1 게시물에 대한 후속 작업으로, 나는 2 월 29 일의 서비스 중단의 근본 원인 분석의 결과를 공유하고 싶습니다. &nbsp;우리는 우리의 고객의 많은 것을 알고 ...
Content: '<h3>소개</h3>  <p>3월 1일 게시물의 후속 작업으로, 2월 29일의 서비스 중단에 대한 근본 원인 분석 결과를 공유하고 싶습니다. &nbsp;우리는 많은 고객이 이 이벤트의 영향을 받았다는 것을 알고 있으며, 발생한 일, 발견된 문제, 이러한 문제를 해결할 계획 및 향후 유사한 발생을 방지하기 위해 인시던트에서 학습하는 방법에 대해 투명하게 파악하고자 합니다. &nbsp;&nbsp;</p>  <p>이번 사건으로 인한 중단, 가동 중지 시간 및 불편에 대해 진심으로 사과드립니다.&nbsp; 우리는 아래에 설명된 대로 영향을 받은 고객에게 서비스 크레딧을 사전에 발급할 것입니다.&nbsp; Azure를 개선하기 위해 학습을 사용하여 이미 열심히 노력하고 Windows.&nbsp;</p>  <h3>Windows Azure 및 서비스 중단 개요</h3>  <p>Windows Azure는 컴퓨팅, Storage, 네트워킹 및 Service Bus 및 SQL Azure 같은 상위 수준 서비스를 비롯한 다양한 서비스로 구성됩니다.&nbsp; 이 부분 서비스 중단은 Azure Compute 및 종속 서비스인 ACS(Access Control Service), Windows Azure Service Bus, SQL Azure Portal 및 데이터 동기화 Services에 Windows 영향을 줍니다.&nbsp; 그것은 Windows Azure Storage 또는 SQL Azure 영향을 미치지 않았다.</p>  <p>이 인시던트에 대한 트리거는 특정 소프트웨어 버그이지만, Windows Azure는 많은 구성 요소로 구성되며 이러한 중단을 복잡하게 만드는 정상 작업과의 다른 상호 작용이 있었습니다. 이 사건에는 두 단계가 있었습니다. 첫 번째 단계는 초기 소프트웨어 버그의 검색, 응답 및 수정에 초점을 맞췄습니다.&nbsp; 두 번째 단계는 진행 중인 일반적인 서비스 작업과의 예기치 않은 상호 작용으로 인해 영향을 받은 소수의 클러스터에 초점을 맞췄습니다.&nbsp; 문제의 기술 세부 정보를 이해하려면 일부 하위 수준 Windows Azure 구성 요소의 작동에 대한 배경 지식이 필요합니다.</p>  <h3>패브릭 컨트롤러, 에이전트 및 인증서</h3>  <p>Windows Azure에서 클라우드 애플리케이션은 Microsoft 데이터 센터의 물리적 서버에서 실행되는 가상 머신으로 구성됩니다. 서버는 그림 1에 표시된 것처럼 FC(패브릭 컨트롤러)라는 확장되고 중복된 플랫폼 소프트웨어 구성 요소에 의해 독립적으로 관리되는 약 1000개의 클러스터&rdquo;로 그룹&ldquo;화됩니다. 각 FC는 클러스터에서 실행되는 애플리케이션의 수명 주기를 관리하고, 제어되는 하드웨어의 상태를 프로비전하고 모니터링합니다. 서버가 실패했다고 판단될 때 정상 서버에서 가상 머신 인스턴스를 다시 환생하는 것과 같은 자율적인 작업과 애플리케이션 배포, 업데이트 및 확장과 같은 애플리케이션 관리 작업을 모두 실행합니다. 데이터 센터를 클러스터로 분할하면 FC 수준에서 오류가 격리되므로 특정 클래스의 오류가 발생하는 클러스터를 벗어나는 서버에 영향을 주지 않습니다.</p>  <p align="center"><img src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/2045.Outage1.png" alt="" border="0"></p>  <p align="center"><em>그림 1. 클러스터 및 패브릭 컨트롤러</em></p>  <p>Windows Azures&rsquo; PaaS(Platform as a Service) 기능의 일부로, 그림 2에 표시된 것처럼 VM에서 사용하는 OS 이미지에 배포하는 게스트 에이전트&rdquo;(GA)를 사용하여 &ldquo;VM에서 실행되는 애플리케이션과 긴밀하게 통합해야 합니다. 각 서버에는 &ldquo;FC가 애플리케이션이 HTTPS 엔드포인트를 보호하기 위해 패키지에 포함하는 SSL 인증서와 같은 애플리케이션 비밀을 배포하는 데 활용하는 HA(호스트 에이전트&rdquo; )가 있으며, &ldquo;VM이 정상인지 또는 FC가 복구 작업을 수행해야 하는지 여부를 확인하기 위해 GA로 하트비트를&rdquo; 합니다.</p>  <p align="center"><img src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/7824.Outage2.png" alt="" border="0"></p>  <p align="center"><em>그림 2. 호스트 에이전트 및 게스트 에이전트 초기화</em></p>  <p>인증서와 같은 애플리케이션 비밀은 물리적 또는 논리 네트워크를 통해 전송될 때 항상 암호화되므로 GA는 초기화할 때 전송 인증서&rdquo;를 &ldquo;만듭니다. GA가 HA와의 연결을 설정하는 동안 수행하는 첫 번째 단계는 HA에 전송 인증서의 공개 키 버전을 전달하는 것입니다. 그런 다음 HA는 비밀을 암호화할 수 있으며 GA에만 프라이빗 키가 있기 때문에 대상 VM의 GA만 암호를 해독할 수 있습니다.</p>  <p>새 전송 인증서를 생성해야 하는 몇 가지 경우가 있습니다. 대부분의 경우 사용자가 새 배포를 시작하거나, 배포가&rsquo; 확장되거나, 배포가 VM 운영 체제를 업데이트할 때 발생하는 새 VM을 만들 때만 발생합니다. 네 번째 사례는 FC가 다른 서버에 비정상으로 간주된 서버에서 실행 중인 VM을 환생하는 경우이며, 플랫폼이 서비스 복구를 호출 &ldquo;하는 프로세스입니다.&rdquo;</p>  <h3>윤일 버그</h3>  <p>GA는 전송 인증서를 만들 때 1년 유효 범위를 제공합니다. 현재 날짜의 자정 UST를 <i>유효한 날짜</i> 로 사용하고 해당 날짜로부터 1년을 <i>유효한</i> 날짜로 사용합니다. 윤일 버그는 GA가 단순히 현재 날짜를 복용하고 연도 <i>에</i> 하나를 추가하여 유효한 날짜를 계산한다는 것입니다. 즉, 윤일에 전송 인증서를 만들려고 시도한 모든 GA가 2013년 2월 29일의 <i>유효한</i> 날짜를 설정했는데, 이로 인해 인증서를 만들지 못했습니다.</p>  <p>앞서 설명한 것처럼 인증서 전송은 GA 초기화의 첫 번째 단계이며 HA에 연결하기 전에 필요합니다. GA가 인증서를 만들지 못하면 종료됩니다. HA는 GA에서 듣기 위한 25 분 시간 제한이 있습니다. GA가 해당 시간 제한 내에 연결하지 않으면&rsquo; HA는 VM&rsquo; OS를 다시 초기화하고 다시 시작합니다.</p>  <p>깨끗한 VM(고객 코드가 실행되지 않은 VM)이 GA 연결을 세 번 연속으로 시간 초과하면 HA는 GA가 그렇지 않으면 오류를 보고했기 때문에 하드웨어 문제가 원인이어야 한다고 결정합니다. 그런 다음 HA는 서버가 잘못되었다는 것을 FC에 보고하고 FC는 이를 HI(Human Investigate)라는 상태로 이동합니다. HI 상태의 서버에 대한 표준 자율 오류 복구 작업의 일환으로 FC는 실패한 서버에 할당된 모든 VM을 다른 서버에 다시 환생하여 복구합니다. 이와 같은 경우 VM을 사용 가능한 서버로 이동하면 윤일 버그가 GA 초기화 중에 재현되어 HI로 이동하는 서버가 연속됩니다.</p>  <p>연속 소프트웨어 버그로 인해 전체 클러스터가 중단되는 것을 방지하기 위해 FC는 HI 임계값을 가지며, 적중 시 기본적으로 전체 클러스터를 유사한 HI 상태로 이동합니다. 이 시점에서 FC는 내부적으로 시작된 모든 소프트웨어 업데이트를 중지하고 자동 서비스 복구를 사용하지 않도록 설정합니다. 이 상태는 성능이 저하되는 동안 운영자가 문제를 제어하고 복구할 수 있는 기회를 제공합니다.</p>  <h3>실행 중인 윤일 버그</h3>  <p>윤일 버그는 2월 28<sup>일</sup> 오후 4시 PST(2월 29<sup>일</sup> 00:00 UST)에 새 VM의 GA가 인증서 생성을 시도했을 때 즉시 트리거되었습니다. Storage 클러스터는 GA로 실행되지 않기&rsquo; 때문에 영향을 받지 않았지만 일반적인 애플리케이션 배포, 스케일 아웃 및 서비스 복구로 인해 새 VM이 생성되었습니다. 동시에 많은 클러스터가 FC, HA 및 GA의 새 버전 출시 중에 있었습니다. 이렇게 하면 해당 클러스터에서 버그가 즉시 적중되고 서버 HI 임계값이 오후 5시 15분 PST 이후 정확히 75분(3회 25분 시간 제한)에 도달했습니다. 버그가 업데이트되지 않은 클러스터를 통해 더 느리게 작동했지만 업데이트 클러스터에 대한 중요한 경보는 자동으로 업데이트를 중지하고 운영 직원에게 문제를 경고했습니다. 그들은 차례로 원인을 연구하고 오후 6시 38분 PST에서 우리의 개발자가 버그를 식별 통화 FC 개발자에게 통보했다.</p>  <p>이때까지 일부 애플리케이션에는 오프라인으로 단일 VM이 있고 일부는 여러 VM을 오프라인으로 사용했지만, 여러 VM이 있는 대부분의 애플리케이션은 일부 용량이 감소했음에도 불구하고 가용성을 유지했습니다. 고객이 실수로 실행 중인 애플리케이션에 더 많은 영향을 미치고, 애플리케이션을 확장하지 못하고, 새 애플리케이션을 배포하려고 하는 것을 방지하기 위해 전 세계 모든 클러스터에서 오후 6시 55분 PST에서 서비스 관리 기능을 사용하지 않도록 설정했습니다.&nbsp; 이 단계를 수행한 것은 이번이&rsquo; 처음입니다.&nbsp; 서비스 관리를 통해 고객은 애플리케이션을 배포, 업데이트, 중지 및 확장할 수 있지만 이미 배포된 애플리케이션의 지속적인 작업에는 필요하지 않습니다&rsquo;. 그러나 서비스 관리를 중지하면 고객이 현재 배포된 애플리케이션을 수정하거나 업데이트할 수 없습니다.&nbsp;</p>  <p>약 10:00PM PST까지 업데이트된 GA에 대한 테스트 및 출시 계획을 만들고, 업데이트된 GA 코드를 오후 11시 20분 PST에 준비했으며, 2월 29<sup>일</sup> 오전 1:50 PST에 테스트 클러스터에서 테스트를 완료했습니다. 병렬로 여러 애플리케이션의 VM에서 프로덕션 클러스터의 수정 사항을 성공적으로 테스트했습니다. 다음으로 하나의 프로덕션 클러스터에 대한 GA 롤아웃을 시작했으며, 이 롤아웃은 오전 2시 11분 PST에 성공적으로 완료되었으며, 이때 모든 클러스터에 수정 사항을 푸시했습니다. 클러스터가 업데이트됨에 따라 해당 클러스터에 대한 서비스 관리 기능을 복원했으며, 오전 5시 23분 PST에서 서비스 관리가 대부분의 클러스터로 복원되었다고 발표했습니다.</p>  <h3>보조 중단</h3>  <p>서비스 관리를 사용하지 않도록 설정했을 때 대부분의 클러스터는 이미 최신 FC, GA 및 HA 버전을 실행 중이거나 거의 롤아웃으로 완료되었습니다. 이러한 클러스터는 완전히 복구되었습니다. 그러나 7개의 클러스터는 버그가 영향을 미쳤을 때 출시를 시작했습니다. 대부분의 서버에는 이전 HA/GA 조합이 있었고 일부는 아래와 같이 GA 윤일 버그를 포함하는 새로운 조합을 가지고 있었습니다.</p>  <p align="center"><img src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/7416.Outage3.png" alt="" border="0"></p>  <p align="center"><em>그림 3. 다른 버전의 HA 및 GA를 실행하는 서버</em></p>  <p>부분적으로 업데이트된 상태인 이러한 7개의 클러스터를 복구하는 다른 접근 방식을 취했습니다.&nbsp; 이전 버전의 FC, HA로 복원했지만 고정된 새 GA를 사용하여 새 HA로 업데이트하는 대신 고정된 GA를 사용하여 복원했습니다. 첫 번째 단계는 이전 GA와의 버전 호환성을 유지하기 위해 이전에 새 HA로 업데이트된 서버에 이전 HA를 배치하여 솔루션을 테스트하는 것이었습니다. 서버의 VM이 성공적으로 시작되었으며 정상인 것처럼 보였습니다.</p>  <p>클러스터에 HA 및 GA 업데이트를 적용하는 일반적인 상황에서는 요일(Update Domains)이라는 배포 가용성 제약 조건을 적용하기 때문에 업데이트에 많은 시간이 걸립니다. 표준 배포 기능을 사용하여 이전 HA를 푸시하는 대신, 모든 서버에서 동시에 이전 버전 HA로 업데이트되는 폭발&rdquo; 업데이트를 옵트인&ldquo;하는 테스트를 통해 충분히 자신감을 느꼈습니다.</p>  <p>아쉽게도 수정 사항을 배포하려는 열망에서 이전 HA를 사용하여 만든 업데이트 패키지에 최신 HA용으로 작성된 네트워킹 플러그 인이 포함되어 있고 두 패키지가 호환되지 않는다는 사실을 간과했습니다. 네트워킹 플러그 인은 VM&rsquo; 가상 네트워크 구성을 담당하며 해당 기능 없이 VM에는 네트워킹 기능이 없습니다. 단일 서버 테스트에는 작동하지 않는 서버의 VM에 대한 네트워크 연결 테스트가 포함되지 않았습니다. 그림 4는 호환되지 않는 조합을 보여 줍니다.</p>  <p style="text-align: center;"><img src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/2133.Outage4.png" alt="" border="0"></p>  <p align="center"><em>그림 4. HA 및 HA 네트워킹 플러그 인의 호환되지 않는 조합을 실행하는 서버</em></p>  <p>29일 오전 2시 47<sup>분</sup> PST에서 호환되지 않는 구성 요소 조합을 해당 7개의 클러스터와 이전에 정상이었던 클러스터를 포함한 모든 VM에 푸시하여 네트워크에서 연결이 끊어졌습니다. ACS(Access Control Service) 및 Windows Azure Service Bus 배포와 같은 주요 서비스가 해당 클러스터에 있었기 때문에 해당 클러스터를 사용하는 모든 애플리케이션이 의존하는 서비스 손실로 인해 영향을 받았습니다.</p>  <p>수정된 HA 패키지를 신속하게 생성했고, 오전 3시 40분에 PST를 다시 테스트했으며, 이번에는 VM 연결 및 VM 상태의 다른 측면을 확인했습니다. 이러한 7개 클러스터에 미치는 영향을 고려하여 오전 5시 40분(PST)부터 수정 사항을 실행하기로 결정했습니다. 클러스터는 대부분 오전 8시 PST까지 다시 작동했지만 다양한 전환으로 인해 많은 서버가 손상된 상태에 있었습니다. 개발자와 운영 직원은 하루 종일 이러한 서버를 수동으로 복원하고 유효성을 검사하는 데 격렬하게 일했습니다. 클러스터 및 서비스가 다시 온라인 상태가 되면서 대시보드에 업데이트를 제공하고 3월 1일 오전 2시 15분(PST) 오전 2시 15분에 모든 Windows Azure 서비스가 정상 상태라는 마지막 인시던트 업데이트를 Windows Azure 대시보드<sup>에</sup> 게시했습니다.</p>  <h3>서비스 개선</h3>  <p>인시던트가 발생한 후 시간을 내어 인시던트를 분석하고 엔지니어링, 운영 및 통신을 개선할 수 있는 방법을 설명합니다.&nbsp; 가능한 한 많은 것을 배우기 위해 근본 원인 분석을 수행하지만 인시던트 모든 측면을 분석하여 이 작업을 수행합니다.&nbsp; 클라우드 컴퓨팅의 세 가지 진실은 하드웨어가 실패하고 소프트웨어에 버그가 있고 사람들이 실수를 저지르는 것입니다.&nbsp; 우리의 임무는 이러한 예측할 수 없는 문제를 모두 완화하여 고객에게 강력한 서비스를 제공하는 것입니다.&nbsp; 이러한 문제를 이해하고 해결함으로써 고객에게 제공하는 서비스를 지속적으로 개선할 것입니다.</p>  <p>분석은 인시던트 수명 주기의 각 부분과 그 이전의 엔지니어링 프로세스를 살펴보면서 네 가지 주요 영역으로 구성됩니다.</p>  <ul>  <li><b>예방</b> &ndash; 시스템이 오류를 방지, 격리 및/또는 복구할 수 있는 방법</li>  <li><b>검색</b> &ndash; 오류를 신속하게 표시하고 복구의 우선 순위를 지정하는 방법</li>  <li><b>응답</b> &ndash; 인시던트 중에 고객을 지원하는 방법</li>  <li><b>복구</b> &ndash; 복구 시간을 줄이고 고객에게 미치는 영향을 줄이는 방법</li>  </ul>  <h4>방지</h4>  <ul>  <li><b>테스트.</b>&nbsp; 초기 중단의 근본 원인은 날짜/시간 값의 잘못된 조작으로 인한 소프트웨어 버그였습니다.&nbsp; 시간 관련 버그를 감지하기 위해 테스트를 개선하는 단계를 수행하고 있습니다.&nbsp; 또한 코드 분석 도구를 개선하여 이와 유사한 코딩 문제를 감지하고 코드 베이스를 이미 검토했습니다.</li>  <li><b>오류 격리.</b>&nbsp; GA(게스트 에이전트) 버그로 인해 작업이 실패했을 때 패브릭 컨트롤러는 노드를 HI(Human Investigate) 상태로 이동했습니다.&nbsp; GA가 아닌 하드웨어에 결함이 있다고 잘못 가정했습니다.&nbsp; 이러한 오류를 구분하고 격리한 후 시스템에 더 전파하기 위한 조치를 취하고 있습니다.</li>  <li><b>정상적인 성능 저하.</b> &nbsp;이 인시던트 중에 이미 서비스를 실행 중인 고객을&rsquo; 보호하기 위해 서비스 관리를 해제하는 단계를 수행했지만, 이로 인해 서비스의 지속적인 관리가 차단되었습니다.&nbsp; 우리는 다른 사람을 유지하고 볼 수 있도록 서비스의 다른 측면을 사용하지 않도록 설정할 수 있도록 더 세분성 제어를 하는 조치를 취하고 있습니다.</li>  </ul>  <h4>감지</h4>  <ul>  <li><b>빨리 실패합니다.</b>&nbsp; GA 오류는 긴 시간 제한 후 75분까지 표시되지 않았습니다.&nbsp; 이러한 경우 장애 조치(fail-fast)하고, 이러한 실패를 경고하고, 복구를 시작할 수 있도록 오류를 더 잘 분류하기 위한 조치를 취하고 있습니다.</li>  </ul>  <h4>대응</h4>  <ul>  <li><b>서비스 대시보드</b>.&nbsp; Windows Azure 대시보드는 개별 서비스 상태를 고객에게 전달하는 기본 메커니즘입니다.&nbsp; 그러나 서비스 대시보드는 간헐적인 가용성 문제를 경험했고, 상황을 전체적으로 요약하지 않았으며&rsquo;, 고객이 필요로 하고 기대하는 세부 사항과 투명성의 세분성을 제공하지 않았습니다&rsquo;.&nbsp;&nbsp;  <ul>  <li><b>간헐적 가용성</b>:&nbsp; 이 대시보드는 Azure 및 Microsoft.com Windows 두 가지 내부 인프라에서 실행되어 두 시스템의 치명적인 오류를 처리합니다.&nbsp; 지리적 특정 인시던트도 처리하기 위해 지리적으로 복제됩니다.&nbsp; 그러나 대시보드는 매우 많은 볼륨 및 장애 조치/부하 분산으로 인해 일시적인 가용성 문제가 발생했습니다.&nbsp;&nbsp;&nbsp; 이를 수정하고 향후 더 강력한 서비스를 보장하기 위한 조치를 취했습니다.</li>  <li><b>상황 요약</b>: 서비스 대시보드는 하위 지역 수준에서 60개 이상의 개별 서비스의 상태에 대한 정보를 제공합니다.&nbsp; 이는 개별 서비스 상태를 이해하는 데 중요하지만 요약 정보가 부족하여 고객이 상황을 전체적으로 이해하기가 어려웠습니다.&nbsp; 고객은 중단의 범위와 심각도를 신속하게 이해할 수 있도록 대시보드에 요약된 보기를 요청했습니다.&nbsp; 우리는 이 변경을 위한 조치를 취하고 있습니다.</li>  <li><b>세부 정보 및 투명성</b>: 업데이트는 시간별로 게시되지만 상태 업데이트는 종종 일반적이거나 지난 몇 시간 동안 제공된 정보를 반복했습니다.&nbsp; 고객은 문제를 해결하기 위해 발생하는 특정 작업에 대한 자세한 내용과 새로운 정보를 제공하도록 요청했습니다.&nbsp; 우리는 중단을 해결하기 위해 취하는 단계에&rsquo; 대한 자세한 내용과 투명성뿐만 아니라 그 과정에서 진행 상황과 좌절에 대한 세부 사항을 제공하기 위해 최선을 다하고 있습니다.</li>  </ul>  </li>  <li><b>고객 지원.&nbsp; </b>이 인시던트 중에는 예상 대기 시간보다 긴 호출 볼륨이 매우 많았습니다.&nbsp;&nbsp; 서비스 대시보드의 간헐적인 가용성과 다른 통신 채널을 통한 업데이트 부족으로 통화 볼륨 증가에 기여하는 경우 대용량 호출 볼륨을 처리할 수 있는 인력이 있습니다.&nbsp; 우리는 고객 지원 인력 요구를 재평가하고 광범위한 채널 세트를 통해 보다 투명한 의사 소통을 제공하는 조치를 취하고 있습니다.</li>  <li><b>기타 통신 채널.</b>&nbsp; 많은 고객이 인시던트 발생 시 블로그, Facebook 페이지 및 Twitter 핸들을 사용하여 통신할 것을 요청하고 있습니다.&nbsp; 그들은 또한 사건 이후에 며칠 안에 이메일을 통해 공식 적인 의사 소통을 더 빨리 제공 할 것을 요청하고 있습니다.&nbsp; 우리는 전반적인 통신을 개선하고 이러한 차량을 통해 보다 사전 예방적인 정보를 제공하기 위한 조치를 취하고 있습니다.&nbsp; 또한 고객에게 보다 세분화된 도구를 제공하고 특정 서비스의 문제를 진단하기 위한 지원을 위한 조치를 취하고 있습니다.</li>  </ul>  <h4>복구</h4>  <ul>  <li><b>내부 도구.&nbsp; </b>이 문제를 해결하기 위해 일부 내부 도구를 개발하고 수정했습니다.&nbsp; 우리는 복구 속도를 돕고 중간 상태에서 복구를 더 예측 할 수 있도록 도구에 계속 투자 할 것입니다.&nbsp;</li>  <li><b>종속성 우선 순위입니다.</b>&nbsp; 또한 ACS 및 Windows Azure Service Bus 같은 모든 Windows Azure 인프라 서비스를 먼저 복구하여 고객에게 미치는 영향을 줄이기 위해 종속성이 복구에 포함되도록 프로세스를 검토하고 있습니다.&nbsp;</li>  <li><b>가시성.</b>&nbsp; 복구 단계에 대한 더 나은 가시성을 제공하고 고객에게 진행 중인 중간 진행 상황을 파악할 수 있는 방법을 찾고 있습니다.</li>  </ul>  <h4>서비스 크레딧</h4>  <p>Microsoft는 이러한 중단이 많은 고객에게 큰 영향을 미쳤다는 것을 알고 있습니다. Microsoft는 서비스 품질과 SLA(서비스 수준 계약)를 유지하며 고객에게 최선을 다하고 있습니다.&nbsp; 이 이벤트의 특별한 특성으로 인해 서비스가 영향을 받았는지 여부에 관계없이 해당 서비스에 대해 영향을 받는 전체 청구 월 동안 Azure Compute, Access Control, Service Bus 및 캐싱을 Windows 모든 고객에게 33%의 크레딧을 제공하기로 결정했습니다.&nbsp; 이러한 크레딧은 사전에 적용되며 영향을 받는 청구 기간 이후에 청구 기간에 반영됩니다.&nbsp; 추가 질문이 있는 고객은 <a target="_blank" href="https://azure.microsoft.com/support/?WT.mc_id=cmp_pst001_blg_post0072">지원에</a> 문의하여 자세한 내용을 확인할 수 있습니다.</p>  <h3>결론</h3>  <p>우리는 앞으로 며칠 및 몇 주 동안 위에 설명된 모든 문제를 완전히 이해하기 위해 시간을 할애할 것이며 서비스를 개선하기 위해 문제를 해결하고 완화하기 위한 조치를 취할 것입니다.&nbsp; Microsoft는 고객이 서비스에 대해 Windows Azure에 의존한다는 것을 알고 있으며 고객과 SLA를 매우 중요하게 생각합니다.&nbsp; 우리는 인시던트가 발생할 때 고객과 계속 투명하게 하기 위해 노력할 것이며, 이 학습을 사용하여 엔지니어링, 운영, 커뮤니케이션 및 고객 지원을 발전시키고 서비스를 개선할 것입니다.</p>  <p>감사합니다.</p>  <p>Bill Laing 및 Windows Azure Team</p>'
