### YamlMime:Yaml
ms.openlocfilehash: 79362782a90e3596b40e147764fa112857e4389e
ms.sourcegitcommit: d03bdc7fe5447adb6530886aab848b75fe8fa8ee
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 03/11/2022
ms.locfileid: "139913007"
Slug: cross-channel-emotion-analysis-in-microsoft-video-indexer
Title: Microsoft Video Indexer의 채널 간 감정 분석
Summary: 산업 전반의 다양한 고객은 미디어 콘텐츠의 다른 부분에 나타나는 감성적인 순간에 대한 통찰력을 원합니다. 방송사의 경우 더 많은 것을 만드는 데 도움이 될 수 있습니다...
Content: >-
  <p>산업 전반의 다양한 고객은 미디어 콘텐츠의 다른 부분에 나타나는 감성적인 순간에 대한 통찰력을 원합니다. 브로드캐스터의 경우 더 많은 영향력 있는 홍보 클립을 만들고 시청자가 콘텐츠로 유도하는 데 도움이 될 수 있습니다. 판매 업계에서는 판매 호출을 분석하고 수렴성을 개선하는 데 매우 유용할 수 있습니다. 광고에서 광고를 팝업하는 가장 좋은 순간을 식별하는 데 도움이 될 수 있으며 목록은 계속 진행됩니다. 이를 위해, 우리는 비디오에서 네 가지 <a href="https://en.wikipedia.org/wiki/Paul_Ekman#Emotions_as_universal_categories" target="_blank">문화적 감정 상태를</a> 감지하기 위해 인간의&rsquo; 행동을 모방 비디오 인덱서&rsquo; (VI) 새로운 기계 학습 모델을 공유하게되어 기쁩니다: 분노, 두려움, 기쁨, 슬픔.</p>


  <p>인간의 감정을 인식하고 해석할 수 있는 인지 능력을 갖춘 머신을 부여하는 것은 복잡성으로 인해 어려운 작업입니다. 인간으로서 우리는 감정을 분석하기 위해 여러 매체를 사용합니다. 여기에는 얼굴 표정, 음성 색조 및 음성 콘텐츠가 포함됩니다. 결국, 특정 감정의 결정은 다양한 각도로이 세 가지 양식의 조합의 결과입니다.</p>


  <p>기존 감정 분석 모델은 예를 들어 콘텐츠 &ndash; 의 극성을 감지하지만 새 &ndash; 모델은 보다 세분성 분석을 제공하는 것을 목표로 합니다. 예를 들어, 부정적인 감정을 가진 순간을 감안할 때, 새로운 모델은 기본 감정이 두려움, 슬픔 또는 분노인지 여부를 결정합니다. 다음 그림에서는 교육의 중요성에 대한 Microsoft CEO Satya Nadellas&rsquo; 연설의 VIS&rsquo; 감정 분석을 보여 줍니다. 그의 연설의 시작 부분에서, 슬픈 순간이 감지되었다.</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/82dbc171-dee3-45ac-9a5f-2e2393ee5472.png"><img alt="Microsoft CEO Satya Nadella's speech on the importance of education" border="0" height="343" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/422fa6c3-955e-45b2-ba60-def29ebfb716.png" style="margin: 0px auto; border: 0px currentcolor; border-image: none; float: none; display: block; background-image: none;" title="Microsoft CEO 사티야 나델라" width="1232"></a></p>


  <p>감지된 모든 감정 및 비디오를 따라 표시되는 특정 모양은 다음과 같이 비디오 인덱스 JSON에 열거됩니다.</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/5682dd63-ccd2-405e-8260-30bb5289b89c.png"><img alt="video index JSON" border="0" height="289" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/b57dfad0-1f50-4cc6-9b68-75cde4529140.png" style="margin: 0px auto; border: 0px currentcolor; border-image: none; float: none; display: block; background-image: none;" title="JSON" width="301"></a></p>


  <h2>VI에서 채널 간 감정 감지</h2>


  <p>새로운 기능은 딥 러닝을 활용하여 음성 콘텐츠 및 음성 음색을 기반으로 미디어 자산에서 감정적인 순간을 감지합니다. VI는 음성 콘텐츠의 의미 체계 속성을 캡처하여 감정을 감지합니다. 그러나 단일 단어의 의미 체계 속성만으로는 충분하지 않으므로 다른 순서의 동일한 단어가 다른 감정을 유도할 수 있기 때문에 기본 구문도 분석됩니다.</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/45b0374b-9cb2-4e07-a8b3-5e903fb5a580.png"><img alt="Syntax" border="0" height="275" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/4544a4f5-5949-422b-903a-4cfeb3dda934.png" style="margin: 0px auto; border: 0px currentcolor; border-image: none; float: none; display: block; background-image: none;" title="구문" width="1388"></a></p>


  <p>VI는 음성 콘텐츠의 컨텍스트를 활용하여 지배적인 감정을 유추합니다. 예를 들어<em>, 자동차가 내게 와서 매우 빠른 속도로 &hellip;&rdquo;가속하는 문장&ldquo;&hellip;</em>은 부정적인 단어가 없지만 VI는 여전히 두려움을 근본적인 감정으로 감지 할 수 있습니다.</p>


  <p>VI는 스피커의 음성 음색도 분석합니다. 음성 활동이 있는 세그먼트를 자동으로 감지하고 음성 콘텐츠 구성 요소에 포함된 정서적 정보를 융합합니다.</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/bdb65fc5-3787-4baf-a798-443e60314b62.png"><img alt="Video Indexer" border="0" height="277" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/771d1f7d-835e-4265-9251-68526ec39786.png" style="margin: 0px auto; border: 0px currentcolor; border-image: none; float: none; display: block; background-image: none;" title="Video Indexer" width="1101"></a></p>


  <p>음성 콘텐츠 및 음성 음색에 의존하는 VI의 새로운 감정 감지 기능을 사용하면 마케팅, 고객 관리 및 영업 목적으로 활용하여 비디오 콘텐츠에 대한 더 많은 통찰력을 얻을 수 있습니다.</p>


  <p>자세한 내용은 <a href="https://www.videoindexer.ai/" target="_blank">VIs&rsquo; 포털</a> 또는 <a href="https://api-portal.videoindexer.ai/" target="_blank">VI 개발자 포털</a>을 방문하여 이 새로운 기능을 무료로 사용해 보세요. 감정 콘텐츠로 인덱싱된 비디오( <a href="https://www.videoindexer.ai/accounts/29189f48-e09a-4bce-9456-3169afd282fd/videos/e09e3055ae/" target="_blank">샘플 1</a>, <a href="https://www.videoindexer.ai/accounts/29189f48-e09a-4bce-9456-3169afd282fd/videos/afdbe9521b/" target="_blank">샘플 2</a> 및 <a href="https://www.videoindexer.ai/accounts/29189f48-e09a-4bce-9456-3169afd282fd/videos/c324f4d698/" target="_blank">샘플 3</a>)를 찾아볼 수도 있습니다.&nbsp;&nbsp;</p>


  <h3>질문이나 의견이 있으신가요? Microsoft는 여러분의 의견을 기다리고 있습니다!</h3>


  <p><a href="https://cognitive.uservoice.com/forums/598144-video-indexer" target="_blank">UserVoice</a>를 사용하여 기능의 우선 순위를 지정하거나 질문이 있는 전자 메일 <a href="mailto:VISupport@Microsoft.com" target="_blank">VISupport@Microsoft.com</a> 을 보내주세요.</p>
