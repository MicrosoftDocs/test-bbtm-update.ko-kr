### YamlMime:Yaml
ms.openlocfilehash: 797c0e0cee9a7576ec6a4d289df2852c1156a99b
ms.sourcegitcommit: d03bdc7fe5447adb6530886aab848b75fe8fa8ee
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 03/11/2022
ms.locfileid: "139912689"
Slug: new-ways-to-train-custom-language-models-effortlessly
Title: 사용자 지정 언어 모델을 학습하는 새로운 방법 - 쉽게!
Summary: Microsoft Azure Media Services VI(Video Indexer)를 사용하면 고객이 특정 사용 사례의 어휘에 속하는 문장 또는 단어의 예제를 업로드할 수 있도록 하여 언어 모델을 사용자 지정할 수 있습니다. 음성 인식은 때때로 까다로울 수 있으므로 VI를 사용하면 특정 도메인에 대한 모델을 학습하고 조정할 수 있습니다.
Content: >-
  <p>Azure Media Services AI 서비스인 VI(Video Indexer)를 사용하면 고객이 특정 사용 사례의 <a href="https://azure.microsoft.com/en-us/blog/bring-your-own-vocabulary-to-microsoft-video-indexer/" target="_blank">어휘</a>에 속하는 문장 또는 단어의 예제를 업로드할 수 있도록 하여 <a href="https://docs.microsoft.com/en-us/azure/media-services/video-indexer/customize-language-model-overview" target="_blank">언어 모델을 사용자 지정할</a> 수 있습니다. 음성 인식은 때때로 까다로울 수 있으므로 VI를 사용하면 특정 도메인에 대한 모델을 학습하고 조정할 수 있습니다. 이 기능을 활용하면 조직에서 해당 계정에서 Video Indexer에서 생성된 전사의 정확도를 향상시킬 수 있습니다.</p>


  <p>지난 몇 개월 동안 이 사용자 지정 프로세스를 더욱 효과적이고 쉽게 수행할 수 있도록 일련의 향상된 기능을 작업했습니다. 향상된 기능에는 수동 또는 API를 통해 수행된 <em>모든 대본 편집 내용을 자동으로 캡처</em> 하고 고객이 <em>선택 자막 파일을 추가하여</em> 사용자 지정 언어 모델을 추가로 학습할 수 있도록 하는 기능이 포함됩니다.</p>


  <p>이러한 추가의 이면에 있는 아이디어는 조직이 기본 기본 언어 모델로 시작하고 일정 기간 동안 수동 편집 및 기타 리소스를 통해 점진적으로 정확도를 향상시키는 <em>피드백 루프</em> 를 만들어 최소한의 노력으로 요구 사항에 맞게 미세 조정된 모델을 만드는 것입니다.</p>


  <p>&rsquo; 계정 사용자 지정 언어 모델 및 이 블로그 공유의 모든 향상된 기능은 비공개이며 계정 간에 공유되지 않습니다.</p>


  <p>다음 섹션에서는 이 작업을 수행할 수 있는 다양한 방법을 드릴다운합니다.</p>


  <h2>대본 업데이트를 사용하여 사용자 지정 언어 모델 개선</h2>


  <p>VI에서 비디오가 인덱싱되면 고객은 Video Indexer 포털을 사용하여 비디오의 자동 전사를 수동으로 편집하고 수정할 수 있습니다. 이 작업은 비디오 <strong>타임라인 창의</strong> 오른쪽 위 모서리에 있는 <strong>편집</strong> 단추를 클릭하여 편집 모드로 이동한 다음 아래 이미지와 같이 텍스트를 업데이트하면 됩니다.</p>


  <p>&nbsp;</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/760800fc-5e7d-44a7-af5c-cbaecfd0afa7.png"><img alt="An image showing the ability to edit text in the Timeline pane." border="0" height="742" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/be8ed3e2-dee7-4aba-b65a-7a009bd63faa.png" style="border: 0px currentcolor; border-image: none; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;" title="타임라인 창에서 텍스트를 편집하는 기능을 보여 주는 이미지입니다." width="1024"></a></p>


  <p>변경 내용은 대본에 반영되고, 텍스트 파일 <strong>에서 대본 편집에서</strong> 캡처되며, 비디오를 인덱싱하는 데 사용되는 언어 모델에 자동으로 삽입됩니다. 아직 고객 언어 모델을 사용하지 않은 경우 업데이트가 계정에서 만든 새 <strong>계정 적응</strong> 언어 모델에 추가됩니다.</p>


  <p>VI 웹 사이트의 콘텐츠 모델 사용자 지정 페이지에서 <strong>언어 탭으로</strong> 이동하여 계정에서 언어 모델을 관리하고 <strong>기록에서</strong> 편집 파일을 볼 수 있습니다.</p>


  <p><strong>From 대본 편집</strong> 파일 중 하나가 열리면 수동 업데이트에서 만든 이전 문장과 새 문장 및 아래와 같이 차이점을 검토할 수 있습니다.</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/e48bf9f8-f432-4c48-9e76-56e60f38f792.png"><img alt="Using the 'From transcript edits' file to review sentence changes." border="0" height="485" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/5fc544b4-a60e-46b0-b9e6-e1eac020ad7b.png" style="border: 0px currentcolor; border-image: none; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;" title="'기록 편집에서' 파일을 사용하여 문장 변경 내용을 검토합니다." width="812"></a></p>


  <p>학습을 클릭하여 최신 변경 내용으로 언어 모델을 <strong>업데이트하기만</strong> 하면 됩니다. 이 시점부터 이러한 변경 내용은 해당 모델을 사용하여 인덱싱된 모든 이후 비디오에 반영됩니다. 물론 포털을 사용하여 모델을 학습시킬 필요는 없으며 Video Indexer <a href="https://api-portal.videoindexer.ai/docs/services/Operations/operations/Train-Language-Model?&amp;pattern=language" target="_blank">학습 언어 모델</a> API를 통해 동일한 작업을 수행할 수 있습니다. API를 사용하면 지속적인 업데이트를 활용하기 위해 되풀이 학습 프로세스를 자동화할 수 있는 것과 같은 새로운 가능성을 열 수 있습니다.</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/753af888-048f-4c10-a646-24692dedd21f.png"><img alt="The Content model customization screen." border="0" height="593" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/3fb70c4e-d63f-4eda-be63-730cb7c8cbe6.png" style="border: 0px currentcolor; border-image: none; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;" title="콘텐츠 모델 사용자 지정 화면입니다." width="1024"></a></p>


  <p>또한 고객이 업데이트를 포함하는 VTT 파일을 업로드하여 계정에서 비디오의 전체 대본을 업데이트할 수 있는 업데이트 <a href="https://api-portal.videoindexer.ai/docs/services/Operations/operations/Update-Video-Transcript" target="_blank">비디오 대본</a> API도 있습니다. 새로운 향상된 기능의 일환으로 고객이 이 API를 사용하는 경우 Video Indexer는 콘텐츠를 교육 자료로 활용하기 위해 고객이 관련 사용자 지정 모델에 자동으로 업로드한 대본을 추가합니다. 예를 들어 대부라는 비디오&quot;의 업데이트 비디오 대본을 호출하면 해당 비디오를 인덱싱하는 데 사용된 사용자 지정 언어 모델에서 대부&rdquo;라는 &ldquo;새 대본 파일이 생성&quot;됩니다.</p>


  <h2>선택 자막 파일을 사용하여 사용자 지정 언어 모델 개선</h2>


  <p>사용자 지정 언어 모델을 학습하는 또 다른 빠르고 효과적인 방법은 기존 선택 자막 파일을 학습 자료로 활용하는 것입니다. 이 작업은 아래 이미지와 같이 포털의 기존 모델에 새 선택 캡션 파일을 업로드하거나 <a href="https://api-portal.videoindexer.ai/docs/services/Operations/operations/Create-Language-Model" target="_blank">언어 모델 만들기</a> 및 <a href="https://api-portal.videoindexer.ai/docs/services/Operations/operations/Update-Language-Model" target="_blank">언어 모델 API를 업데이트</a> 하여 VTT, SRT 또는 TTML 파일을 업로드하여 수동으로 수행할 수 있습니다(TXT 파일을 사용하여 지금까지 수행한 작업과 유사하게).</p>


  <p>&nbsp;</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/05dad023-3928-4b6d-a94c-d5ff2c28ec5c.png"><img alt="The Content model customization screen, with flies added." border="0" height="631" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/c23a0c08-4bd4-4c94-8a3f-6e027a6df7bf.png" style="border: 0px currentcolor; border-image: none; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;" title="파리가 추가된 콘텐츠 모델 사용자 지정 화면" width="1024"></a></p>


  <p>업로드되면 VI는 파일의 모든 메타데이터를 정리하고 텍스트 자체까지 제거합니다. 다음 표에서 이전 및 이후 결과를 볼 수 있습니다.</p>


  <p>&nbsp;</p>


  <table border="1" cellpadding="1" cellspacing="0">
   <tbody>
    <tr>
     <td valign="top"><strong>형식</strong></td>
     <td valign="top"><strong>이전</strong></td>
     <td valign="top"><strong>이후</strong></td>
    </tr>
    <tr>
     <td valign="top"><strong>VTT</strong></td>
     <td valign="top">
     <p>참고 신뢰도: 0.891635<br>
  00:00:02.620 --&gt; 00:00:05.080<br>

  하지만 오전 10시 이전에는 모임이 마음에 들지&#39;.</p>
     </td>
     <td valign="top">하지만 오전 10시 이전에는 모임을 좋아하지 않습니다&rsquo;.</td>
    </tr>
    <tr>
     <td valign="top"><strong>SRT</strong></td>
     <td valign="top">
     <p>2<br>
  00:00:02,620 --&gt; 00:00:05,080<br>

  하지만 오전 10시 이전에는 모임이 마음에 들지&#39;.</p>
     </td>
     <td valign="top">하지만 오전 10시 이전에는 모임을 좋아하지 않습니다&rsquo;.</td>
    </tr>
    <tr>
     <td valign="top"><strong>TTML</strong></td>
     <td valign="top">
     <p>&lt;!-- 신뢰도: 0.891635 --&gt;<br>
  &lt;p begin=&quot;00:00:02.620&quot; end=&quot;00:00:05.080but&quot;&gt; 당신은 오전 10시 이전에 모임을 좋아하지&#39;.&lt; /p&gt;</p>
     </td>
     <td valign="top">하지만 오전 10시 이전에는 모임을 좋아하지 않습니다&rsquo;.</td>
    </tr>
   </tbody>
  </table>


  <p>이 시점부터 모델에 대한 추가 사항을 검토하고 <strong>학습</strong> 을 클릭하거나 <a href="https://api-portal.videoindexer.ai/docs/services/Operations/operations/Train-Language-Model?&amp;pattern=language" target="_blank">학습 언어 모델</a> API를 사용하여 모델을 업데이트하기만 하면 됩니다.</p>


  <h2>다음 단계</h2>


  <p>사용자 지정 언어 모델 학습 흐름에 새로 추가된 기능을 사용하면 사용자와 조직에서 보다 정확한 전사 결과를 쉽고 쉽게 얻을 수 있습니다. 이제 방금 설명한 방법을 사용하여 사용자 지정 언어 모델에 데이터를 추가하여 다음에 비디오를 인덱싱할 때 특정 콘텐츠에 대한 보다 정확한 결과를 얻을 수 있습니다.</p>


  <p><strong>질문이나 의견이 있으신가요?</strong> Microsoft는 여러분의 의견을 기다리고 있습니다! <a href="https://cognitive.uservoice.com/forums/598144-video-indexer" target="_blank">UserVoice 페이지를</a> 사용하여 기능의 우선 순위를 지정하거나 질문에 대한 전자 메일 <a target="_blank">VISupport@Microsoft.com</a> 을 보내주세요.</p>
