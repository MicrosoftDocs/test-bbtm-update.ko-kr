### YamlMime:Yaml
ms.openlocfilehash: a0299a81954bbba1d62dfdb89b1da503d844379c
ms.sourcegitcommit: d03bdc7fe5447adb6530886aab848b75fe8fa8ee
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 03/11/2022
ms.locfileid: "139902056"
Slug: monitoring-environmental-conditions-near-underwater-datacenters-using-deep-learning
Title: Deep Learning 사용하여 수중 데이터 센터 근처의 환경 조건 모니터링
Summary: Microsoft는 지구 AI와 같은 프로그램을 통해 글로벌 환경 문제를 해결하기 위해 노력하는 사람들의 손에 클라우드 및 AI(인공 지능) 도구를 배치했습니다.
Content: >-
  <p><em>이 블로그 게시물은 주샤오용, 나일 윌슨(Microsoft AI CTO Office), 벤 커틀러(Project Natick), 루카스 조파(Microsoft 최고 환경 책임자)가 공동 저술했습니다.</em></p>


  <p>Microsoft는 지구 AI와 같은 프로그램을 통해 글로벌 환경 문제를 해결하기 위해 노력하는 사람들의 손에 클라우드 및 <a href="https://www.microsoft.com/en-us/aiforearth/">AI</a>(인공 지능) 도구를 배치했습니다. 또한 이러한 동일한 도구를 사용하여 <a href="https://natick.research.microsoft.com/">Project Natick</a>과 함께 수행되는 작업과 같이 환경과의 상호 작용을 이해합니다.</p>


  <p><a href="https://natick.research.microsoft.com/">Project Natick</a>은 전 세계 해저 데이터 센터 배포의 이점과 어려움을 이해하려고 합니다. 이는 세계&#39;최초로 배치된 수중 데이터 센터이며 지속 가능성에 중점을 두고 설계되었습니다. 2단계는 재생 가능 에너지로 구동되는 북해에 본격적인 데이터 센터 모듈을 배포하여 1단계에서 수행한 연구를 확장합니다. Project Natick은 AI를 사용하여 서버 및 기타 장비에서 오류 징후를 모니터링하고 환경과 서버 수수 간의 상관 관계를 식별합니다.</p>


  <p>Project Natick은 표준 토지 데이터 센터처럼 작동하므로 내부의 컴퓨터를 기계 학습에 사용하여 다른 Microsoft 데이터 센터와 마찬가지로 다른 애플리케이션에 AI를 제공할 수 있습니다. 또한 AI를 사용하여 주변 수생 환경을 모니터링하며, 데이터 센터가 미칠 수 있는 영향을 이해하는 첫 번째 단계로 사용합니다.</p>


  <p><br>

  <a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/8a953e59-b9a0-427b-b71b-df4ec0470f8c.png"><img alt="image" border="0" height="351" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/6f634128-1775-4586-b4e9-fd6c7dfeda01.png" style="border: 0px currentColor; border-image: none; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;" title="이미지" width="624"></a></p>


  <p align="center"><em>그림 1. Project Natick 데이터 센터 사전 잠수. 사진: 스콧 에클룬드/레드 박스 픽처스</em></p>


  <h2>개체 감지를 사용하여 해양 생물 모니터링</h2>


  <p>Project Natick 데이터 센터는 라이브 비디오 스트림으로 사용할 수있는 두 개의 수중 카메라를 포함하여 서버 조건과 환경을 모니터링하는 다양한 센서를 갖추고 있습니다 (<a href="https://natick.research.microsoft.com/#section-live">Project Natick 홈페이지</a>에서 라이브 스트림 확인). 이러한 카메라를 사용하면 데이터 센터 외부의 두 고정 위치에서 주변 환경을 실시간으로 모니터링할 수 있습니다.</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/c5bd8de1-12d7-4362-885a-e1483406f0fa.png"><img alt="image" border="0" height="231" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/ad63f308-bed5-44ce-949b-b34a1f5e6543.png" style="border: 0px currentColor; border-image: none; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;" title="이미지" width="574"></a></p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/af416e0f-5a05-4a05-9711-5ade92ae2b31.gif"><img alt="Natick livestream" height="143" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/9dcac1be-8755-4740-8fa9-310316d57d42.gif" style="margin-right: auto; margin-left: auto; float: none; display: block;" title="Natick 라이브 스트림" width="214"></a></p>


  <p align="center"><em>그림 2. Project Natick 데이터 센터의 라이브 카메라 피드(원본: <a href="https://natick.research.microsoft.com/">Project Natick 홈페이지</a>)</em></p>


  <p align="left">우리는 카메라에 의해 본 해양 생물을 계산하고 싶습니다. 비디오 스트림의 각 프레임에서 해양 생물을 수동으로 계산하려면 상당한 노력이 필요합니다. 이를 해결하기 위해 개체 감지를 활용하여 해양 생물의 모니터링 및 계산을 자동화할 수 있습니다.</p>


  <p align="left"><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/2792ad9b-f8ce-4777-8bc1-3314145e36fe.png"><img alt="image" border="0" height="103" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/cfe0dd19-f4eb-46f3-af9f-305856a8929e.png" style="border: 0px currentColor; border-image: none; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;" title="이미지" width="509"></a></p>


  <p align="center"><em>그림 3. 라이브 카메라 피드에서, 우리는 왼쪽, 광선을 포함하여 다양한 수생 생활을 관찰; 중간, 물고기; 오른쪽, 화살표 웜</em></p>


  <p align="left">각 프레임에서 해양 생물의 수를 계산합니다. 이를 개체 감지 문제로 모델링합니다. 개체 검색은 분류 작업을 지역화와 결합하고 이미지에서 검색된 각 개체의 경계 상자를 나타내는 범주와 좌표 집합을 모두 출력합니다. 그림 4에 나와 있습니다.</p>


  <p align="left"><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/bddd2529-6c88-451d-81d5-f3ef32f4c30d.png"><img alt="image" border="0" height="212" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/7ad926c0-b6aa-4070-bfd8-85e88803e6da.png" style="border: 0px currentColor; border-image: none; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;" title="이미지" width="460"></a></p>


  <p align="center"><em>그림 4. Computer Vision의 개체 검색 작업입니다. 왼쪽, 입력 이미지; 오른쪽, 경계 상자를 사용하여 개체 검색</em></p>


  <h2>개체 검색 모델을 선택하는 방법</h2>


  <p>지난 몇 년 동안 개체 감지에 대한 많은 흥미로운 딥 러닝 접근 방식이 등장했습니다. <a href="https://arxiv.org/abs/1506.01497">더 빠른 R-CNN</a>과 같은 모델은 2단계 프로시저를 사용하여 먼저 일부 개체가 포함된 지역을 제안한 다음, 제안된 지역을 분류하고 제안된 경계 상자를 조정합니다. 1단계 접근 방식을 사용하여 YOLO( <a href="https://pjreddie.com/media/files/papers/YOLOv3.pdf">You Only Look Once</a> ) 및 SSD( <a href="https://arxiv.org/abs/1512.02325">Single Shot MultiBox Detector </a>) 또는 초점 손실이 있는 <a href="https://arxiv.org/abs/1708.02002">RetinaNet</a> 과 같은 모델은 감지를 위해 고정된 상자 집합을 고려하고 지역 제안 단계를 건너뜁니다. 이는 일반적으로 2단계 감지기에 비해 더 빠릅니다.</p>


  <p>비디오에 대한 실시간 개체 감지를 달성하려면 속도와 정확도 간에 균형을 맞춰야 합니다. 비디오 스트림에서, 우리는 보기&mdash; 물고기, 화살표 벌레 및 광선 내에 오는 수생 생활의 몇 가지 유형이 있다는 것을 관찰했다. 동물 범주의 수가 제한되어 있으므로 CPU에서 실행할 수 있는 비교적 가벼운 개체 감지 모델을 선택할 수 있습니다.</p>


  <p>다양한 딥 러닝 모델 아키텍처의 속도와 정확도를 비교하여 SSD와 MobileNet을 네트워크 아키텍처로 사용하도록 선택했습니다.</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/61051631-481f-4e0c-8575-f8d32f0824ed.png"><img alt="image" border="0" height="313" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/d7875297-9690-446f-8fc2-43f4b92956e9.png" style="border: 0px currentColor; border-image: none; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;" title="이미지" width="507"></a></p>


  <p align="center"><br>

  <em>그림 5. 개체 감지 방법(정확도와 유추 시간 간의 절충). 표식 모양은 메타 아키텍처를 나타내고 색은 기능 추출기를 나타냅니다. 입력 크기, 보폭 등으로 인해 각(메타 아키텍처, 기능 추출기) 쌍이 이 플롯의 여러 지점에 해당<a href="https://arxiv.org/pdf/1611.10012.pdf">합니다.</a></em></p>


  <h2>환경 모니터링을 위한 AI 지향 아키텍처</h2>


  <p>AOA(AI 지향 아키텍처)는 기업이 AI를 사용하여 디지털 변환을 가속화할 수 있는 청사진입니다. AOA를 사용하면 조직에서 비즈니스 솔루션을 비즈니스 솔루션을 실현할 수 있는 AI 도구, 서비스 및 인프라 집합에 매핑할 수&nbsp; 있습니다. 이 예제에서는 AI 지향 아키텍처를 사용하여 환경 모니터링을 위한 딥 러닝 솔루션을 설계합니다.</p>


  <p>그림 6은 수중 데이터 센터 근처의 해양 생물을 모니터링하기 위한 AI 지향 아키텍처를 보여줍니다. 먼저 OpenCV를 사용하여 Azure Media Service에서 스트리밍된 비디오 파일을 저장한 다음, VoTT를 사용하여 비디오 프레임에 레이블을 지정하고 Azure Blob Storage 레이블이 지정된 데이터를 넣습니다. 데이터 세트가 레이블이 지정되고 Azure Blob Storage 배치되면 Azure를 사용하여 개체 검색 모델 학습을 시작합니다. 모델을 학습한 후 모델을 Natick 데이터 센터에 배포하므로 모델이 입력 스트림에서 직접 유추를 실행할 수 있습니다. 그러면 결과가 PowerBI에 게시되거나 직관적인 디버깅을 위해 UI에 직접 표시됩니다. 이러한 각 단계는 다음 섹션에서 설명합니다.</p>


  <p align="center"><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/f77f5af4-90e3-4cd3-8535-0e22a142634f.png"><img alt="image" border="0" height="259" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/840782a2-95b9-4514-86a2-c4af38dc362c.png" style="border: 0px currentColor; border-image: none; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;" title="이미지" width="624"></a></p>


  <p align="center"><em>그림 6. 수중 야생 동물을 감지하기 위한 AI 지향 아키텍처</em></p>


  <p>환경 모니터링 솔루션의 주요 요소는 다음과 같습니다.</p>


  <ul>
   <li>데이터 세트 <ul>
    <li>VoTT(Visual Object Tagging Tool)를 사용하여 데이터 레이블 지정</li>
    <li>학습 및 평가 중에 쉽게 액세스할 수 있도록 데이터 세트를 저장하는 Azure <a href="https://azure.microsoft.com/en-us/services/storage/blobs/">Blob Storage</a></li>
   </ul>
   </li>
   <li>도구 <ul>
    <li>TensorFlow 개체 검색 API</li>
   </ul>
   </li>
   <li>Azure <ul>
    <li>Azure GPU 클러스터 또는 Project Natick Datacenter에서 사용할 수 있는 CPU 클러스터</li>
   </ul>
   </li>
   <li>개발 및 배포 도구 <ul>
    <li>IDE(통합 개발 환경)에서 모델을 개발하고 디버그하는 확장인 <a href="https://www.visualstudio.com/downloads/ai-tools-vs/">AI용 Visual Studio Tools</a></li>
   </ul>
   </li>
  </ul>


  <h3>개체 검색을 위한 데이터 레이블 지정</h3>


  <p>첫 번째 단계는 비디오 파일에 레이블을 지정하는 것입니다. 비디오 스트림은 공개적으로 사용할 수 있으며(<a href="https://aka.ms/azuremediaplayer?url=%2F%2Fnatickmediaservices.streaming.mediaservices.windows.net%2F57320b1f-7365-436c-8e4e-9bad1345e849%2Fa5f06021-0b1e-4af9-8071-89727c774501.ism%2Fmanifest">여기</a> 와 <a href="https://aka.ms/azuremediaplayer?url=%2F%2Fnatickmediaservices.streaming.mediaservices.windows.net%2F436cbbc1-6c6f-40e1-a3b3-f65baa4ecdc9%2F41f19f22-1154-4661-8d54-5adaf375d43a.ism%2Fmanifest">여기</a>) OpenCV를 사용하여 로컬 mp4 파일에 저장할 수 있습니다. 레이블 지정 프로세스를 용이하게 하기 위해 Microsoft에서 개발한 오픈 소스 도구 <a href="https://github.com/Microsoft/VoTT">VoTT</a> 를 사용하여 mp4 비디오 파일에 레이블을 지정합니다. VoTT는 비디오에서 개체의 레이블을 지정하기 위해 빌드된 일반적으로 사용되는 도구입니다.</p>


  <p>이 문제의 경우 물고기와 화살표 벌레를 모니터링하도록 범위를 지정합니다. 두 클래스(화살표 웜 및 물고기)에 대해 총 200개의 이미지를 표시했으며 레이블이 지정된 데이터는 <a href="https://github.com/Microsoft/Project_Natick_Analysis">GitHub 리포지토리</a>에서 사용할 수 있습니다.</p>


  <p align="left"><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/1620d0b0-ad0d-46a8-a04f-4f35f87e88e8.png"><img alt="image" border="0" height="285" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/f34486c3-f9b2-441a-91ee-f46e8b41271c.png" style="border: 0px currentColor; border-image: none; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;" title="이미지" width="555"></a></p>


  <p align="center"><em>그림 7. 레이블이 지정된 파일의 샘플 이미지</em></p>


  <h2>Azure를 사용하여 개체 검색 모델 학습</h2>


  <p>TensorFlow를 사용하여 개체 검색을 수행했습니다. TensorFlow에는 몇 가지 기본 제공 네트워크 아키텍처가 있는 <a href="https://github.com/tensorflow/models/tree/master/research/object_detection">TensorFlow 개체 감지 API</a> 가 함께 제공되므로 수중 동물을 인식하도록 신경망을 쉽게 학습시킬 수 있습니다.</p>


  <p>데이터 세트가 작기 때문에(화살표 웜 및 물고기의 경우 총 200개 이미지) 문제는 레이블이 지정된 데이터가 제한된 정확한 개체 탐지기를 학습시키고 과잉 맞춤을 방지하는 방법입니다. 대칭 이동, 색 조정(색조, 밝기, 대비 및 채도 포함) 및 경계 상자 지터링과 같은 강력한 데이터 확대를 사용하여 COCO 가중치에서 초기화된 1,000단계의 개체 감지기를 학습하여 대부분의 조건에서 모델이 잘 일반화될 수 있도록 합니다.</p>


  <p>또한 정기적으로 사용되는 앵커 비율(예: 2:1)과 함께 더 많은 앵커 비율(특히 0.25:1 및 4:1)을 사용하여 모델이 대부분의 동물을 포착할 수 있도록 합니다. 이는 모양이 길고 좁기 때문에 화살표 웜을 캡처하는 데 특히 유용합니다.</p>


  <p>코드 및 개체 검색 구성은 이 <a href="https://github.com/Microsoft/Project_Natick_Analysis">GitHub 리포지토리</a>에서 사용할 수 있습니다.</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/bdfbcce8-5e02-4a29-8533-a17f04b3cb3b.png"><img alt="image" border="0" height="160" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/7dd99e28-0151-4cfa-a8d5-c4d799acc60d.png" style="border: 0px currentColor; border-image: none; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;" title="이미지" width="566"></a></p>


  <p align="center"><em>그림 8. 수중 생물 탐지기에 대한 훈련 손실</em></p>


  <h3>Project Natick 데이터 센터에 모델 배포</h3>


  <p>우리가 물어본 또 다른 질문은 - 우리는 데이터 센터 주위에 가득 야생 동물을 모니터링하기 위해 Natick 데이터 센터에 모델을 배포 할 수 있습니까?</p>


  <p>CPU를 사용하여 입력 비디오를 처리하고 로컬에서 테스트하여 제대로 작동하는지 확인했습니다. 그러나 기본 TensorFlow 미리 빌드된 이진 파일에는 최신 CPU를 완전히 활용하기 위한 AVX 또는 FMA 기본 제공과 같은 최적화가 없습니다. CPU를 더 잘 활용하기 위해 소스 코드에서 TensorFlow 이진 파일을 빌드하고 Intels&rsquo; <a href="https://software.intel.com/en-us/articles/intel-optimization-for-tensorflow-installation-guide">설명서</a>에 따라 Intel CPU에 대한 모든 최적화를 설정했습니다. 모든 최적화를 통해 초당 약 2프레임에서 초당 3프레임으로 처리 속도를 50% 늘릴 수 있습니다. 빌드 명령은 다음과 같습니다.</p>


  <pre>

  bazel build --config=mkl -c opt --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-mavx512f --copt=-mavx512pf --copt=-mavx512cd --copt=-mavx512er --copt=&quot;-DEIGEN_USE_VML&quot;


  //tensorflow/tools/pip_package:build_pip_package</pre>


  <h3>Power BI 사용하여 실시간 환경 모니터링</h3>


  <p>환경 과학자와 수생 과학자들은 수중 데이터 센터의 통계를 보다 직관적으로 모니터링하여 Power BI 통해 강력한 시각화를 통해 진행 중인 일에 대한 통찰력을 빠르게 얻을 수 있습니다.</p>


  <p>Power BI 스트리밍된 데이터를 수락하고 실시간으로 대시보드를 업데이트하는 기능을 제공하는 실시간 데이터 세트<a href="https://docs.microsoft.com/en-us/power-bi/service-real-time-streaming">의 개념을 가지고 있습니다</a>. REST API를 호출하여 몇 줄의 코드로 데이터를 Power BI 대시보드에 게시하는 것은 직관적입니다.</p>


  <pre>

  # REST API endpoint, given to you when you create an API streaming dataset

  # Will be of the format: <a href="https://api.powerbi.com/beta/">https://api.powerbi.com/beta/</a>&lt;tenant id&gt;/datasets/&lt; dataset id&gt;/rows?key=&lt;key id&gt;

  REST_API_URL = &#39; *** Your Push API URL goes here *** &#39;

  # ensure that timestamp string is formatted properly

  now = datetime.strftime(datetime.now(), &quot;%Y-%m-%dT%H:%M:%S%Z&quot;)

  # data that we&#39;re sending to Power BI REST API

  data = &#39;[{{ &quot;timestamp&quot;: &quot;{0}&quot;, &quot;fish_count&quot;: &quot;{1}&quot;, &quot;arrow_worm_count&quot;: &quot;{2}&quot; }}]&#39;.format(now, fish_count, arrow_worm_count)

  req = urllib2.Request(REST_API_URL, data)

  response = urllib2.urlopen(req)</pre>


  <p>동물이 빠르게 이동할 수 있기 때문에 짧은 연속으로 여러 프레임의 데이터를 캡처하고, Power BI 대시보드로 보내고, 컴퓨팅 리소스를 사용하는 것 사이에서 신중하게 균형을 유지해야 합니다. 이 균형을 달성하기 위해 분석된 데이터(예: 물고기 수)를 초당 세 번 Power BI 푸시하기로 결정했습니다.</p>


  <p><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/01a8b2d6-efd8-47fe-9b2e-695792e6364d.png"><img alt="image" border="0" height="174" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/024e3c5f-09bb-492a-b835-dc258a084494.png" style="border: 0px currentColor; border-image: none; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;" title="이미지" width="624"></a></p>


  <p align="center"><em><a href="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/5a922b56-ae94-4130-8a3c-a7f3b7c8c659.gif"><img alt="Natick Power BI dashboard" border="0" height="359" src="https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/d78b59fd-ab95-4b57-b32e-459931e00c0f.gif" style="border: 0px currentColor; border-image: none; display: inline; background-image: none;" title="Natick Power BI 대시보드" width="573"></a></em></p>


  <p align="center"><em>그림 9. 비디오 프레임과 함께 실행되는 대시보드를 Power BI. 아래쪽: E2E 결과를 보여 주는 GIF</em></p>


  <h2 align="left">요약</h2>


  <p>환경 영향을 모니터링하는 것은 중요한 주제이며, AI는 이 프로세스를 보다 확장 가능하고 자동화하는 데 도움이 될 수 있습니다. 이 게시물에서는 수중 데이터 센터 근처에서 환경 모니터링을 위한 딥 러닝 솔루션을 개발한 방법을 설명했습니다. 이 솔루션에서는 데이터를 수집 및 저장하고 수중 동물 탐지기를 학습시켜 카메라에서 볼 수 있는 해양 생물을 감지하는 방법을 보여 줍니다. 그런 다음 모델은 해양 생물을 모니터링하기 위해 데이터 센터의 머신에 배포됩니다. 동시에 비디오 스트림을 분석하고 Power BI&rsquo; 스트리밍 API를 활용하여 시간이 지남에 따라 해양 생물을 모니터링하는 방법을 알아봅니다.</p>


  <p>질문이나 의견이 있는 경우 <a href="https://github.com/Microsoft/Project_Natick_Analysis">GitHub 리포지토리</a>에 메시지를 남겨 주세요.</p>
