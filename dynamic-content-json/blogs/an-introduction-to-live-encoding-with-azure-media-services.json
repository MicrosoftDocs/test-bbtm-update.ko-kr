{
    "Slug": "an-introduction-to-live-encoding-with-azure-media-services",
    "Title": "Azure Media Services 포함된 라이브 인코딩 소개",
    "Summary": "In this blog, I will provide an overview of this Live Encoding feature, which adds the following capabilities to Azure Media Services.",
    "Content": "<div style=\"background:#eee;border:1px solid #ccc;padding:5px 10px;\"><strong>2019년 4월 19일에 업데이트됨: </strong>Azure Media Services 2015년 블로그 게시물 이후 진화했습니다. 서비스의 현재 기능에 대해서는 설명서, &ldquo;<a href=\"https://docs.microsoft.com/en-us/azure/media-services/latest/live-streaming-overview\">Azure Media Services v3</a>&rdquo;을 사용한 라이브 스트리밍, &ldquo;<a href=\"https://docs.microsoft.com/en-us/azure/media-services/latest/live-events-outputs-concept\">라이브 이벤트 및 라이브 출력을</a> 참조하세요.&rdquo; 특히 지원되는 형식, 코덱 및 입력 프로토콜에 대한 아래 섹션은 이후 업데이트되었습니다.</div>\n\n<p>지난해 Azure Media Services 라이브 스트리밍이 출시된 이후, 여러분은 방송사가 수백만 명의 고객에게 라이브 이벤트를 제공하기 위해 몇 번이고 사용한 것과 동일한 즉시 확장 가능하고 항상 사용 가능한 스트리밍 솔루션에 액세스할 수 있었습니다. <a href=\"https://azure.microsoft.com/blog/2014/09/10/getting-started-with-live-streaming-using-the-azure-management-portal/\" target=\"_blank\">Azure 관리 포털</a> 또는 <a href=\"https://azure.microsoft.com/blog/2014/11/04/getting-started-with-live-streaming-using-the-media-services-sdk-2/\" target=\"_blank\">.NET SDK</a>를 사용하여 라이브 이벤트를 관리하고 <a href=\"https://azure.microsoft.com/blog/2014/09/18/azure-media-services-rtmp-support-and-live-encoders/\" target=\"_blank\">라이브 피드를 생성하는</a> 방법에 대한 동료&rsquo; 블로그를 읽었을 수 있습니다.&nbsp; 그러나 이전에는 라이브 스트리밍을 사용하려면 온-프레미스 인코더를 사용하여 적응 비트 전송률 비디오 스트림을 생성하고 클라우드로 푸시해야 했습니다. 라이브 인코딩의 미리 보기 릴리스를 사용하면 단일 비트 전송률 라이브 피드를 Azure Media Services 보내고, 적응 비트 전송률 스트림으로 인코딩하고, MPEG-DASH, Microsoft 부드러운 스트리밍, Apple HLS 또는 Adobe HDS 형식으로 배달하는 다양한 클라이언트에 배달할 수 있습니다. 이 블로그에서는 다음 기능을 Azure Media Services 추가하는 이 라이브 인코딩 기능에 대한 개요를 제공합니다.</p>\n\n<ul>\n <li>적응 비트 전송률 스트림으로 단일 비트 전송률 라이브 피드의 라이브 인코딩</li>\n <li>RTP 프로토콜(MPEG 전송 스트림), RTMP 및 부드러운 스트리밍을 통해 라이브 피드를 수집하는 기능</li>\n <li>슬레이트 삽입을 제어하고 클라이언트에 광고 삽입을 알리는 기능</li>\n <li>라이브 피드의 썸네일 미리 보기를 가져오는 기능</li>\n</ul>\n\n<h2>라이브 인코딩이란?</h2>\n\n<p>라이브 이벤트를 스트리밍할 때 목표는&nbsp; 다양한 네트워크 조건에서 고객이 가질 수 있는 모든 디바이스에 고품질 비디오를 제공하는 것입니다. 품질 및 네트워크 조건의 문제에는 <a href=\"https://en.wikipedia.org/wiki/Adaptive_bitrate_streaming\" target=\"_blank\">적응 비트 전송률 스트리밍이라는 솔루션이 있습니다</a>. 그리고 여러 디바이스(및 해당 기능)의 문제에 대한 해결책은 동적 패키징과 같은 재패키 <a href=\"https://go.microsoft.com/fwlink/?linkid=276874\" target=\"_blank\">징</a> 시스템입니다. 적응 비트 전송률 스트리밍은 비디오를 서로 다른 해상도 및 비트 전송률로 여러 비디오 스트림에 인코딩하는 동시에 동기화된 상태로 유지하여 작동합니다. 또한 라이브 이벤트의 경우 들어오는 비디오를 실시간으로 처리하여 관리 가능한 수에 대한 대기 시간을 유지해야 합니다. 이 실시간 비디오 압축은 라이브 인코딩이며 많은 컴퓨팅 주기가 필요합니다. 라이브 이벤트를 스트리밍하기 위해 이제 GPU 가속과 같은 빠른 CPU가 있는 하드웨어 상자를 살펴봅니다. 또한 여러 비디오 스트림(6~10개)을 생성하고 있습니다. 즉&nbsp;, 이러한 스트림을 CDN 가져오기 위해 많은 대역폭을 제공하므로 고객에게 이벤트를 제공할 수 있습니다. 인프라 비용이 Azure Media Services 라이브 인코딩을 추가&hellip;하기 시작하는 것은 이러한 인프라 문제를 해결하는 클라우드 기반 워크플로입니다. 이 기능을 사용하면 단일(고품질) 비디오 피드만 Azure 데이터 센터로 보내야 하며, 서비스는 이를 적응 비트 전송률 스트림으로 인코딩하는 계산 집약적 작업을 처리합니다. 즉, 원격 위치에서 라이브 이벤트를 실행할 수 있습니다 (좋은, 빠른 WiFi 또는 모바일 네트워크에 대 한 지불), 그리고 카메라에 내장 된 인코더, 또는 더 적은 전력을 필요로 하는 저렴 한 (심지어 무료) 인코더. Microsoft 서비스는 즉시 확장 가능하므로 사용하는 항목에 대해서만 지불하는 이벤트 일정의 급증을 처리할 수 있습니다.</p>\n\n<h2>라이브 인코딩을 사용할 어떻게 할까요? 있나요?</h2>\n\n<p>다음 단계를 통해 라이브 이벤트를 배달하도록 라이브 인코딩을 설정할 수 있습니다.</p>\n\n<ol>\n <li>입력 라이브 피드에 사용할 프로토콜 결정(아래 섹션 참조)</li>\n <li>API 또는 Azure 관리 포털을 사용하여 라이브 채널을 만들고 라이브 인코딩 요구 사항을 충족하는 설정을 선택합니다.</li>\n <li>단일(고품질) 비디오 피드로 보내도록 온-프레미스 인코더 설정</li>\n <li>예를 들어 Azure 관리 포털을 통해 출력 스트림 미리 보기</li>\n <li><a href=\"https://azure.microsoft.com/en-us/documentation/articles/media-services-manage-channels-overview/\" target=\"_blank\">이벤트를 관리하는</a> 프로그램 만들기</li>\n</ol>\n\n<p>참고: 향후 블로그 게시물을 통해 API 및 구성 단계에 대한 세부 정보를 얻을 수 있습니다.</p>\n\n<h2>지원되는 형식 및 코덱</h2>\n\n<p>라이브 인코딩에서 지원하는 입력 프로토콜은 RTMP, RTP(MPEG TS) 및 부드러운 스트리밍입니다. 비디오가 MPEG-2(최대 422 프로필) 또는 H.264(최대 High 422 프로필)로 인코딩되고 오디오가 AAC-LC(최대 7.1 채널) 또는 Dolby&reg; Digital/AC-3(최대 7.1 채널) 또는 MPEG 오디오(계층 II 및 III, 스테레오까지)로 인코딩되는 라이브 피드로 보낼 수 있습니다. 라이브 인코더는 4:2:2에서 4:2:0까지의 크로마 하위 샘플링과 오디오 채널 다운믹싱, 오디오 리샘플링 및 오디오 동적 범위 압축을 지원합니다. 출력에서 라이브 인코더는 비디오를 H.264(최대 높음 4:2:0 프로그레시브)로 인코딩하고 오디오를 스테레오 또는 모노 채널 AAC(LC, HE v1, HE v2 프로필)로 인코딩할 수 있습니다. 또한 라이브 인코더는 입력 비디오 피드에 있는 경우 EIA/CEA-708 선택 자막의 통과를 지원합니다. 알림 알림의 경우 라이브 인코더는 API 호출을 통한 입력을 지원하거나, theinput&nbsp; 프로토콜이 RTP인 경우, in-bandSCTE-35&nbsp; SpliceInsert 및 TimeSignal 명령을 지원합니다. 출력에서 서비스는 HLS 재생 목록 태그(SCTE-67), 부드러운 스트리밍 스파스 트랙(SCTE-35) 및 HDS CueInfo 요소를 내보낼 수 있습니다.</p>\n\n<h2>수집 프로토콜 선택</h2>\n\n<p>다음 중 하나를 통해 채널에 입력 라이브 피드를 보낼 수 있습니다.</p>\n\n<ol>\n <li>RTMP: 입력 피드를 개방형 인터넷을 통해 주변 Azure 데이터 센터로 보내거나, 카메라에 기본 제공되는 인코더를 사용하거나, Telestream Wirecast, Flash Media Live Encoder, Tricaster 등의 도구를&nbsp; 사용하는 프로서머 시나리오에서 가장 일반적입니다.</li>\n <li>RTP: Elemental Technologies, Ericsson, Ateme&nbsp;, Envivio 등과 같은 공급업체의 온-프레미스 라이브 인코더로 전문 방송사를 대상으로 합니다.&nbsp; 입력 스트림은 일반적으로 IT 부서와 함께&nbsp; 설정되며 Microsoft <a href=\"https://azure.microsoft.com/en-us/services/expressroute/\">Azure ExpressRoute</a>와 같은 프라이빗/전용 네트워크를 사용합니다.</li>\n <li>HTTP를 통한 부드러운 스트리밍: 일반적으로&nbsp;&nbsp; Elemental Technologies, Ericsson, Ateme,&nbsp; Envivio 등과 같은 공급업체의 온-프레미스 라이브 인코더를 사용합니다. 일반적으로 열린 인터넷을 통해 입력 스트림을 근처의 Azure 데이터 센터로 보낼 수 있습니다.</li>\n</ol>\n\n<h2>RTMP 사용에 대한 참고 사항</h2>\n\n<p>RTMP를 통해 채널에 라이브 피드를 보내는 경우 다음 제약 조건이 적용됩니다.</p>\n\n<ol>\n <li>최대 1080p30 해상도에서 H.264로 인코딩된 비디오 및 AAC-LC로 인코딩된 스테레오 오디오</li>\n <li>오디오 샘플링 속도는 44.1kHz여야 합니다.</li>\n <li>닫힌 GOP 및 CBR 모드 인코딩 권장</li>\n <li>사용 가능한 대역폭이 비디오 및 오디오의 집계 비트 전송률을 초과해야 합니다.</li>\n</ol>\n\n<h2>RTP 사용에 대한 참고 사항</h2>\n\n<p>RTP를 사용하여 라이브 스트림으로 보내려는 경우 네트워크 연결에서 다음을 예상해야 합니다.</p>\n\n<ol>\n <li>높은 처리량(입력 스트림의 비트 전송률 최대 1.5배). 높은 대역폭은 높은 프로필 이벤트 중에만 필요할 수 있지만 연중무휴로 필요할 수 있으므로 네트워크에 대한 선택은 비용 절감을 위해 대역폭 약정을 쉽게 변경할 수 있어야 합니다.</li>\n <li>짧은 대기 시간(150ms 미만), 추적 경로에 의해 보고된 약 10-15개의 홉</li>\n <li>QoS 및&nbsp; 사용 가능성에 대한 SLA</li>\n</ol>\n\n<p>두 가지 권장 방법은 아래에 설명되어 있습니다. 선택한 옵션에 관계없이 계층 1 네트워크 공급자를 사용해야 합니다. 계층 1 네트워크 공급자 목록은 <a href=\"https://en.wikipedia.org/wiki/Tier_1_network\">여기에서</a> 찾을 수 있습니다.</p>\n\n<h2>공용 인터넷 및 BGP(Border GatewayProtocol&nbsp;)&nbsp;를 통해 RTP 피어링</h2>\n\n<p>공용 인터넷을 통해 RTP를 사용하고 Microsoft Azure 네트워크와 BGP 피어링을 사용할 수 있습니다. 이 경우 HSIP(고속 IP)라고도 하는 인터넷 용량은 하나 이상의 네트워크 공급자가 제공합니다. 비디오 데이터는 공용 인터넷을 통과하며 네트워크 공급자&rsquo; 인터넷 IP 에지와 공동 위치에서 Microsoft Azure 네트워크 간에 교차 연결이 필요합니다. 이 공동 위치는 네트워크 공급자 및 Microsoft에 따라 달라 지고 <a href=\"https://www.peeringdb.com/\" target=\"_blank\">PeeringDB</a>에서 찾을 수 있습니다. 네트워크 공급자는 업계 표준 SLA를 사용하여 Azure로 인터넷 배달 서비스를 담당합니다. 이것은 우리가 현재 <a href=\"https://news.microsoft.com/2014/02/06/nbc-olympics-production-of-the-2014-olympic-winter-games-to-utilize-microsoft-for-live-and-on-demand-streaming/\">NBC 스포츠 / 소치 올림픽 솔루션</a>에서 사용하는 접근 방식이며, 종종 낮은 네트워킹 비용을 초래한다.</p>\n\n<h2>프라이빗/전용 네트워크를 통해 RTP</h2>\n\n<p>전용 프라이빗 네트워크를 통해 일반 데이터 전송(비디오 특정 데이터 대신)을 위해 설계된 네트워크 솔루션을 사용할 수 있습니다. 이 옵션은 네트워크 공급자의 관리되는 서비스 패키지를 통해 제공되는 경우가 많습니다. 필요한 것은 패키지에 제공되는 서비스의 하위 집합일 수 있습니다. 이러한 관리형 서비스의 이점은 엔드 투 엔드 배달이 향상된 SLA로 제공되고 관리된다는 것입니다. 이 범주에는 두 가지 유형의 서비스가 있습니다.</p>\n\n<ol>\n <li>NSP(네트워크 서비스 공급자) 또는 Exchange 공급자(예: Azure ExpressRoute + 수준 3 클라우드 커넥트 솔루션 또는&nbsp; <a href=\"https://www.equinix.com/services/interconnection-connectivity/cloud-exchange/\">Azure ExpressRoute + Equinix Cloud Exchange를 통해 Microsoft Azure ExpressRoute</a> <a href=\"https://azure.microsoft.com/en-us/services/expressroute/\"></a></li>\n <li><a href=\"https://www.level3.com/en/products/vyvx-solutions/\">수준 3 VYVX 솔루션</a>과 같은 네트워크 공급자가 제공하는 관리되는 비디오 서비스</li>\n</ol>\n\n<p>&nbsp; RTP를 통해 라이브 피드를 보내는 경우 사용되는 일반적인 전송 중 인코딩/컨테이너 및 프로토콜은 다음과 같습니다.</p>\n\n<ul>\n <li>인코딩: H264/AAC</li>\n <li>컨테이너 형식: MPEG-2 TS</li>\n <li>네트워크 프로토콜 &ndash; 애플리케이션 계층: RTP 유니캐스트</li>\n <li>네트워크 프로토콜 &ndash; 전송 계층: UDP</li>\n</ul>\n\n<h2>슬레이트 및 신호 광고 사용</h2>\n\n<p>채널이 Live Encoding을 사용하도록 설정된 경우 파이프라인에 비디오를 처리하는 구성 요소가 있으며 이 구성 요소를 조작할 수 있습니다. 이 서비스에서는 채널이 슬레이트 및/또는 광고 신호를 나가는 적응 비트 전송률 스트림에 삽입할 수 있습니다. 슬레이트는 특정한 경우(예: 중간 광고 중)에 입력 라이브 피드를 숨기는 데 사용할 수 있는 정지 이미지입니다. 이름에서 알 수 있듯이 광고 신호는 비디오 플레이어에게 적절한 시간에 광고로 전환하는 것과 같은 특별한 조치를 &ndash; 취하도록 지시하기 위해 나가는 스트림에 포함하는 시간 동기화 신호입니다. 이 목적을 위해 사용되는 SCTE-35 신호 메커니즘의 개요는 이 <a href=\"https://codesequoia.wordpress.com/2014/02/24/understanding-scte-35/\" target=\"_blank\">블로그</a> 를 참조하세요. 다음은 라이브 이벤트에서 구현할 수 있는 일반적인 시나리오입니다(샘플 코드 및 API 세부 정보는 예정된 블로그 게시물에서 사용할 수 있음).</p>\n\n<ol>\n <li>이벤트가 시작되기 전에 시청자가 사전 이벤트 이미지를 받게 합니다.</li>\n <li>이벤트가 종료된 후 시청자가 POST-EVENT 이미지를 받게 합니다.</li>\n <li>이벤트 중에 문제가 있는 경우 뷰어에 ERROR-EVENT 이미지가 표시되도록 합니다(예: 경기장의 정전)</li>\n <li>AD-BREAK 이미지를 보내 상업용 중단 중에 라이브 이벤트 피드를 숨깁니다.</li>\n</ol>\n\n<h2>라이브 피드의 축소판 그림 미리 보기 가져오기</h2>\n\n<p>Live Encoding을 사용하도록 설정한 경우 이제 라이브 피드가 채널에 도달할 때 라이브 피드의 미리 보기를 가져올 수 있습니다. 이 도구는 라이브 피드가 실제로 채널에 도달하고 있는지를 확인하는 데 유용할 수 있습니다. API를 통해 썸네일에 액세스할 수 있습니다.</p>\n\n<h2>요약</h2>\n\n<p>이 블로그에서는 Azure Media Services 라이브 인코딩 기능을 소개했습니다. 앞으로 Azure 관리 포털 사용, 라이브 인코딩 사용, 입력 라이브 피드 생성을 위한&nbsp; 구성&nbsp; 온-프레미스 인코더, 슬레이트 및 광고를 제어하는 방법과 같은&nbsp; 주제에 대한 게시물이 더 많이 있을 것입니다. 그 동안 이 기능에 대한 질문이 있으면 문의하세요. <a href=\"mailto:AMSLiveD@microsoft.com\">AMSLiveD@microsoft.com</a></p>\n"
}